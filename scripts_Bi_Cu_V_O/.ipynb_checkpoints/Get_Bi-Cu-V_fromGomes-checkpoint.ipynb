{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "663baee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "from copy import deepcopy\n",
    "from scipy.constants import h, c, e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "5412899a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The Bi-Cu-V dataset is from \"Automating crystal-structure phase mapping by combining deep learning with constraint reasoning\" \n",
    "and its github:https://github.com/gomes-lab/DRNets-Nature-Machine-Intelligence\n",
    "\n",
    "In the following, **P** is the number of pure phases provided in the ICDD library,\n",
    "**M** is the number of elements in the system, \n",
    "**N** is the number of data points, \n",
    "**Q** is the number of diffraction scattering vector magnitudes (angles) with measurements in each XRD pattern, \n",
    "**Q'** is the downsampled length, and **K** is the expected maximum number of phases present in the solution.\n",
    "\n",
    "ICDD Library-100 entries:\n",
    "    **bases_comp.npy** :a matrix of size (**P**, **M**), e.g., (100, 3) for Bi-Cu-V.\n",
    "        The elemental compositions of the possible pure phases in the ICDD library.\n",
    "    **bases_edge.npy** : a matrix of size (**P**, **P**), e.g., (100, 100) for Bi-Cu-V.  \n",
    "        The similarity matrix of possible phases. If two phases are linked, then they are very similar to each other and can be considered interchangeable.\n",
    "    **bases_name.npy** : a vector of size (**P**), e.g., (100) for Bi-Cu-V.  \n",
    "        The names of the possible pure phases in the ICDD library.\n",
    "    **sticks_lib.npy** : an object array of size (**P**).  \n",
    "        The stick pattern or list of peaks (Q, intensity) for each ICDD library phase.\n",
    "\n",
    "    \n",
    "Instance_data-307 samples:\n",
    "    **composition.npy** : a matrix of size (**N**, **M**), e.g., (307, 3) for Bi-Cu-V.  \n",
    "        The elemental composition of the mixed material in each data point.\n",
    "    **data.npy** : a matrix of size (**N**, **M**+**Q**), e.g., (307, 3 + 1197) for Bi-Cu-V.  \n",
    "        For each row, the composition (length **M**) is concatenated with the XRD pattern (length **Q**), i.e. the XRD intensity at each diffraction angle.\n",
    "    **lib_comp.npy** : a matrix of size (**P**, **M**), e.g., (100, 3) for Bi-Cu-V.  \n",
    "        The elemental compositions of the possible pure phases in the ICDD library. This is the same as bases_comp.npy.\n",
    "    **Q.npy** : a vector of length (**Q**).  \n",
    "        The XRD scattering vector magnitudes (angles) for the XRD patterns.\n",
    "    **Q_XXX.npy** : a vector of length (**Q'**).  \n",
    "        The downsampled XRD scattering vector magnitudes (angles) for lower resolution versions of the XRD patterns.\n",
    "    **XRD.npy** : a matrix of size (**N**, **Q**) \n",
    "        The unnormalized XRD patterns for each data point.   \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# ICDD Library-100 entries:\n",
    "bases_comp = np.load('bases_comp.npy', allow_pickle = True)\n",
    "bases_edge = np.load('bases_edge.npy',allow_pickle = True)\n",
    "bases_name = np.load('bases_name.npy',allow_pickle = True)\n",
    "sticks_lib = np.load('sticks_lib.npy',allow_pickle = True)\n",
    "\n",
    "# Instance_data-307 samples:\n",
    "composition = np.load('composition.npy',allow_pickle = True)\n",
    "data_com_xrd = np.load('data.npy',allow_pickle = True)\n",
    "lib_comp = np.load('lib_comp.npy',allow_pickle = True)\n",
    "Q= np.load('Q.npy',allow_pickle = True)\n",
    "Q_300= np.load('Q_300.npy',allow_pickle = True)\n",
    "Q_idx_300 = np.load('Q_idx_300.npy',allow_pickle = True)\n",
    "XRD = np.load('XRD.npy',allow_pickle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7ac62a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "id": "0afe601f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2cff843f488>]"
      ]
     },
     "execution_count": 581,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(Q,data_com_xrd[72][3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "d1ba5351",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def creat_Instance_data_Bi_Cu_V(index, q,sample_xrd,comp):\n",
    "    dict_Instance_data_info = {\n",
    "                       'q': q,\n",
    "                       'amp':amp,\n",
    "                       'sample_xrd': sample_xrd, \n",
    "                       'comp': comp                       \n",
    "                      }\n",
    "    dict_connection = {'Instance_data_info': dict_Instance_data_info}\n",
    "    dict_index = {'index': index}  \n",
    "    data_instance = dict( dict_index, **dict_connection)\n",
    "    return data_instance\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    Instance_data_Bi_Cu_V=[]\n",
    "    for i in range(len(composition)):        \n",
    "        index = i\n",
    "        q = Q.tolist()      \n",
    "        sample_xrd = data_com_xrd[i][3:].tolist()\n",
    "        comp = composition[i].tolist()  \n",
    "        json_founc = creat_Instance_data_Bi_Cu_V\n",
    "        data_instance = json_founc(index, q, sample_xrd,comp)         \n",
    "        Instance_data_Bi_Cu_V.append(data_instance)\n",
    "        \n",
    "    Instance_data_Bi_Cu_V = json.dumps(Instance_data_Bi_Cu_V,cls = MontyEncoder)\n",
    "    with open('Instance_data_Bi_Cu_V.json','w+') as file:\n",
    "            file.write(Instance_data_Bi_Cu_V)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "5de49b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load instance data: 307 instance of Bi_Cu_V\n",
    "with open('Instance_data_Bi_Cu_V.json') as f:\n",
    "    Instance_data_Bi_Cu_V = json.load(f, cls=MontyDecoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "d6d1381e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['q', 'amp', 'sample_xrd', 'comp'])"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Instance_data_Bi_Cu_V[2]['Instance_data_info'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "24d391c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InstanceDataBiCuV:\n",
    "    def __init__(self,chemsys, photon_e, log_q,sample_xrd,comp_dict,q_BiCuV):\n",
    "        self.chemsys = chemsys\n",
    "        self.photon_e = photon_e\n",
    "        self.log_q = log_q\n",
    "        self.wavelength = 1e10 * h * c / (photon_e * e)  # in A\n",
    "        self.sample_xrd = sample_xrd\n",
    "        self.comp_dict = comp_dict\n",
    "        self.q = q_BiCuV\n",
    "    @classmethod\n",
    "    def from_file_BiCuV(cls, instancefile, chemsys, photo_e):        \n",
    "        with open(f'{instancefile}.json') as f:\n",
    "            Instance_data_Bi_Cu_V = json.load(f, cls=MontyDecoder)\n",
    "        sample_xrd = [ Instance_data_Bi_Cu_V[i]['Instance_data_info']['sample_xrd'] for i in range(len(Instance_data_Bi_Cu_V))]\n",
    "        comp_dict = {}\n",
    "        comp_dict['Bi'] = np.array([ Instance_data_Bi_Cu_V[i]['Instance_data_info']['comp'][0] for i in range(len(Instance_data_Bi_Cu_V))])\n",
    "        comp_dict['Cu'] = np.array([ Instance_data_Bi_Cu_V[i]['Instance_data_info']['comp'][1] for i in range(len(Instance_data_Bi_Cu_V))])\n",
    "        comp_dict['V'] = np.array([ Instance_data_Bi_Cu_V[i]['Instance_data_info']['comp'][2] for i in range(len(Instance_data_Bi_Cu_V))])        \n",
    "        q_BiCuV = np.array(Instance_data_Bi_Cu_V[0]['Instance_data_info']['q'])\n",
    "        log_q = np.log(q_BiCuV)\n",
    "        return InstanceDataBiCuV(chemsys, photon_e, log_q, np.array(sample_xrd), comp_dict,q_BiCuV)\n",
    "    @property\n",
    "    def qmin(self):\n",
    "        return self.q[0]\n",
    "\n",
    "    @property\n",
    "    def qmax(self):\n",
    "        return self.q[-1]\n",
    "\n",
    "    @property\n",
    "    def sample_comp(self):\n",
    "        comp = np.array([self.comp_dict[el] for el in self.chemsys]).T\n",
    "        comp /= np.sum(comp, axis=1, keepdims=True)\n",
    "        return comp\n",
    "\n",
    "    @property\n",
    "    def dim(self):\n",
    "        return len(self.chemsys)\n",
    "\n",
    "    @property\n",
    "    def sample_num(self):\n",
    "        return self.sample_comp.shape[0]\n",
    "\n",
    "    @property\n",
    "    def twotheta(self):\n",
    "        return np.arcsin(np.array(self.q) / np.pi / 2 / 10 * self.wavelength / 2) / 2 / np.pi * 360 * 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "251eb35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_data = InstanceDataBiCuV.from_file_BiCuV('Instance_data_Bi_Cu_V', chemsys, photon_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608b82b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce61241a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced0d939",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2fa90a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f683b7b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed78cd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "79d96047",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the scattering vector q and intensity from the stick_lib in ICDD \n",
    "qs = []\n",
    "amps=[]\n",
    "for i in range(len(sticks_lib)):\n",
    "    q,amp = list(zip(*(sticks_lib[i])))\n",
    "    qs.append(q)\n",
    "    amps.append(amp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "1f83863c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the samples' name, ICDD entry_id, crystal_system by spliting bases_name,i.e.bases_name[0]:'0+Bi(VO4)_04-010-5710_Tetragonal.txt'\n",
    "names = []\n",
    "entry_ids = []\n",
    "crystal_systems = []\n",
    "bases_name_copy = deepcopy(bases_name)\n",
    "\n",
    "for i in range(len(bases_name_copy)):\n",
    "    list1 = bases_name_copy[i].split('_')\n",
    "    list2 = list1[0].split('+')\n",
    "    list3 = list1[2].split('.')\n",
    "    names.append(list2[1])\n",
    "    entry_ids.append(list1[1])\n",
    "    crystal_systems.append(list3[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d803d9f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# for q,amp in zip(qs,amps):\n",
    "#     plt.plot([q,q],[0,amp],c='C0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "01c050d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def creat_ICDD_entries_Bi_Cu_V(index, q,amp, xrd, comp,base_name,name,entry_id,crystal_system):\n",
    "    dict_entries_info = {\n",
    "                       'q': q,\n",
    "                       'amp':amp,\n",
    "                       'xrd': xrd, \n",
    "                       'comp': comp, \n",
    "                        'base_name':base_name, \n",
    "                        'name':name,\n",
    "                        'entry_id':entry_id,\n",
    "                        'crystal_system':crystal_system\n",
    "                      }\n",
    "    dict_connection = {'entries_info': dict_entries_info}\n",
    "    dict_index = {'index': index}  \n",
    "    data = dict( dict_index, **dict_connection)\n",
    "    return data\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ICDD_entries_Bi_Cu_V=[]\n",
    "    for i in range(len(bases_comp)):        \n",
    "        index = i\n",
    "        q = np.array(qs[i]).tolist()\n",
    "        amp = np.array(amps[i]).tolist()\n",
    "        xrd = sticks_lib[i].tolist()\n",
    "        comp = bases_comp[i].tolist()\n",
    "        base_name = np.array(bases_name[i]).tolist()\n",
    "        name = np.array(names[i]).tolist()\n",
    "        entry_id = np.array(entry_ids[i]).tolist()\n",
    "        crystal_system = np.array(crystal_systems[i]).tolist()\n",
    "        json_founc = creat_ICDD_entries_Bi_Cu_V\n",
    "        data = json_founc(index, q,amp, xrd, comp, base_name,name,entry_id,crystal_system)         \n",
    "        ICDD_entries_Bi_Cu_V.append(data)\n",
    "        \n",
    "    ICDD_entries_Bi_Cu_V = json.dumps(ICDD_entries_Bi_Cu_V)\n",
    "    with open('ICDD_entries_Bi_Cu_V.json','w+') as file:\n",
    "            file.write(ICDD_entries_Bi_Cu_V)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "104fc10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load entry pool: 100 ICDD entries\n",
    "with open('ICDD_entries_Bi_Cu_V.json') as f:\n",
    "    entries_Bi_Cu_V = json.load(f, cls=MontyDecoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacf2da8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "7a5dd913",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymatgen.core import Element, Composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "67076151",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ICDDEntriesBiCuV(ICDDEntry):\n",
    "    def __init__ (self,common_name, composition, data, formula, entry_id, name, q, amp, crystal_system):\n",
    "        self.common_name = common_name\n",
    "        self.comp = composition\n",
    "        self.data = data\n",
    "        self.formula = formula\n",
    "        self.composition = Composition(formula)\n",
    "        self.entry_id = entry_id\n",
    "        self.name = name\n",
    "        self.q = q\n",
    "        self.amp = amp\n",
    "        self.crystal_system = crystal_system\n",
    "    @classmethod\n",
    "    def from_ICDD_Bi_Cu_V(cls, entry):\n",
    "        data = {}\n",
    "        data['xrd'] = [np.array(entry['entries_info']['q']), np.array(entry['entries_info']['amp'])]\n",
    "        return cls(entry['entries_info']['name'],entry['entries_info']['comp'],\n",
    "                   data,entry['entries_info'][ 'name'],\n",
    "                   entry['entries_info']['entry_id'],entry['entries_info']['name'],entry['entries_info']['q'],\n",
    "                   entry['entries_info']['amp'],entry['entries_info']['crystal_system'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "f6d52559",
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = [ICDDEntriesBiCuV.from_ICDD_Bi_Cu_V(en) for en in entries_Bi_Cu_V]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49b501e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('C:\\\\Users\\\\dell\\\\Desktop\\\\phasemapy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f829628f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (dataio.py, line 137)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[0;32m\"C:\\Users\\dell\\anaconda3\\envs\\myPymatgen\\lib\\site-packages\\IPython\\core\\interactiveshell.py\"\u001b[0m, line \u001b[0;32m3457\u001b[0m, in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_79804\\2281874675.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[1;36m, in \u001b[1;35m<module>\u001b[1;36m\u001b[0m\n\u001b[1;33m    from phasemapy.dataio import InstanceData\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\dell\\Desktop\\phasemapy\\phasemapy\\dataio.py\"\u001b[1;36m, line \u001b[1;32m137\u001b[0m\n\u001b[1;33m    return cls(entry['instance_info']['name'],entry['instance_info']['instance_comp'],entry['instance_info']['instance_xrd'],entry['instance_info'][ 'name'],entry['instance_info']['entry_id'],entry['instance_info']['name'],entry['instance_info']['q'],entry['instance_info']['amp'],entry['instance_info']['crystal_system'])\u001b[0m\n\u001b[1;37m                                                                                                                                                                                                                                                                                                                                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "from phasemapy.dataio import InstanceData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189d4294",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "3ac9d2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93fa91b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "0a744ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('C:\\\\Users\\\\dell\\\\Desktop\\\\phasemapy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "29e4abb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymatgen.core import Element\n",
    "from monty.json import MontyDecoder, MontyEncoder\n",
    "from pymatgen.analysis.diffraction.xrd import XRDCalculator\n",
    "import numpy as np\n",
    "from phasemapy.dataio import InstanceData\n",
    "from phasemapy.parser import ICDDEntry\n",
    "from phasemapy.solver import Phase, Sample\n",
    "import matplotlib.pyplot as plt\n",
    "chemsys = ['Bi', 'Cu', 'V']\n",
    "oxide_system = True\n",
    "photon_e = 13e3\n",
    "max_q_shift = 0.05\n",
    "resample_density = 1000\n",
    "initial_alphagamma = 0.1\n",
    "SUM_NORM = 6000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "id": "d20367c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_weight = {'xrd_loss': 6.0, 'comp_loss': 2.0, 'entropy_loss': 0.2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "65000608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 557,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "370a21c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Bi(VO4)\n",
      "1 Bi(VO4)\n",
      "2 Bi(VO4)\n",
      "3 Bi1.62V8O16\n",
      "4 Bi11VO19\n",
      "5 Bi12V2O23\n",
      "6 Bi14V4O30\n",
      "7 Bi14V4O31\n",
      "8 Bi17V3O33\n",
      "9 Bi23V4O44.5\n",
      "10 Bi2O2.3\n",
      "11 Bi2O3\n",
      "12 Bi2O3\n",
      "13 Bi2O3\n",
      "14 Bi2O3\n",
      "15 Bi2O3\n",
      "16 Bi2O3\n",
      "17 Bi2O3\n",
      "18 Bi2O3\n",
      "19 Bi2O3\n",
      "20 Bi2O3\n",
      "21 Bi2O3\n",
      "22 Bi2O3\n",
      "23 Bi2VO5.5\n",
      "24 Bi2VO5.5\n",
      "25 Bi3.5V1.2O8.25\n",
      "26 Bi3V4.2O15.5\n",
      "27 Bi4(V2O11.2)\n",
      "28 Bi4.1Cu0.2V1.7O10.6\n",
      "29 Bi4O7\n",
      "30 Bi4V2O11\n",
      "31 Bi4V3O12\n",
      "32 Bi6O7\n",
      "33 Bi7.38Cu0.62O11.69\n",
      "34 Bi7VO13\n",
      "35 Bi8V2O17\n",
      "36 BiO1.5\n",
      "37 BiO2\n",
      "38 BiV1.025O4\n",
      "39 BiVO4\n",
      "40 Cu0.59V2O5\n",
      "41 Cu0.64V2O5\n",
      "42 Cu1.3V9O22\n",
      "43 Cu1.5V12O29\n",
      "44 Cu1.82V4O11\n",
      "45 Cu1.98(V1.96O6.92)\n",
      "46 Cu11(VO4)6O2\n",
      "47 Cu2(V2O7)\n",
      "48 Cu2(V2O7)\n",
      "49 Cu2(V2O7)\n",
      "50 Cu2(V2O7)\n",
      "51 Cu2O\n",
      "52 Cu2O\n",
      "53 Cu2V2Bi0.95O8\n",
      "54 Cu2VBiO6\n",
      "55 Cu3(VO4)2\n",
      "56 Cu3(VO4)2\n",
      "57 Cu3(VO4)\n",
      "58 Cu3V2Bi4O14\n",
      "59 Cu4V2.15O9.38\n",
      "60 Cu5V2O10\n",
      "61 Cu6.5V6O18.5\n",
      "62 CuBi2O4\n",
      "63 CuO\n",
      "64 CuV2O5\n",
      "65 CuV2O6\n",
      "66 CuV2O6\n",
      "67 CuV2O6\n",
      "68 CuV2O6\n",
      "69 CuVO3\n",
      "70 CuVO3\n",
      "71 CuVO3\n",
      "72 SnO2\n",
      "73 V0.99Bi11.66O20\n",
      "74 V0.9O\n",
      "75 V2Bi4O11\n",
      "76 V2Bi4O11\n",
      "77 V2O3\n",
      "78 V2O3\n",
      "79 V2O3\n",
      "80 V2O5\n",
      "81 V2O5\n",
      "82 V2O5\n",
      "83 V3Bi6O16\n",
      "84 V3O5\n",
      "85 V3O5\n",
      "86 V3O7\n",
      "87 V4O7\n",
      "88 V4O9\n",
      "89 V51.6O64\n",
      "90 V5O9\n",
      "91 V6O13\n",
      "92 V8O15\n",
      "93 V9O17\n",
      "94 VBi2O5.5\n",
      "95 VO2\n",
      "96 VO2\n",
      "97 VO2\n",
      "98 VO2\n",
      "99 VO2\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(entries)):\n",
    "    print(i,entries[i].formula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 950,
   "id": "a6097c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=72\n",
    "solution = []\n",
    "for ent in (entries[38],entries[54],entries[58]):\n",
    "    phase = Phase.from_entry_and_instance_data(ent, 3, instance_data)\n",
    "    solution.append(phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 951,
   "id": "334544fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = Sample(k, instance_data.log_q, instance_data.sample_xrd[k], instance_data.chemsys,\n",
    "                        instance_data.sample_comp[k], oxide_system, instance_data.wavelength, max_q_shift, solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 952,
   "id": "8455d8a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x tensor([[0.3345, 0.2440, 0.4216]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.0746], grad_fn=<NegBackward0>) tensor(1.0746, grad_fn=<MeanBackward0>)\n",
      "loss tensor(7396203.5000, grad_fn=<DivBackward0>) tensor(1.0746, grad_fn=<MeanBackward0>) tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "0 44377220.0 tensor(7396203.5000) tensor(0.0041) tensor(1.0746)\n",
      "x tensor([[0.3472, 0.2260, 0.4268]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.0668], grad_fn=<NegBackward0>) tensor(1.0668, grad_fn=<MeanBackward0>)\n",
      "loss tensor(7097459.5000, grad_fn=<DivBackward0>) tensor(1.0668, grad_fn=<MeanBackward0>) tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.3614, 0.2110, 0.4276]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.0594], grad_fn=<NegBackward0>) tensor(1.0594, grad_fn=<MeanBackward0>)\n",
      "loss tensor(6830492., grad_fn=<DivBackward0>) tensor(1.0594, grad_fn=<MeanBackward0>) tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.3753, 0.1985, 0.4262]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.0523], grad_fn=<NegBackward0>) tensor(1.0523, grad_fn=<MeanBackward0>)\n",
      "loss tensor(6599220., grad_fn=<DivBackward0>) tensor(1.0523, grad_fn=<MeanBackward0>) tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.3890, 0.1858, 0.4253]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.0436], grad_fn=<NegBackward0>) tensor(1.0436, grad_fn=<MeanBackward0>)\n",
      "loss tensor(6390213., grad_fn=<DivBackward0>) tensor(1.0436, grad_fn=<MeanBackward0>) tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4022, 0.1731, 0.4247]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.0336], grad_fn=<NegBackward0>) tensor(1.0336, grad_fn=<MeanBackward0>)\n",
      "loss tensor(6202568.5000, grad_fn=<DivBackward0>) tensor(1.0336, grad_fn=<MeanBackward0>) tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4149, 0.1619, 0.4231]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.0237], grad_fn=<NegBackward0>) tensor(1.0237, grad_fn=<MeanBackward0>)\n",
      "loss tensor(6044340., grad_fn=<DivBackward0>) tensor(1.0237, grad_fn=<MeanBackward0>) tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4264, 0.1523, 0.4213]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.0142], grad_fn=<NegBackward0>) tensor(1.0142, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5915763., grad_fn=<DivBackward0>) tensor(1.0142, grad_fn=<MeanBackward0>) tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4377, 0.1424, 0.4199]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.0035], grad_fn=<NegBackward0>) tensor(1.0035, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5800646.5000, grad_fn=<DivBackward0>) tensor(1.0035, grad_fn=<MeanBackward0>) tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4499, 0.1320, 0.4181]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9912], grad_fn=<NegBackward0>) tensor(0.9912, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5699134.5000, grad_fn=<DivBackward0>) tensor(0.9912, grad_fn=<MeanBackward0>) tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4612, 0.1230, 0.4158]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9796], grad_fn=<NegBackward0>) tensor(0.9796, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5608888., grad_fn=<DivBackward0>) tensor(0.9796, grad_fn=<MeanBackward0>) tensor(0.0229, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4719, 0.1148, 0.4133]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9680], grad_fn=<NegBackward0>) tensor(0.9680, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5528033., grad_fn=<DivBackward0>) tensor(0.9680, grad_fn=<MeanBackward0>) tensor(0.0250, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4822, 0.1080, 0.4098]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9576], grad_fn=<NegBackward0>) tensor(0.9576, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5459601.5000, grad_fn=<DivBackward0>) tensor(0.9576, grad_fn=<MeanBackward0>) tensor(0.0269, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4925, 0.1015, 0.4060]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9469], grad_fn=<NegBackward0>) tensor(0.9469, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5404595.5000, grad_fn=<DivBackward0>) tensor(0.9469, grad_fn=<MeanBackward0>) tensor(0.0288, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.5026, 0.0957, 0.4017]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9366], grad_fn=<NegBackward0>) tensor(0.9366, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5361142., grad_fn=<DivBackward0>) tensor(0.9366, grad_fn=<MeanBackward0>) tensor(0.0307, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.5115, 0.0914, 0.3971]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9284], grad_fn=<NegBackward0>) tensor(0.9284, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5328383.5000, grad_fn=<DivBackward0>) tensor(0.9284, grad_fn=<MeanBackward0>) tensor(0.0322, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.5188, 0.0874, 0.3938]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9205], grad_fn=<NegBackward0>) tensor(0.9205, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5301127.5000, grad_fn=<DivBackward0>) tensor(0.9205, grad_fn=<MeanBackward0>) tensor(0.0336, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.5240, 0.0834, 0.3926]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9129], grad_fn=<NegBackward0>) tensor(0.9129, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5278517.5000, grad_fn=<DivBackward0>) tensor(0.9129, grad_fn=<MeanBackward0>) tensor(0.0347, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.5288, 0.0796, 0.3916]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9054], grad_fn=<NegBackward0>) tensor(0.9054, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5258209.5000, grad_fn=<DivBackward0>) tensor(0.9054, grad_fn=<MeanBackward0>) tensor(0.0358, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.5312, 0.0760, 0.3928]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.8990], grad_fn=<NegBackward0>) tensor(0.8990, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5240887.5000, grad_fn=<DivBackward0>) tensor(0.8990, grad_fn=<MeanBackward0>) tensor(0.0366, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.5314, 0.0745, 0.3942]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.8963], grad_fn=<NegBackward0>) tensor(0.8963, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5226034.5000, grad_fn=<DivBackward0>) tensor(0.8963, grad_fn=<MeanBackward0>) tensor(0.0368, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.5303, 0.0737, 0.3960]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.8954], grad_fn=<NegBackward0>) tensor(0.8954, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5212288., grad_fn=<DivBackward0>) tensor(0.8954, grad_fn=<MeanBackward0>) tensor(0.0368, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.5289, 0.0735, 0.3976]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.8954], grad_fn=<NegBackward0>) tensor(0.8954, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5200144.5000, grad_fn=<DivBackward0>) tensor(0.8954, grad_fn=<MeanBackward0>) tensor(0.0367, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.5266, 0.0737, 0.3997]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.8965], grad_fn=<NegBackward0>) tensor(0.8965, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5188478., grad_fn=<DivBackward0>) tensor(0.8965, grad_fn=<MeanBackward0>) tensor(0.0363, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.5234, 0.0744, 0.4022]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.8985], grad_fn=<NegBackward0>) tensor(0.8985, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5177336., grad_fn=<DivBackward0>) tensor(0.8985, grad_fn=<MeanBackward0>) tensor(0.0359, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.5197, 0.0755, 0.4048]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9014], grad_fn=<NegBackward0>) tensor(0.9014, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5166791.5000, grad_fn=<DivBackward0>) tensor(0.9014, grad_fn=<MeanBackward0>) tensor(0.0353, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.5157, 0.0771, 0.4072]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9049], grad_fn=<NegBackward0>) tensor(0.9049, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5156920.5000, grad_fn=<DivBackward0>) tensor(0.9049, grad_fn=<MeanBackward0>) tensor(0.0346, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.5119, 0.0787, 0.4094]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9085], grad_fn=<NegBackward0>) tensor(0.9085, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5148071.5000, grad_fn=<DivBackward0>) tensor(0.9085, grad_fn=<MeanBackward0>) tensor(0.0339, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.5089, 0.0800, 0.4111]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9112], grad_fn=<NegBackward0>) tensor(0.9112, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5140399., grad_fn=<DivBackward0>) tensor(0.9112, grad_fn=<MeanBackward0>) tensor(0.0334, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.5061, 0.0814, 0.4125]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9141], grad_fn=<NegBackward0>) tensor(0.9141, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5133263.5000, grad_fn=<DivBackward0>) tensor(0.9141, grad_fn=<MeanBackward0>) tensor(0.0329, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.5033, 0.0829, 0.4138]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9171], grad_fn=<NegBackward0>) tensor(0.9171, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5126655., grad_fn=<DivBackward0>) tensor(0.9171, grad_fn=<MeanBackward0>) tensor(0.0324, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.5015, 0.0842, 0.4143]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9195], grad_fn=<NegBackward0>) tensor(0.9195, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5120739.5000, grad_fn=<DivBackward0>) tensor(0.9195, grad_fn=<MeanBackward0>) tensor(0.0320, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4998, 0.0853, 0.4149]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9216], grad_fn=<NegBackward0>) tensor(0.9216, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5115230., grad_fn=<DivBackward0>) tensor(0.9216, grad_fn=<MeanBackward0>) tensor(0.0317, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4979, 0.0864, 0.4157]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9236], grad_fn=<NegBackward0>) tensor(0.9236, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5108034.5000, grad_fn=<DivBackward0>) tensor(0.9236, grad_fn=<MeanBackward0>) tensor(0.0313, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4958, 0.0872, 0.4170]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9253], grad_fn=<NegBackward0>) tensor(0.9253, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5101166.5000, grad_fn=<DivBackward0>) tensor(0.9253, grad_fn=<MeanBackward0>) tensor(0.0310, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4936, 0.0879, 0.4185]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9268], grad_fn=<NegBackward0>) tensor(0.9268, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5094537., grad_fn=<DivBackward0>) tensor(0.9268, grad_fn=<MeanBackward0>) tensor(0.0306, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4915, 0.0884, 0.4200]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9279], grad_fn=<NegBackward0>) tensor(0.9279, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5088152.5000, grad_fn=<DivBackward0>) tensor(0.9279, grad_fn=<MeanBackward0>) tensor(0.0303, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4896, 0.0888, 0.4216]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9288], grad_fn=<NegBackward0>) tensor(0.9288, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5082103.5000, grad_fn=<DivBackward0>) tensor(0.9288, grad_fn=<MeanBackward0>) tensor(0.0301, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4880, 0.0890, 0.4231]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9293], grad_fn=<NegBackward0>) tensor(0.9293, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5076368.5000, grad_fn=<DivBackward0>) tensor(0.9293, grad_fn=<MeanBackward0>) tensor(0.0298, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4866, 0.0890, 0.4245]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9295], grad_fn=<NegBackward0>) tensor(0.9295, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5070946., grad_fn=<DivBackward0>) tensor(0.9295, grad_fn=<MeanBackward0>) tensor(0.0297, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4855, 0.0888, 0.4257]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9294], grad_fn=<NegBackward0>) tensor(0.9294, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5065846., grad_fn=<DivBackward0>) tensor(0.9294, grad_fn=<MeanBackward0>) tensor(0.0296, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4849, 0.0885, 0.4266]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9289], grad_fn=<NegBackward0>) tensor(0.9289, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5061077., grad_fn=<DivBackward0>) tensor(0.9289, grad_fn=<MeanBackward0>) tensor(0.0296, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4847, 0.0884, 0.4269]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9288], grad_fn=<NegBackward0>) tensor(0.9288, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5056810.5000, grad_fn=<DivBackward0>) tensor(0.9288, grad_fn=<MeanBackward0>) tensor(0.0295, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4846, 0.0886, 0.4268]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9292], grad_fn=<NegBackward0>) tensor(0.9292, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5053062., grad_fn=<DivBackward0>) tensor(0.9292, grad_fn=<MeanBackward0>) tensor(0.0295, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4848, 0.0887, 0.4265]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9293], grad_fn=<NegBackward0>) tensor(0.9293, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5049727., grad_fn=<DivBackward0>) tensor(0.9293, grad_fn=<MeanBackward0>) tensor(0.0295, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4853, 0.0887, 0.4260]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9293], grad_fn=<NegBackward0>) tensor(0.9293, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5046810., grad_fn=<DivBackward0>) tensor(0.9293, grad_fn=<MeanBackward0>) tensor(0.0296, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4861, 0.0887, 0.4253]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9291], grad_fn=<NegBackward0>) tensor(0.9291, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5044286.5000, grad_fn=<DivBackward0>) tensor(0.9291, grad_fn=<MeanBackward0>) tensor(0.0297, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4870, 0.0885, 0.4245]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9287], grad_fn=<NegBackward0>) tensor(0.9287, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5042132., grad_fn=<DivBackward0>) tensor(0.9287, grad_fn=<MeanBackward0>) tensor(0.0298, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4881, 0.0882, 0.4236]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9281], grad_fn=<NegBackward0>) tensor(0.9281, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5040308., grad_fn=<DivBackward0>) tensor(0.9281, grad_fn=<MeanBackward0>) tensor(0.0300, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4894, 0.0879, 0.4228]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9274], grad_fn=<NegBackward0>) tensor(0.9274, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5038772., grad_fn=<DivBackward0>) tensor(0.9274, grad_fn=<MeanBackward0>) tensor(0.0301, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4906, 0.0874, 0.4219]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9265], grad_fn=<NegBackward0>) tensor(0.9265, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5037485.5000, grad_fn=<DivBackward0>) tensor(0.9265, grad_fn=<MeanBackward0>) tensor(0.0303, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4914, 0.0868, 0.4218]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9255], grad_fn=<NegBackward0>) tensor(0.9255, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5036381.5000, grad_fn=<DivBackward0>) tensor(0.9255, grad_fn=<MeanBackward0>) tensor(0.0305, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4921, 0.0862, 0.4218]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9243], grad_fn=<NegBackward0>) tensor(0.9243, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5035386.5000, grad_fn=<DivBackward0>) tensor(0.9243, grad_fn=<MeanBackward0>) tensor(0.0307, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4927, 0.0855, 0.4218]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9232], grad_fn=<NegBackward0>) tensor(0.9232, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5034494.5000, grad_fn=<DivBackward0>) tensor(0.9232, grad_fn=<MeanBackward0>) tensor(0.0308, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4934, 0.0849, 0.4217]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9221], grad_fn=<NegBackward0>) tensor(0.9221, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5033703.5000, grad_fn=<DivBackward0>) tensor(0.9221, grad_fn=<MeanBackward0>) tensor(0.0310, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4941, 0.0843, 0.4217]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9210], grad_fn=<NegBackward0>) tensor(0.9210, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5033019., grad_fn=<DivBackward0>) tensor(0.9210, grad_fn=<MeanBackward0>) tensor(0.0311, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4948, 0.0837, 0.4215]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9199], grad_fn=<NegBackward0>) tensor(0.9199, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5032431.5000, grad_fn=<DivBackward0>) tensor(0.9199, grad_fn=<MeanBackward0>) tensor(0.0313, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4957, 0.0831, 0.4212]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9189], grad_fn=<NegBackward0>) tensor(0.9189, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5031951., grad_fn=<DivBackward0>) tensor(0.9189, grad_fn=<MeanBackward0>) tensor(0.0315, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4965, 0.0827, 0.4208]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9180], grad_fn=<NegBackward0>) tensor(0.9180, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5031578.5000, grad_fn=<DivBackward0>) tensor(0.9180, grad_fn=<MeanBackward0>) tensor(0.0316, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4973, 0.0823, 0.4204]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9173], grad_fn=<NegBackward0>) tensor(0.9173, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss tensor(5031298., grad_fn=<DivBackward0>) tensor(0.9173, grad_fn=<MeanBackward0>) tensor(0.0318, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4980, 0.0821, 0.4198]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9169], grad_fn=<NegBackward0>) tensor(0.9169, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5031080., grad_fn=<DivBackward0>) tensor(0.9169, grad_fn=<MeanBackward0>) tensor(0.0319, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4986, 0.0821, 0.4192]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9167], grad_fn=<NegBackward0>) tensor(0.9167, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5030896., grad_fn=<DivBackward0>) tensor(0.9167, grad_fn=<MeanBackward0>) tensor(0.0319, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4991, 0.0822, 0.4187]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9168], grad_fn=<NegBackward0>) tensor(0.9168, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5030800., grad_fn=<DivBackward0>) tensor(0.9168, grad_fn=<MeanBackward0>) tensor(0.0320, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4996, 0.0825, 0.4179]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9171], grad_fn=<NegBackward0>) tensor(0.9171, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5030537., grad_fn=<DivBackward0>) tensor(0.9171, grad_fn=<MeanBackward0>) tensor(0.0320, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4999, 0.0829, 0.4172]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9177], grad_fn=<NegBackward0>) tensor(0.9177, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5030340.5000, grad_fn=<DivBackward0>) tensor(0.9177, grad_fn=<MeanBackward0>) tensor(0.0320, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.5001, 0.0834, 0.4165]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9185], grad_fn=<NegBackward0>) tensor(0.9185, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5030130., grad_fn=<DivBackward0>) tensor(0.9185, grad_fn=<MeanBackward0>) tensor(0.0319, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.5002, 0.0840, 0.4158]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9194], grad_fn=<NegBackward0>) tensor(0.9194, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5029915.5000, grad_fn=<DivBackward0>) tensor(0.9194, grad_fn=<MeanBackward0>) tensor(0.0319, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.5002, 0.0846, 0.4151]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9204], grad_fn=<NegBackward0>) tensor(0.9204, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5029707.5000, grad_fn=<DivBackward0>) tensor(0.9204, grad_fn=<MeanBackward0>) tensor(0.0318, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.5002, 0.0853, 0.4145]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9215], grad_fn=<NegBackward0>) tensor(0.9215, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5029515., grad_fn=<DivBackward0>) tensor(0.9215, grad_fn=<MeanBackward0>) tensor(0.0317, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.5002, 0.0860, 0.4138]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9226], grad_fn=<NegBackward0>) tensor(0.9226, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5029335.5000, grad_fn=<DivBackward0>) tensor(0.9226, grad_fn=<MeanBackward0>) tensor(0.0316, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.5002, 0.0866, 0.4132]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9235], grad_fn=<NegBackward0>) tensor(0.9235, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5029166., grad_fn=<DivBackward0>) tensor(0.9235, grad_fn=<MeanBackward0>) tensor(0.0315, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.5002, 0.0871, 0.4126]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9244], grad_fn=<NegBackward0>) tensor(0.9244, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5029002., grad_fn=<DivBackward0>) tensor(0.9244, grad_fn=<MeanBackward0>) tensor(0.0315, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.5002, 0.0876, 0.4121]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9252], grad_fn=<NegBackward0>) tensor(0.9252, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5028842., grad_fn=<DivBackward0>) tensor(0.9252, grad_fn=<MeanBackward0>) tensor(0.0314, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.5003, 0.0880, 0.4117]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9257], grad_fn=<NegBackward0>) tensor(0.9257, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5028682., grad_fn=<DivBackward0>) tensor(0.9257, grad_fn=<MeanBackward0>) tensor(0.0314, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.5003, 0.0883, 0.4114]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9262], grad_fn=<NegBackward0>) tensor(0.9262, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5028525.5000, grad_fn=<DivBackward0>) tensor(0.9262, grad_fn=<MeanBackward0>) tensor(0.0313, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.5003, 0.0885, 0.4112]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9264], grad_fn=<NegBackward0>) tensor(0.9264, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5028372.5000, grad_fn=<DivBackward0>) tensor(0.9264, grad_fn=<MeanBackward0>) tensor(0.0313, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.5003, 0.0886, 0.4111]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9266], grad_fn=<NegBackward0>) tensor(0.9266, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5028225., grad_fn=<DivBackward0>) tensor(0.9266, grad_fn=<MeanBackward0>) tensor(0.0313, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.5002, 0.0885, 0.4112]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9266], grad_fn=<NegBackward0>) tensor(0.9266, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5028084., grad_fn=<DivBackward0>) tensor(0.9266, grad_fn=<MeanBackward0>) tensor(0.0313, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.5001, 0.0885, 0.4114]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9265], grad_fn=<NegBackward0>) tensor(0.9265, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5027953.5000, grad_fn=<DivBackward0>) tensor(0.9265, grad_fn=<MeanBackward0>) tensor(0.0313, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.5000, 0.0883, 0.4117]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9263], grad_fn=<NegBackward0>) tensor(0.9263, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5027826.5000, grad_fn=<DivBackward0>) tensor(0.9263, grad_fn=<MeanBackward0>) tensor(0.0313, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4998, 0.0881, 0.4121]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9260], grad_fn=<NegBackward0>) tensor(0.9260, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5027707., grad_fn=<DivBackward0>) tensor(0.9260, grad_fn=<MeanBackward0>) tensor(0.0313, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4996, 0.0878, 0.4126]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9256], grad_fn=<NegBackward0>) tensor(0.9256, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5027595., grad_fn=<DivBackward0>) tensor(0.9256, grad_fn=<MeanBackward0>) tensor(0.0313, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4994, 0.0876, 0.4130]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9252], grad_fn=<NegBackward0>) tensor(0.9252, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5027485., grad_fn=<DivBackward0>) tensor(0.9252, grad_fn=<MeanBackward0>) tensor(0.0313, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4993, 0.0873, 0.4134]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9248], grad_fn=<NegBackward0>) tensor(0.9248, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5027378., grad_fn=<DivBackward0>) tensor(0.9248, grad_fn=<MeanBackward0>) tensor(0.0313, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4992, 0.0870, 0.4138]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9243], grad_fn=<NegBackward0>) tensor(0.9243, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5027277.5000, grad_fn=<DivBackward0>) tensor(0.9243, grad_fn=<MeanBackward0>) tensor(0.0314, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4992, 0.0867, 0.4141]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9239], grad_fn=<NegBackward0>) tensor(0.9239, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5027182., grad_fn=<DivBackward0>) tensor(0.9239, grad_fn=<MeanBackward0>) tensor(0.0314, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4993, 0.0864, 0.4143]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9234], grad_fn=<NegBackward0>) tensor(0.9234, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5027093.5000, grad_fn=<DivBackward0>) tensor(0.9234, grad_fn=<MeanBackward0>) tensor(0.0315, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4994, 0.0861, 0.4145]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9230], grad_fn=<NegBackward0>) tensor(0.9230, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5027012.5000, grad_fn=<DivBackward0>) tensor(0.9230, grad_fn=<MeanBackward0>) tensor(0.0315, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4995, 0.0859, 0.4146]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9227], grad_fn=<NegBackward0>) tensor(0.9227, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5026875.5000, grad_fn=<DivBackward0>) tensor(0.9227, grad_fn=<MeanBackward0>) tensor(0.0315, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4989, 0.0871, 0.4140]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9246], grad_fn=<NegBackward0>) tensor(0.9246, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5025298.5000, grad_fn=<DivBackward0>) tensor(0.9246, grad_fn=<MeanBackward0>) tensor(0.0313, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4981, 0.0887, 0.4132]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9273], grad_fn=<NegBackward0>) tensor(0.9273, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5023280.5000, grad_fn=<DivBackward0>) tensor(0.9273, grad_fn=<MeanBackward0>) tensor(0.0310, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4971, 0.0907, 0.4122]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9304], grad_fn=<NegBackward0>) tensor(0.9304, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5021096., grad_fn=<DivBackward0>) tensor(0.9304, grad_fn=<MeanBackward0>) tensor(0.0307, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4961, 0.0928, 0.4112]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9338], grad_fn=<NegBackward0>) tensor(0.9338, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5018909., grad_fn=<DivBackward0>) tensor(0.9338, grad_fn=<MeanBackward0>) tensor(0.0303, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x tensor([[0.4951, 0.0949, 0.4100]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9371], grad_fn=<NegBackward0>) tensor(0.9371, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5016800.5000, grad_fn=<DivBackward0>) tensor(0.9371, grad_fn=<MeanBackward0>) tensor(0.0299, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4941, 0.0970, 0.4089]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9403], grad_fn=<NegBackward0>) tensor(0.9403, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5014807., grad_fn=<DivBackward0>) tensor(0.9403, grad_fn=<MeanBackward0>) tensor(0.0295, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4932, 0.0989, 0.4079]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9432], grad_fn=<NegBackward0>) tensor(0.9432, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5012933., grad_fn=<DivBackward0>) tensor(0.9432, grad_fn=<MeanBackward0>) tensor(0.0292, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4924, 0.1007, 0.4069]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9459], grad_fn=<NegBackward0>) tensor(0.9459, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5011153.5000, grad_fn=<DivBackward0>) tensor(0.9459, grad_fn=<MeanBackward0>) tensor(0.0289, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4917, 0.1022, 0.4061]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9482], grad_fn=<NegBackward0>) tensor(0.9482, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5009443.5000, grad_fn=<DivBackward0>) tensor(0.9482, grad_fn=<MeanBackward0>) tensor(0.0286, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4911, 0.1036, 0.4054]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9501], grad_fn=<NegBackward0>) tensor(0.9501, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5007770., grad_fn=<DivBackward0>) tensor(0.9501, grad_fn=<MeanBackward0>) tensor(0.0284, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4905, 0.1046, 0.4048]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9517], grad_fn=<NegBackward0>) tensor(0.9517, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5006112.5000, grad_fn=<DivBackward0>) tensor(0.9517, grad_fn=<MeanBackward0>) tensor(0.0282, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4900, 0.1056, 0.4044]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9531], grad_fn=<NegBackward0>) tensor(0.9531, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5004293.5000, grad_fn=<DivBackward0>) tensor(0.9531, grad_fn=<MeanBackward0>) tensor(0.0280, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4886, 0.1080, 0.4034]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9565], grad_fn=<NegBackward0>) tensor(0.9565, grad_fn=<MeanBackward0>)\n",
      "loss tensor(5000849., grad_fn=<DivBackward0>) tensor(0.9565, grad_fn=<MeanBackward0>) tensor(0.0276, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4871, 0.1105, 0.4024]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9601], grad_fn=<NegBackward0>) tensor(0.9601, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4997768.5000, grad_fn=<DivBackward0>) tensor(0.9601, grad_fn=<MeanBackward0>) tensor(0.0271, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4860, 0.1128, 0.4012]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9633], grad_fn=<NegBackward0>) tensor(0.9633, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4995497.5000, grad_fn=<DivBackward0>) tensor(0.9633, grad_fn=<MeanBackward0>) tensor(0.0267, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4854, 0.1145, 0.4001]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9656], grad_fn=<NegBackward0>) tensor(0.9656, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4993958.5000, grad_fn=<DivBackward0>) tensor(0.9656, grad_fn=<MeanBackward0>) tensor(0.0264, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4855, 0.1154, 0.3991]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9666], grad_fn=<NegBackward0>) tensor(0.9666, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4992675.5000, grad_fn=<DivBackward0>) tensor(0.9666, grad_fn=<MeanBackward0>) tensor(0.0264, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4864, 0.1153, 0.3983]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9663], grad_fn=<NegBackward0>) tensor(0.9663, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4991215., grad_fn=<DivBackward0>) tensor(0.9663, grad_fn=<MeanBackward0>) tensor(0.0265, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4876, 0.1145, 0.3979]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9650], grad_fn=<NegBackward0>) tensor(0.9650, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4989514., grad_fn=<DivBackward0>) tensor(0.9650, grad_fn=<MeanBackward0>) tensor(0.0267, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4890, 0.1130, 0.3979]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9629], grad_fn=<NegBackward0>) tensor(0.9629, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4987789.5000, grad_fn=<DivBackward0>) tensor(0.9629, grad_fn=<MeanBackward0>) tensor(0.0270, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4902, 0.1113, 0.3985]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9605], grad_fn=<NegBackward0>) tensor(0.9605, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4986284., grad_fn=<DivBackward0>) tensor(0.9605, grad_fn=<MeanBackward0>) tensor(0.0273, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4909, 0.1096, 0.3994]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9582], grad_fn=<NegBackward0>) tensor(0.9582, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4985191., grad_fn=<DivBackward0>) tensor(0.9582, grad_fn=<MeanBackward0>) tensor(0.0276, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4912, 0.1081, 0.4008]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9561], grad_fn=<NegBackward0>) tensor(0.9561, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4984352., grad_fn=<DivBackward0>) tensor(0.9561, grad_fn=<MeanBackward0>) tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4908, 0.1069, 0.4023]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9546], grad_fn=<NegBackward0>) tensor(0.9546, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4983788.5000, grad_fn=<DivBackward0>) tensor(0.9546, grad_fn=<MeanBackward0>) tensor(0.0279, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4900, 0.1062, 0.4038]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9539], grad_fn=<NegBackward0>) tensor(0.9539, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4983257.5000, grad_fn=<DivBackward0>) tensor(0.9539, grad_fn=<MeanBackward0>) tensor(0.0279, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4888, 0.1061, 0.4051]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9540], grad_fn=<NegBackward0>) tensor(0.9540, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4982629.5000, grad_fn=<DivBackward0>) tensor(0.9540, grad_fn=<MeanBackward0>) tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4875, 0.1065, 0.4060]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9547], grad_fn=<NegBackward0>) tensor(0.9547, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4981896.5000, grad_fn=<DivBackward0>) tensor(0.9547, grad_fn=<MeanBackward0>) tensor(0.0276, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4864, 0.1072, 0.4064]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9559], grad_fn=<NegBackward0>) tensor(0.9559, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4981151., grad_fn=<DivBackward0>) tensor(0.9559, grad_fn=<MeanBackward0>) tensor(0.0274, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4855, 0.1082, 0.4063]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9574], grad_fn=<NegBackward0>) tensor(0.9574, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4980487.5000, grad_fn=<DivBackward0>) tensor(0.9574, grad_fn=<MeanBackward0>) tensor(0.0272, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4850, 0.1093, 0.4057]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9588], grad_fn=<NegBackward0>) tensor(0.9588, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4979954., grad_fn=<DivBackward0>) tensor(0.9588, grad_fn=<MeanBackward0>) tensor(0.0270, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4849, 0.1103, 0.4048]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9602], grad_fn=<NegBackward0>) tensor(0.9602, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4979541., grad_fn=<DivBackward0>) tensor(0.9602, grad_fn=<MeanBackward0>) tensor(0.0269, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4851, 0.1112, 0.4038]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9613], grad_fn=<NegBackward0>) tensor(0.9613, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4979200.5000, grad_fn=<DivBackward0>) tensor(0.9613, grad_fn=<MeanBackward0>) tensor(0.0268, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4854, 0.1119, 0.4027]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9622], grad_fn=<NegBackward0>) tensor(0.9622, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4978875., grad_fn=<DivBackward0>) tensor(0.9622, grad_fn=<MeanBackward0>) tensor(0.0268, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4856, 0.1125, 0.4019]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9629], grad_fn=<NegBackward0>) tensor(0.9629, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4978552., grad_fn=<DivBackward0>) tensor(0.9629, grad_fn=<MeanBackward0>) tensor(0.0267, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4854, 0.1136, 0.4010]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9644], grad_fn=<NegBackward0>) tensor(0.9644, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4978324., grad_fn=<DivBackward0>) tensor(0.9644, grad_fn=<MeanBackward0>) tensor(0.0265, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4858, 0.1143, 0.3999]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9652], grad_fn=<NegBackward0>) tensor(0.9652, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4977515., grad_fn=<DivBackward0>) tensor(0.9652, grad_fn=<MeanBackward0>) tensor(0.0265, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4863, 0.1147, 0.3991]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9655], grad_fn=<NegBackward0>) tensor(0.9655, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4976689.5000, grad_fn=<DivBackward0>) tensor(0.9655, grad_fn=<MeanBackward0>) tensor(0.0265, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4866, 0.1148, 0.3986]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9657], grad_fn=<NegBackward0>) tensor(0.9657, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4975970.5000, grad_fn=<DivBackward0>) tensor(0.9657, grad_fn=<MeanBackward0>) tensor(0.0265, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4867, 0.1149, 0.3984]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9657], grad_fn=<NegBackward0>) tensor(0.9657, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4975369.5000, grad_fn=<DivBackward0>) tensor(0.9657, grad_fn=<MeanBackward0>) tensor(0.0265, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4866, 0.1149, 0.3985]], grad_fn=<SumBackward1>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entropy tensor([0.9657], grad_fn=<NegBackward0>) tensor(0.9657, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4974847.5000, grad_fn=<DivBackward0>) tensor(0.9657, grad_fn=<MeanBackward0>) tensor(0.0265, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4862, 0.1148, 0.3989]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9657], grad_fn=<NegBackward0>) tensor(0.9657, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4974380., grad_fn=<DivBackward0>) tensor(0.9657, grad_fn=<MeanBackward0>) tensor(0.0265, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4857, 0.1148, 0.3995]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9658], grad_fn=<NegBackward0>) tensor(0.9658, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4973975., grad_fn=<DivBackward0>) tensor(0.9658, grad_fn=<MeanBackward0>) tensor(0.0265, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4851, 0.1148, 0.4000]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9659], grad_fn=<NegBackward0>) tensor(0.9659, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4973627.5000, grad_fn=<DivBackward0>) tensor(0.9659, grad_fn=<MeanBackward0>) tensor(0.0264, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4846, 0.1149, 0.4005]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9661], grad_fn=<NegBackward0>) tensor(0.9661, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4973342., grad_fn=<DivBackward0>) tensor(0.9661, grad_fn=<MeanBackward0>) tensor(0.0263, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4841, 0.1150, 0.4009]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9664], grad_fn=<NegBackward0>) tensor(0.9664, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4973111.5000, grad_fn=<DivBackward0>) tensor(0.9664, grad_fn=<MeanBackward0>) tensor(0.0262, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4837, 0.1152, 0.4011]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9666], grad_fn=<NegBackward0>) tensor(0.9666, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4972908., grad_fn=<DivBackward0>) tensor(0.9666, grad_fn=<MeanBackward0>) tensor(0.0262, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4835, 0.1153, 0.4012]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9669], grad_fn=<NegBackward0>) tensor(0.9669, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4972700., grad_fn=<DivBackward0>) tensor(0.9669, grad_fn=<MeanBackward0>) tensor(0.0261, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4834, 0.1155, 0.4011]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9671], grad_fn=<NegBackward0>) tensor(0.9671, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4972470., grad_fn=<DivBackward0>) tensor(0.9671, grad_fn=<MeanBackward0>) tensor(0.0261, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4832, 0.1156, 0.4012]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9673], grad_fn=<NegBackward0>) tensor(0.9673, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4972229.5000, grad_fn=<DivBackward0>) tensor(0.9673, grad_fn=<MeanBackward0>) tensor(0.0261, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4830, 0.1157, 0.4013]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9674], grad_fn=<NegBackward0>) tensor(0.9674, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4971973.5000, grad_fn=<DivBackward0>) tensor(0.9674, grad_fn=<MeanBackward0>) tensor(0.0261, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4829, 0.1157, 0.4014]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9674], grad_fn=<NegBackward0>) tensor(0.9674, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4971722.5000, grad_fn=<DivBackward0>) tensor(0.9674, grad_fn=<MeanBackward0>) tensor(0.0260, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4828, 0.1156, 0.4016]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9673], grad_fn=<NegBackward0>) tensor(0.9673, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4971501., grad_fn=<DivBackward0>) tensor(0.9673, grad_fn=<MeanBackward0>) tensor(0.0260, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4828, 0.1154, 0.4018]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9672], grad_fn=<NegBackward0>) tensor(0.9672, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4971323., grad_fn=<DivBackward0>) tensor(0.9672, grad_fn=<MeanBackward0>) tensor(0.0261, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4827, 0.1152, 0.4020]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9669], grad_fn=<NegBackward0>) tensor(0.9669, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4971186., grad_fn=<DivBackward0>) tensor(0.9669, grad_fn=<MeanBackward0>) tensor(0.0261, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4827, 0.1150, 0.4023]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9666], grad_fn=<NegBackward0>) tensor(0.9666, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4971074., grad_fn=<DivBackward0>) tensor(0.9666, grad_fn=<MeanBackward0>) tensor(0.0261, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4827, 0.1147, 0.4026]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9663], grad_fn=<NegBackward0>) tensor(0.9663, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4970969., grad_fn=<DivBackward0>) tensor(0.9663, grad_fn=<MeanBackward0>) tensor(0.0261, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4827, 0.1144, 0.4029]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9659], grad_fn=<NegBackward0>) tensor(0.9659, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4970857.5000, grad_fn=<DivBackward0>) tensor(0.9659, grad_fn=<MeanBackward0>) tensor(0.0262, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4831, 0.1140, 0.4029]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9654], grad_fn=<NegBackward0>) tensor(0.9654, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4970813., grad_fn=<DivBackward0>) tensor(0.9654, grad_fn=<MeanBackward0>) tensor(0.0263, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4835, 0.1137, 0.4028]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9648], grad_fn=<NegBackward0>) tensor(0.9648, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4970760.5000, grad_fn=<DivBackward0>) tensor(0.9648, grad_fn=<MeanBackward0>) tensor(0.0263, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4839, 0.1134, 0.4027]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9644], grad_fn=<NegBackward0>) tensor(0.9644, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4970702., grad_fn=<DivBackward0>) tensor(0.9644, grad_fn=<MeanBackward0>) tensor(0.0264, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4843, 0.1132, 0.4025]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9640], grad_fn=<NegBackward0>) tensor(0.9640, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4970648., grad_fn=<DivBackward0>) tensor(0.9640, grad_fn=<MeanBackward0>) tensor(0.0265, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4846, 0.1130, 0.4024]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9638], grad_fn=<NegBackward0>) tensor(0.9638, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4970601., grad_fn=<DivBackward0>) tensor(0.9638, grad_fn=<MeanBackward0>) tensor(0.0265, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4848, 0.1129, 0.4023]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9636], grad_fn=<NegBackward0>) tensor(0.9636, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4970570., grad_fn=<DivBackward0>) tensor(0.9636, grad_fn=<MeanBackward0>) tensor(0.0266, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4851, 0.1128, 0.4021]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9634], grad_fn=<NegBackward0>) tensor(0.9634, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4970548., grad_fn=<DivBackward0>) tensor(0.9634, grad_fn=<MeanBackward0>) tensor(0.0266, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4853, 0.1128, 0.4019]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9633], grad_fn=<NegBackward0>) tensor(0.9633, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4970538.5000, grad_fn=<DivBackward0>) tensor(0.9633, grad_fn=<MeanBackward0>) tensor(0.0266, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4855, 0.1127, 0.4017]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9632], grad_fn=<NegBackward0>) tensor(0.9632, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4970534., grad_fn=<DivBackward0>) tensor(0.9632, grad_fn=<MeanBackward0>) tensor(0.0267, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4858, 0.1127, 0.4015]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9631], grad_fn=<NegBackward0>) tensor(0.9631, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4970527., grad_fn=<DivBackward0>) tensor(0.9631, grad_fn=<MeanBackward0>) tensor(0.0267, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4861, 0.1127, 0.4012]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9630], grad_fn=<NegBackward0>) tensor(0.9630, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4970519.5000, grad_fn=<DivBackward0>) tensor(0.9630, grad_fn=<MeanBackward0>) tensor(0.0267, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4864, 0.1126, 0.4009]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9629], grad_fn=<NegBackward0>) tensor(0.9629, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4970514., grad_fn=<DivBackward0>) tensor(0.9629, grad_fn=<MeanBackward0>) tensor(0.0268, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4867, 0.1126, 0.4007]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9629], grad_fn=<NegBackward0>) tensor(0.9629, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4970505., grad_fn=<DivBackward0>) tensor(0.9629, grad_fn=<MeanBackward0>) tensor(0.0268, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4870, 0.1126, 0.4005]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9628], grad_fn=<NegBackward0>) tensor(0.9628, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4970494.5000, grad_fn=<DivBackward0>) tensor(0.9628, grad_fn=<MeanBackward0>) tensor(0.0268, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4871, 0.1126, 0.4003]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9627], grad_fn=<NegBackward0>) tensor(0.9627, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4970484.5000, grad_fn=<DivBackward0>) tensor(0.9627, grad_fn=<MeanBackward0>) tensor(0.0269, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4872, 0.1126, 0.4002]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9627], grad_fn=<NegBackward0>) tensor(0.9627, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4970472.5000, grad_fn=<DivBackward0>) tensor(0.9627, grad_fn=<MeanBackward0>) tensor(0.0269, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4872, 0.1126, 0.4002]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9627], grad_fn=<NegBackward0>) tensor(0.9627, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4970457.5000, grad_fn=<DivBackward0>) tensor(0.9627, grad_fn=<MeanBackward0>) tensor(0.0269, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4872, 0.1126, 0.4002]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9628], grad_fn=<NegBackward0>) tensor(0.9628, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4970443.5000, grad_fn=<DivBackward0>) tensor(0.9628, grad_fn=<MeanBackward0>) tensor(0.0269, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x tensor([[0.4870, 0.1127, 0.4003]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9629], grad_fn=<NegBackward0>) tensor(0.9629, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4970426.5000, grad_fn=<DivBackward0>) tensor(0.9629, grad_fn=<MeanBackward0>) tensor(0.0268, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4868, 0.1127, 0.4004]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9630], grad_fn=<NegBackward0>) tensor(0.9630, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4970412., grad_fn=<DivBackward0>) tensor(0.9630, grad_fn=<MeanBackward0>) tensor(0.0268, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4867, 0.1127, 0.4006]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9630], grad_fn=<NegBackward0>) tensor(0.9630, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4970400.5000, grad_fn=<DivBackward0>) tensor(0.9630, grad_fn=<MeanBackward0>) tensor(0.0268, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4865, 0.1128, 0.4007]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9631], grad_fn=<NegBackward0>) tensor(0.9631, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4970389.5000, grad_fn=<DivBackward0>) tensor(0.9631, grad_fn=<MeanBackward0>) tensor(0.0268, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4864, 0.1128, 0.4009]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9631], grad_fn=<NegBackward0>) tensor(0.9631, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4970379., grad_fn=<DivBackward0>) tensor(0.9631, grad_fn=<MeanBackward0>) tensor(0.0268, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4863, 0.1128, 0.4009]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9631], grad_fn=<NegBackward0>) tensor(0.9631, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4970366., grad_fn=<DivBackward0>) tensor(0.9631, grad_fn=<MeanBackward0>) tensor(0.0268, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4863, 0.1127, 0.4010]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9631], grad_fn=<NegBackward0>) tensor(0.9631, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4970353.5000, grad_fn=<DivBackward0>) tensor(0.9631, grad_fn=<MeanBackward0>) tensor(0.0267, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4863, 0.1127, 0.4010]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9631], grad_fn=<NegBackward0>) tensor(0.9631, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4970341., grad_fn=<DivBackward0>) tensor(0.9631, grad_fn=<MeanBackward0>) tensor(0.0268, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4863, 0.1127, 0.4010]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9631], grad_fn=<NegBackward0>) tensor(0.9631, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4970329.5000, grad_fn=<DivBackward0>) tensor(0.9631, grad_fn=<MeanBackward0>) tensor(0.0268, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4863, 0.1127, 0.4010]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9630], grad_fn=<NegBackward0>) tensor(0.9630, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4970319.5000, grad_fn=<DivBackward0>) tensor(0.9630, grad_fn=<MeanBackward0>) tensor(0.0268, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4863, 0.1127, 0.4010]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9631], grad_fn=<NegBackward0>) tensor(0.9631, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4970311.5000, grad_fn=<DivBackward0>) tensor(0.9631, grad_fn=<MeanBackward0>) tensor(0.0268, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4863, 0.1127, 0.4009]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9631], grad_fn=<NegBackward0>) tensor(0.9631, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4970303., grad_fn=<DivBackward0>) tensor(0.9631, grad_fn=<MeanBackward0>) tensor(0.0268, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4855, 0.1126, 0.4019]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9630], grad_fn=<NegBackward0>) tensor(0.9630, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4968296.5000, grad_fn=<DivBackward0>) tensor(0.9630, grad_fn=<MeanBackward0>) tensor(0.0267, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4846, 0.1123, 0.4031]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9628], grad_fn=<NegBackward0>) tensor(0.9628, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4965635.5000, grad_fn=<DivBackward0>) tensor(0.9628, grad_fn=<MeanBackward0>) tensor(0.0266, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4837, 0.1119, 0.4044]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9625], grad_fn=<NegBackward0>) tensor(0.9625, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4962624., grad_fn=<DivBackward0>) tensor(0.9625, grad_fn=<MeanBackward0>) tensor(0.0266, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4830, 0.1115, 0.4056]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9621], grad_fn=<NegBackward0>) tensor(0.9621, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4959451., grad_fn=<DivBackward0>) tensor(0.9621, grad_fn=<MeanBackward0>) tensor(0.0265, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4824, 0.1109, 0.4066]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9615], grad_fn=<NegBackward0>) tensor(0.9615, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4956229., grad_fn=<DivBackward0>) tensor(0.9615, grad_fn=<MeanBackward0>) tensor(0.0265, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4820, 0.1103, 0.4077]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9608], grad_fn=<NegBackward0>) tensor(0.9608, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4953046., grad_fn=<DivBackward0>) tensor(0.9608, grad_fn=<MeanBackward0>) tensor(0.0266, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4816, 0.1098, 0.4086]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9601], grad_fn=<NegBackward0>) tensor(0.9601, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4949959.5000, grad_fn=<DivBackward0>) tensor(0.9601, grad_fn=<MeanBackward0>) tensor(0.0266, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4812, 0.1092, 0.4097]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9594], grad_fn=<NegBackward0>) tensor(0.9594, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4947019., grad_fn=<DivBackward0>) tensor(0.9594, grad_fn=<MeanBackward0>) tensor(0.0266, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4806, 0.1086, 0.4108]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9587], grad_fn=<NegBackward0>) tensor(0.9587, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4944253.5000, grad_fn=<DivBackward0>) tensor(0.9587, grad_fn=<MeanBackward0>) tensor(0.0266, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4797, 0.1080, 0.4123]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9581], grad_fn=<NegBackward0>) tensor(0.9581, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4941709.5000, grad_fn=<DivBackward0>) tensor(0.9581, grad_fn=<MeanBackward0>) tensor(0.0266, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4786, 0.1076, 0.4138]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9576], grad_fn=<NegBackward0>) tensor(0.9576, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4939345., grad_fn=<DivBackward0>) tensor(0.9576, grad_fn=<MeanBackward0>) tensor(0.0265, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4775, 0.1072, 0.4154]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9573], grad_fn=<NegBackward0>) tensor(0.9573, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4937171.5000, grad_fn=<DivBackward0>) tensor(0.9573, grad_fn=<MeanBackward0>) tensor(0.0264, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4762, 0.1069, 0.4169]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4935187.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0263, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4750, 0.1067, 0.4183]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9569], grad_fn=<NegBackward0>) tensor(0.9569, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4933390.5000, grad_fn=<DivBackward0>) tensor(0.9569, grad_fn=<MeanBackward0>) tensor(0.0262, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4739, 0.1065, 0.4196]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9568], grad_fn=<NegBackward0>) tensor(0.9568, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4931765.5000, grad_fn=<DivBackward0>) tensor(0.9568, grad_fn=<MeanBackward0>) tensor(0.0261, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4730, 0.1064, 0.4207]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9567], grad_fn=<NegBackward0>) tensor(0.9567, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4930302., grad_fn=<DivBackward0>) tensor(0.9567, grad_fn=<MeanBackward0>) tensor(0.0261, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4723, 0.1063, 0.4215]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9567], grad_fn=<NegBackward0>) tensor(0.9567, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4928976., grad_fn=<DivBackward0>) tensor(0.9567, grad_fn=<MeanBackward0>) tensor(0.0260, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4718, 0.1062, 0.4220]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9566], grad_fn=<NegBackward0>) tensor(0.9566, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4927773., grad_fn=<DivBackward0>) tensor(0.9566, grad_fn=<MeanBackward0>) tensor(0.0260, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4715, 0.1061, 0.4224]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9565], grad_fn=<NegBackward0>) tensor(0.9565, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4926730., grad_fn=<DivBackward0>) tensor(0.9565, grad_fn=<MeanBackward0>) tensor(0.0259, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4714, 0.1061, 0.4225]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9565], grad_fn=<NegBackward0>) tensor(0.9565, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4925714.5000, grad_fn=<DivBackward0>) tensor(0.9565, grad_fn=<MeanBackward0>) tensor(0.0259, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4713, 0.1061, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9565], grad_fn=<NegBackward0>) tensor(0.9565, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4924838.5000, grad_fn=<DivBackward0>) tensor(0.9565, grad_fn=<MeanBackward0>) tensor(0.0259, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4712, 0.1061, 0.4226]], grad_fn=<SumBackward1>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entropy tensor([0.9566], grad_fn=<NegBackward0>) tensor(0.9566, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4924046.5000, grad_fn=<DivBackward0>) tensor(0.9566, grad_fn=<MeanBackward0>) tensor(0.0259, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4710, 0.1063, 0.4227]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9568], grad_fn=<NegBackward0>) tensor(0.9568, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4923331.5000, grad_fn=<DivBackward0>) tensor(0.9568, grad_fn=<MeanBackward0>) tensor(0.0259, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4707, 0.1064, 0.4228]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4922691.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4704, 0.1066, 0.4230]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9574], grad_fn=<NegBackward0>) tensor(0.9574, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4922121., grad_fn=<DivBackward0>) tensor(0.9574, grad_fn=<MeanBackward0>) tensor(0.0257, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4700, 0.1068, 0.4231]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9577], grad_fn=<NegBackward0>) tensor(0.9577, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4921617., grad_fn=<DivBackward0>) tensor(0.9577, grad_fn=<MeanBackward0>) tensor(0.0257, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4697, 0.1070, 0.4232]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9580], grad_fn=<NegBackward0>) tensor(0.9580, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4921172.5000, grad_fn=<DivBackward0>) tensor(0.9580, grad_fn=<MeanBackward0>) tensor(0.0256, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4695, 0.1072, 0.4233]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9583], grad_fn=<NegBackward0>) tensor(0.9583, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4920779., grad_fn=<DivBackward0>) tensor(0.9583, grad_fn=<MeanBackward0>) tensor(0.0256, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4694, 0.1074, 0.4233]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9585], grad_fn=<NegBackward0>) tensor(0.9585, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4920432., grad_fn=<DivBackward0>) tensor(0.9585, grad_fn=<MeanBackward0>) tensor(0.0256, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4693, 0.1075, 0.4232]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9587], grad_fn=<NegBackward0>) tensor(0.9587, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4920123.5000, grad_fn=<DivBackward0>) tensor(0.9587, grad_fn=<MeanBackward0>) tensor(0.0255, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4694, 0.1076, 0.4231]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9588], grad_fn=<NegBackward0>) tensor(0.9588, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4919850., grad_fn=<DivBackward0>) tensor(0.9588, grad_fn=<MeanBackward0>) tensor(0.0255, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4695, 0.1076, 0.4229]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9589], grad_fn=<NegBackward0>) tensor(0.9589, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4919608.5000, grad_fn=<DivBackward0>) tensor(0.9589, grad_fn=<MeanBackward0>) tensor(0.0255, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4696, 0.1077, 0.4228]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9589], grad_fn=<NegBackward0>) tensor(0.9589, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4919396., grad_fn=<DivBackward0>) tensor(0.9589, grad_fn=<MeanBackward0>) tensor(0.0255, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4696, 0.1077, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9590], grad_fn=<NegBackward0>) tensor(0.9590, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4919211., grad_fn=<DivBackward0>) tensor(0.9590, grad_fn=<MeanBackward0>) tensor(0.0255, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4696, 0.1078, 0.4225]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9591], grad_fn=<NegBackward0>) tensor(0.9591, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4919047.5000, grad_fn=<DivBackward0>) tensor(0.9591, grad_fn=<MeanBackward0>) tensor(0.0255, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4696, 0.1079, 0.4225]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9592], grad_fn=<NegBackward0>) tensor(0.9592, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4918904., grad_fn=<DivBackward0>) tensor(0.9592, grad_fn=<MeanBackward0>) tensor(0.0255, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4696, 0.1079, 0.4225]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9592], grad_fn=<NegBackward0>) tensor(0.9592, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4918778., grad_fn=<DivBackward0>) tensor(0.9592, grad_fn=<MeanBackward0>) tensor(0.0255, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4695, 0.1079, 0.4225]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9593], grad_fn=<NegBackward0>) tensor(0.9593, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4918666., grad_fn=<DivBackward0>) tensor(0.9593, grad_fn=<MeanBackward0>) tensor(0.0255, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4695, 0.1079, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9593], grad_fn=<NegBackward0>) tensor(0.9593, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4918564.5000, grad_fn=<DivBackward0>) tensor(0.9593, grad_fn=<MeanBackward0>) tensor(0.0255, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4695, 0.1079, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9592], grad_fn=<NegBackward0>) tensor(0.9592, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4918479.5000, grad_fn=<DivBackward0>) tensor(0.9592, grad_fn=<MeanBackward0>) tensor(0.0255, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4695, 0.1078, 0.4227]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9591], grad_fn=<NegBackward0>) tensor(0.9591, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4918400.5000, grad_fn=<DivBackward0>) tensor(0.9591, grad_fn=<MeanBackward0>) tensor(0.0255, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4697, 0.1077, 0.4227]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9589], grad_fn=<NegBackward0>) tensor(0.9589, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4918332., grad_fn=<DivBackward0>) tensor(0.9589, grad_fn=<MeanBackward0>) tensor(0.0256, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4699, 0.1075, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9586], grad_fn=<NegBackward0>) tensor(0.9586, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4918269.5000, grad_fn=<DivBackward0>) tensor(0.9586, grad_fn=<MeanBackward0>) tensor(0.0256, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4701, 0.1073, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9584], grad_fn=<NegBackward0>) tensor(0.9584, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4918216., grad_fn=<DivBackward0>) tensor(0.9584, grad_fn=<MeanBackward0>) tensor(0.0256, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4703, 0.1071, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9581], grad_fn=<NegBackward0>) tensor(0.9581, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4918174., grad_fn=<DivBackward0>) tensor(0.9581, grad_fn=<MeanBackward0>) tensor(0.0257, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4705, 0.1070, 0.4225]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9579], grad_fn=<NegBackward0>) tensor(0.9579, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4918136., grad_fn=<DivBackward0>) tensor(0.9579, grad_fn=<MeanBackward0>) tensor(0.0257, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4706, 0.1068, 0.4225]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9576], grad_fn=<NegBackward0>) tensor(0.9576, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4918105.5000, grad_fn=<DivBackward0>) tensor(0.9576, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4708, 0.1067, 0.4225]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9575], grad_fn=<NegBackward0>) tensor(0.9575, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4918082., grad_fn=<DivBackward0>) tensor(0.9575, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4708, 0.1066, 0.4225]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9573], grad_fn=<NegBackward0>) tensor(0.9573, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4918063., grad_fn=<DivBackward0>) tensor(0.9573, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9572], grad_fn=<NegBackward0>) tensor(0.9572, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4918047., grad_fn=<DivBackward0>) tensor(0.9572, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4918035.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4710, 0.1064, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9570], grad_fn=<NegBackward0>) tensor(0.9570, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4918027., grad_fn=<DivBackward0>) tensor(0.9570, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4710, 0.1064, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9570], grad_fn=<NegBackward0>) tensor(0.9570, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4918022.5000, grad_fn=<DivBackward0>) tensor(0.9570, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4711, 0.1063, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9569], grad_fn=<NegBackward0>) tensor(0.9569, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4918015., grad_fn=<DivBackward0>) tensor(0.9569, grad_fn=<MeanBackward0>) tensor(0.0259, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4711, 0.1063, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9568], grad_fn=<NegBackward0>) tensor(0.9568, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4918010.5000, grad_fn=<DivBackward0>) tensor(0.9568, grad_fn=<MeanBackward0>) tensor(0.0259, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4712, 0.1062, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9568], grad_fn=<NegBackward0>) tensor(0.9568, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4918005.5000, grad_fn=<DivBackward0>) tensor(0.9568, grad_fn=<MeanBackward0>) tensor(0.0259, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4712, 0.1062, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9567], grad_fn=<NegBackward0>) tensor(0.9567, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4918003., grad_fn=<DivBackward0>) tensor(0.9567, grad_fn=<MeanBackward0>) tensor(0.0259, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x tensor([[0.4712, 0.1062, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9567], grad_fn=<NegBackward0>) tensor(0.9567, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4918001., grad_fn=<DivBackward0>) tensor(0.9567, grad_fn=<MeanBackward0>) tensor(0.0259, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4712, 0.1062, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9567], grad_fn=<NegBackward0>) tensor(0.9567, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917996.5000, grad_fn=<DivBackward0>) tensor(0.9567, grad_fn=<MeanBackward0>) tensor(0.0259, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4712, 0.1062, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9567], grad_fn=<NegBackward0>) tensor(0.9567, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917993.5000, grad_fn=<DivBackward0>) tensor(0.9567, grad_fn=<MeanBackward0>) tensor(0.0259, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4712, 0.1062, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9567], grad_fn=<NegBackward0>) tensor(0.9567, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917987., grad_fn=<DivBackward0>) tensor(0.9567, grad_fn=<MeanBackward0>) tensor(0.0259, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4711, 0.1062, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9567], grad_fn=<NegBackward0>) tensor(0.9567, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917983., grad_fn=<DivBackward0>) tensor(0.9567, grad_fn=<MeanBackward0>) tensor(0.0259, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4711, 0.1063, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9568], grad_fn=<NegBackward0>) tensor(0.9568, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917977., grad_fn=<DivBackward0>) tensor(0.9568, grad_fn=<MeanBackward0>) tensor(0.0259, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4710, 0.1063, 0.4227]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9568], grad_fn=<NegBackward0>) tensor(0.9568, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917973.5000, grad_fn=<DivBackward0>) tensor(0.9568, grad_fn=<MeanBackward0>) tensor(0.0259, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1063, 0.4228]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9568], grad_fn=<NegBackward0>) tensor(0.9568, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917969.5000, grad_fn=<DivBackward0>) tensor(0.9568, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1063, 0.4228]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9568], grad_fn=<NegBackward0>) tensor(0.9568, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917966.5000, grad_fn=<DivBackward0>) tensor(0.9568, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1063, 0.4228]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9568], grad_fn=<NegBackward0>) tensor(0.9568, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917964.5000, grad_fn=<DivBackward0>) tensor(0.9568, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4710, 0.1063, 0.4228]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9568], grad_fn=<NegBackward0>) tensor(0.9568, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917960., grad_fn=<DivBackward0>) tensor(0.9568, grad_fn=<MeanBackward0>) tensor(0.0259, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4710, 0.1063, 0.4227]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9568], grad_fn=<NegBackward0>) tensor(0.9568, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917957.5000, grad_fn=<DivBackward0>) tensor(0.9568, grad_fn=<MeanBackward0>) tensor(0.0259, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4711, 0.1063, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9568], grad_fn=<NegBackward0>) tensor(0.9568, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917955., grad_fn=<DivBackward0>) tensor(0.9568, grad_fn=<MeanBackward0>) tensor(0.0259, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4711, 0.1063, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9568], grad_fn=<NegBackward0>) tensor(0.9568, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917949.5000, grad_fn=<DivBackward0>) tensor(0.9568, grad_fn=<MeanBackward0>) tensor(0.0259, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4711, 0.1063, 0.4225]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9569], grad_fn=<NegBackward0>) tensor(0.9569, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917945.5000, grad_fn=<DivBackward0>) tensor(0.9569, grad_fn=<MeanBackward0>) tensor(0.0259, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4711, 0.1064, 0.4225]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9570], grad_fn=<NegBackward0>) tensor(0.9570, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917942.5000, grad_fn=<DivBackward0>) tensor(0.9570, grad_fn=<MeanBackward0>) tensor(0.0259, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4711, 0.1065, 0.4225]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917940., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4710, 0.1065, 0.4225]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9572], grad_fn=<NegBackward0>) tensor(0.9572, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917935.5000, grad_fn=<DivBackward0>) tensor(0.9572, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4225]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9572], grad_fn=<NegBackward0>) tensor(0.9572, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917933.5000, grad_fn=<DivBackward0>) tensor(0.9572, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1066, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9573], grad_fn=<NegBackward0>) tensor(0.9573, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917930., grad_fn=<DivBackward0>) tensor(0.9573, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4708, 0.1066, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9573], grad_fn=<NegBackward0>) tensor(0.9573, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917927.5000, grad_fn=<DivBackward0>) tensor(0.9573, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4708, 0.1066, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9573], grad_fn=<NegBackward0>) tensor(0.9573, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917927., grad_fn=<DivBackward0>) tensor(0.9573, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4708, 0.1066, 0.4227]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9572], grad_fn=<NegBackward0>) tensor(0.9572, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917924., grad_fn=<DivBackward0>) tensor(0.9572, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4708, 0.1065, 0.4227]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9572], grad_fn=<NegBackward0>) tensor(0.9572, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917922., grad_fn=<DivBackward0>) tensor(0.9572, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4708, 0.1065, 0.4227]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9572], grad_fn=<NegBackward0>) tensor(0.9572, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917922., grad_fn=<DivBackward0>) tensor(0.9572, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4708, 0.1065, 0.4227]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917919.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4708, 0.1065, 0.4227]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917918., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4708, 0.1065, 0.4227]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917918., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4708, 0.1065, 0.4227]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917918.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4708, 0.1065, 0.4227]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917916.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4708, 0.1065, 0.4227]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9572], grad_fn=<NegBackward0>) tensor(0.9572, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917917., grad_fn=<DivBackward0>) tensor(0.9572, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4708, 0.1065, 0.4227]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9572], grad_fn=<NegBackward0>) tensor(0.9572, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917914.5000, grad_fn=<DivBackward0>) tensor(0.9572, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4708, 0.1065, 0.4227]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9572], grad_fn=<NegBackward0>) tensor(0.9572, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917915., grad_fn=<DivBackward0>) tensor(0.9572, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9572], grad_fn=<NegBackward0>) tensor(0.9572, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917915., grad_fn=<DivBackward0>) tensor(0.9572, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entropy tensor([0.9572], grad_fn=<NegBackward0>) tensor(0.9572, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917914., grad_fn=<DivBackward0>) tensor(0.9572, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9572], grad_fn=<NegBackward0>) tensor(0.9572, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917913.5000, grad_fn=<DivBackward0>) tensor(0.9572, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9572], grad_fn=<NegBackward0>) tensor(0.9572, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917914., grad_fn=<DivBackward0>) tensor(0.9572, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9572], grad_fn=<NegBackward0>) tensor(0.9572, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917914., grad_fn=<DivBackward0>) tensor(0.9572, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9572], grad_fn=<NegBackward0>) tensor(0.9572, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917912.5000, grad_fn=<DivBackward0>) tensor(0.9572, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4708, 0.1065, 0.4227]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9572], grad_fn=<NegBackward0>) tensor(0.9572, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917911.5000, grad_fn=<DivBackward0>) tensor(0.9572, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4708, 0.1065, 0.4227]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9572], grad_fn=<NegBackward0>) tensor(0.9572, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917911.5000, grad_fn=<DivBackward0>) tensor(0.9572, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4708, 0.1065, 0.4227]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9572], grad_fn=<NegBackward0>) tensor(0.9572, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917913., grad_fn=<DivBackward0>) tensor(0.9572, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4708, 0.1065, 0.4227]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9572], grad_fn=<NegBackward0>) tensor(0.9572, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917911.5000, grad_fn=<DivBackward0>) tensor(0.9572, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4708, 0.1065, 0.4227]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917912., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4227]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917912., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917912., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917911., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917911., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917911.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917911.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917911.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917912., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917911.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917911.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917912., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9572], grad_fn=<NegBackward0>) tensor(0.9572, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909.5000, grad_fn=<DivBackward0>) tensor(0.9572, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9572], grad_fn=<NegBackward0>) tensor(0.9572, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917911.5000, grad_fn=<DivBackward0>) tensor(0.9572, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9572], grad_fn=<NegBackward0>) tensor(0.9572, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917911., grad_fn=<DivBackward0>) tensor(0.9572, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917911., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917911., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917911., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917911.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917908.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917911., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917911.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917911., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917911., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917911.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917912., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917911.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917911., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917911.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917911.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917911.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917911., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917911., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917911.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917911., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917911., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917911., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917911., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917911.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917911., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917911., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917912., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917911.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917911., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917911.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917911., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917911., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917908., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917911., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917911., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917911., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917911., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917911., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917911., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917912., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917911., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917911., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917911.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917911.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917911., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917911., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917908.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917911.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917909.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917911., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917912., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917912., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917911.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917910., grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.4709, 0.1065, 0.4226]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([0.9571], grad_fn=<NegBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(4917908.5000, grad_fn=<DivBackward0>) tensor(0.9571, grad_fn=<MeanBackward0>) tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "Sample: # 72\n",
      "          Name     Entry_id  fraction  shift  width\n",
      "0   BiV1.025O4  00-044-0081  0.436424      0   0.03\n",
      "1     Cu2VBiO6  04-012-3857  0.382891      0   0.03\n",
      "2  Cu3V2Bi4O14  04-011-5345  0.180684      0   0.03\n",
      "Current R^2 = 2736721.189422785\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'matplotlib.pyplot' from 'C:\\\\Users\\\\dell\\\\anaconda3\\\\envs\\\\myPymatgen\\\\lib\\\\site-packages\\\\matplotlib\\\\pyplot.py'>"
      ]
     },
     "execution_count": 952,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample = sample.optimize(num_epoch=500, print_prog=True, loss_weight=loss_weight)\n",
    "#new_sample.update_solution(0.03, 0.2999, new_sample.max_q_shift)\n",
    "sample.print_solution()\n",
    "# sample.plot(perphase=True)\n",
    "sample.refine_all_fractions()\n",
    "sample.refine_one_by_one()\n",
    "sample.plot(perphase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "id": "ff2a5e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_file = f'solution/samples{sample.sample_id}.json'\n",
    "with open(solution_file, 'w') as f:\n",
    "                json.dump(sample, f, cls=MontyEncoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 953,
   "id": "969206dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: # 72\n",
      "          Name     Entry_id  fraction     shift     width\n",
      "0   BiV1.025O4  00-044-0081  0.679678  0.002145  0.058585\n",
      "1     Cu2VBiO6  04-012-3857  0.263399  0.000612  0.059747\n",
      "2  Cu3V2Bi4O14  04-011-5345  0.056923  0.002300  0.044804\n",
      "Current R^2 = 0.2944966523867998\n"
     ]
    }
   ],
   "source": [
    "sample.print_solution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 910,
   "id": "d900b0f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.151885, 0.791021, 0.057094])"
      ]
     },
     "execution_count": 910,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance_data.sample_comp[306]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 940,
   "id": "eed28266",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "k=10\n",
    "solution = []\n",
    "for ent in entries:\n",
    "    phase = Phase.from_entry_and_instance_data(ent, 1/len(entries), instance_data)\n",
    "    solution.append(phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 941,
   "id": "78d97680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.213579, 0.208379, 0.578042])"
      ]
     },
     "execution_count": 941,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance_data.sample_comp[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 942,
   "id": "2ec1bbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = Sample(k, instance_data.log_q, instance_data.sample_xrd[k], instance_data.chemsys,\n",
    "                        instance_data.sample_comp[k], oxide_system, instance_data.wavelength, max_q_shift, solution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 944,
   "id": "46d7e773",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.prune_candidates_based_on_composition(cutoff=0.4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 946,
   "id": "cdb5a35e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample.prune_candidate_based_on_xrd(plot=True, cutoff=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 949,
   "id": "193de509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: # 10\n",
      "           Name     Entry_id  fraction     shift  width\n",
      "0       Bi(VO4)  04-010-5713  0.731419  0.001969   0.03\n",
      "1    BiV1.025O4  00-044-0081  0.225649  0.003937   0.03\n",
      "2  Bi3V4.2O15.5  00-058-0430  0.035439  0.007874   0.03\n",
      "3       Bi(VO4)  04-010-5710  0.007493  0.015748   0.03\n",
      "Current R^2 = 0.3577732660842573\n"
     ]
    }
   ],
   "source": [
    "sample.print_solution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 948,
   "id": "4d30a29b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'matplotlib.pyplot' from 'C:\\\\Users\\\\dell\\\\anaconda3\\\\envs\\\\myPymatgen\\\\lib\\\\site-packages\\\\matplotlib\\\\pyplot.py'>"
      ]
     },
     "execution_count": 948,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample.refine_all_fractions()\n",
    "# sample.refine_one_by_one()\n",
    "sample.plot(perphase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "id": "01ae001c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x tensor([[0.0794, 0.0821, 0.0755, 0.0728, 0.0887, 0.0727, 0.0922, 0.0962, 0.0732,\n",
      "         0.1434, 0.1237]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([2.3712], grad_fn=<NegBackward0>) tensor(2.3712, grad_fn=<MeanBackward0>)\n",
      "loss tensor(1.2677, grad_fn=<DivBackward0>) tensor(2.3712, grad_fn=<MeanBackward0>) tensor(0.0299, grad_fn=<MseLossBackward0>)\n",
      "0 8.140113 tensor(1.2677) tensor(0.0299) tensor(2.3712)\n",
      "x tensor([[0.0390, 0.1107, 0.1020, 0.0737, 0.0970, 0.0975, 0.1282, 0.0483, 0.0813,\n",
      "         0.1296, 0.0927]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([2.3475], grad_fn=<NegBackward0>) tensor(2.3475, grad_fn=<MeanBackward0>)\n",
      "loss tensor(1.0256, grad_fn=<DivBackward0>) tensor(2.3475, grad_fn=<MeanBackward0>) tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0185, 0.1325, 0.1148, 0.0783, 0.1096, 0.1146, 0.1432, 0.0283, 0.0679,\n",
      "         0.1094, 0.0828]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([2.2905], grad_fn=<NegBackward0>) tensor(2.2905, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.9697, grad_fn=<DivBackward0>) tensor(2.2905, grad_fn=<MeanBackward0>) tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0130, 0.1385, 0.1109, 0.0806, 0.1112, 0.1355, 0.1600, 0.0213, 0.0570,\n",
      "         0.0897, 0.0823]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([2.2525], grad_fn=<NegBackward0>) tensor(2.2525, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.9395, grad_fn=<DivBackward0>) tensor(2.2525, grad_fn=<MeanBackward0>) tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0101, 0.1382, 0.1114, 0.0811, 0.1103, 0.1545, 0.1712, 0.0183, 0.0538,\n",
      "         0.0732, 0.0779]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([2.2228], grad_fn=<NegBackward0>) tensor(2.2228, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.9225, grad_fn=<DivBackward0>) tensor(2.2228, grad_fn=<MeanBackward0>) tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0087, 0.1356, 0.1120, 0.0774, 0.1085, 0.1718, 0.1802, 0.0190, 0.0520,\n",
      "         0.0590, 0.0758]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([2.1993], grad_fn=<NegBackward0>) tensor(2.1993, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.9091, grad_fn=<DivBackward0>) tensor(2.1993, grad_fn=<MeanBackward0>) tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0089, 0.1333, 0.1133, 0.0702, 0.1092, 0.1868, 0.1882, 0.0190, 0.0494,\n",
      "         0.0449, 0.0768]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([2.1739], grad_fn=<NegBackward0>) tensor(2.1739, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8978, grad_fn=<DivBackward0>) tensor(2.1739, grad_fn=<MeanBackward0>) tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0094, 0.1321, 0.1143, 0.0628, 0.1080, 0.1989, 0.1953, 0.0198, 0.0486,\n",
      "         0.0325, 0.0782]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([2.1491], grad_fn=<NegBackward0>) tensor(2.1491, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8889, grad_fn=<DivBackward0>) tensor(2.1491, grad_fn=<MeanBackward0>) tensor(0.0217, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0106, 0.1302, 0.1159, 0.0561, 0.1050, 0.2074, 0.2019, 0.0209, 0.0479,\n",
      "         0.0243, 0.0798]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([2.1296], grad_fn=<NegBackward0>) tensor(2.1296, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8817, grad_fn=<DivBackward0>) tensor(2.1296, grad_fn=<MeanBackward0>) tensor(0.0242, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0116, 0.1270, 0.1180, 0.0508, 0.1008, 0.2131, 0.2093, 0.0217, 0.0475,\n",
      "         0.0177, 0.0823]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([2.1106], grad_fn=<NegBackward0>) tensor(2.1106, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8752, grad_fn=<DivBackward0>) tensor(2.1106, grad_fn=<MeanBackward0>) tensor(0.0267, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0125, 0.1232, 0.1209, 0.0464, 0.0964, 0.2161, 0.2170, 0.0221, 0.0492,\n",
      "         0.0140, 0.0823]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([2.0962], grad_fn=<NegBackward0>) tensor(2.0962, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8701, grad_fn=<DivBackward0>) tensor(2.0962, grad_fn=<MeanBackward0>) tensor(0.0290, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0130, 0.1185, 0.1244, 0.0433, 0.0919, 0.2168, 0.2247, 0.0229, 0.0507,\n",
      "         0.0129, 0.0810]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([2.0878], grad_fn=<NegBackward0>) tensor(2.0878, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8659, grad_fn=<DivBackward0>) tensor(2.0878, grad_fn=<MeanBackward0>) tensor(0.0309, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0133, 0.1147, 0.1282, 0.0396, 0.0872, 0.2165, 0.2327, 0.0234, 0.0518,\n",
      "         0.0121, 0.0805]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([2.0779], grad_fn=<NegBackward0>) tensor(2.0779, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8624, grad_fn=<DivBackward0>) tensor(2.0779, grad_fn=<MeanBackward0>) tensor(0.0330, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0134, 0.1120, 0.1319, 0.0367, 0.0816, 0.2164, 0.2399, 0.0235, 0.0531,\n",
      "         0.0119, 0.0795]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([2.0677], grad_fn=<NegBackward0>) tensor(2.0677, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8593, grad_fn=<DivBackward0>) tensor(2.0677, grad_fn=<MeanBackward0>) tensor(0.0351, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0134, 0.1090, 0.1356, 0.0344, 0.0766, 0.2168, 0.2464, 0.0233, 0.0543,\n",
      "         0.0115, 0.0787]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([2.0567], grad_fn=<NegBackward0>) tensor(2.0567, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8566, grad_fn=<DivBackward0>) tensor(2.0567, grad_fn=<MeanBackward0>) tensor(0.0371, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0132, 0.1056, 0.1393, 0.0325, 0.0715, 0.2179, 0.2523, 0.0230, 0.0553,\n",
      "         0.0112, 0.0782]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([2.0452], grad_fn=<NegBackward0>) tensor(2.0452, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8543, grad_fn=<DivBackward0>) tensor(2.0452, grad_fn=<MeanBackward0>) tensor(0.0390, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0128, 0.1028, 0.1426, 0.0307, 0.0658, 0.2196, 0.2568, 0.0222, 0.0560,\n",
      "         0.0123, 0.0783]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([2.0351], grad_fn=<NegBackward0>) tensor(2.0351, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8525, grad_fn=<DivBackward0>) tensor(2.0351, grad_fn=<MeanBackward0>) tensor(0.0403, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0122, 0.1002, 0.1453, 0.0299, 0.0606, 0.2221, 0.2597, 0.0214, 0.0566,\n",
      "         0.0134, 0.0785]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([2.0263], grad_fn=<NegBackward0>) tensor(2.0263, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8511, grad_fn=<DivBackward0>) tensor(2.0263, grad_fn=<MeanBackward0>) tensor(0.0413, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0120, 0.0973, 0.1478, 0.0291, 0.0559, 0.2265, 0.2613, 0.0204, 0.0569,\n",
      "         0.0144, 0.0784]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([2.0168], grad_fn=<NegBackward0>) tensor(2.0168, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8499, grad_fn=<DivBackward0>) tensor(2.0168, grad_fn=<MeanBackward0>) tensor(0.0419, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0118, 0.0940, 0.1506, 0.0283, 0.0515, 0.2316, 0.2624, 0.0194, 0.0571,\n",
      "         0.0153, 0.0779]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([2.0062], grad_fn=<NegBackward0>) tensor(2.0062, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8489, grad_fn=<DivBackward0>) tensor(2.0062, grad_fn=<MeanBackward0>) tensor(0.0424, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0117, 0.0906, 0.1541, 0.0275, 0.0469, 0.2370, 0.2632, 0.0185, 0.0573,\n",
      "         0.0161, 0.0772]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.9942], grad_fn=<NegBackward0>) tensor(1.9942, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8480, grad_fn=<DivBackward0>) tensor(1.9942, grad_fn=<MeanBackward0>) tensor(0.0430, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0118, 0.0875, 0.1579, 0.0266, 0.0427, 0.2421, 0.2637, 0.0176, 0.0573,\n",
      "         0.0166, 0.0763]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.9821], grad_fn=<NegBackward0>) tensor(1.9821, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8472, grad_fn=<DivBackward0>) tensor(1.9821, grad_fn=<MeanBackward0>) tensor(0.0434, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0120, 0.0844, 0.1618, 0.0264, 0.0388, 0.2462, 0.2636, 0.0170, 0.0570,\n",
      "         0.0170, 0.0757]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.9723], grad_fn=<NegBackward0>) tensor(1.9723, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8466, grad_fn=<DivBackward0>) tensor(1.9723, grad_fn=<MeanBackward0>) tensor(0.0435, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0124, 0.0812, 0.1662, 0.0262, 0.0348, 0.2498, 0.2633, 0.0168, 0.0567,\n",
      "         0.0173, 0.0754]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.9629], grad_fn=<NegBackward0>) tensor(1.9629, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8462, grad_fn=<DivBackward0>) tensor(1.9629, grad_fn=<MeanBackward0>) tensor(0.0433, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0128, 0.0778, 0.1718, 0.0260, 0.0309, 0.2525, 0.2628, 0.0166, 0.0562,\n",
      "         0.0174, 0.0751]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.9531], grad_fn=<NegBackward0>) tensor(1.9531, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8458, grad_fn=<DivBackward0>) tensor(1.9531, grad_fn=<MeanBackward0>) tensor(0.0430, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0133, 0.0743, 0.1779, 0.0258, 0.0275, 0.2546, 0.2621, 0.0164, 0.0555,\n",
      "         0.0174, 0.0751]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.9433], grad_fn=<NegBackward0>) tensor(1.9433, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8454, grad_fn=<DivBackward0>) tensor(1.9433, grad_fn=<MeanBackward0>) tensor(0.0428, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0138, 0.0705, 0.1843, 0.0256, 0.0240, 0.2560, 0.2613, 0.0162, 0.0549,\n",
      "         0.0182, 0.0752]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.9343], grad_fn=<NegBackward0>) tensor(1.9343, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8452, grad_fn=<DivBackward0>) tensor(1.9343, grad_fn=<MeanBackward0>) tensor(0.0422, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0144, 0.0667, 0.1914, 0.0253, 0.0204, 0.2573, 0.2607, 0.0160, 0.0539,\n",
      "         0.0182, 0.0755]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.9221], grad_fn=<NegBackward0>) tensor(1.9221, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8449, grad_fn=<DivBackward0>) tensor(1.9221, grad_fn=<MeanBackward0>) tensor(0.0419, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0149, 0.0626, 0.1989, 0.0251, 0.0167, 0.2588, 0.2601, 0.0159, 0.0534,\n",
      "         0.0178, 0.0760]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.9078], grad_fn=<NegBackward0>) tensor(1.9078, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8447, grad_fn=<DivBackward0>) tensor(1.9078, grad_fn=<MeanBackward0>) tensor(0.0417, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0153, 0.0586, 0.2067, 0.0249, 0.0128, 0.2601, 0.2594, 0.0158, 0.0525,\n",
      "         0.0176, 0.0765]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.8918], grad_fn=<NegBackward0>) tensor(1.8918, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8445, grad_fn=<DivBackward0>) tensor(1.8918, grad_fn=<MeanBackward0>) tensor(0.0414, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0157, 0.0550, 0.2143, 0.0246, 0.0098, 0.2607, 0.2585, 0.0156, 0.0514,\n",
      "         0.0179, 0.0764]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.8777], grad_fn=<NegBackward0>) tensor(1.8777, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8443, grad_fn=<DivBackward0>) tensor(1.8777, grad_fn=<MeanBackward0>) tensor(0.0412, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0159, 0.0514, 0.2220, 0.0243, 0.0067, 0.2613, 0.2578, 0.0155, 0.0504,\n",
      "         0.0185, 0.0762]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.8616], grad_fn=<NegBackward0>) tensor(1.8616, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8441, grad_fn=<DivBackward0>) tensor(1.8616, grad_fn=<MeanBackward0>) tensor(0.0410, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0161, 0.0482, 0.2298, 0.0239, 0.0038, 0.2619, 0.2566, 0.0153, 0.0495,\n",
      "         0.0191, 0.0757]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.8450], grad_fn=<NegBackward0>) tensor(1.8450, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8441, grad_fn=<DivBackward0>) tensor(1.8450, grad_fn=<MeanBackward0>) tensor(0.0406, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0162, 0.0449, 0.2374, 0.0235, 0.0017, 0.2625, 0.2550, 0.0151, 0.0486,\n",
      "         0.0198, 0.0753]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.8288], grad_fn=<NegBackward0>) tensor(1.8288, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8440, grad_fn=<DivBackward0>) tensor(1.8288, grad_fn=<MeanBackward0>) tensor(0.0402, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x tensor([[0.0162, 0.0412, 0.2449, 0.0229, 0.0004, 0.2629, 0.2532, 0.0150, 0.0479,\n",
      "         0.0205, 0.0750]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.8137], grad_fn=<NegBackward0>) tensor(1.8137, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8440, grad_fn=<DivBackward0>) tensor(1.8137, grad_fn=<MeanBackward0>) tensor(0.0396, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0161, 0.0373, 0.2519, 0.0222, 0.0000, 0.2629, 0.2513, 0.0149, 0.0473,\n",
      "         0.0212, 0.0749]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.8021], grad_fn=<NegBackward0>) tensor(1.8021, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8439, grad_fn=<DivBackward0>) tensor(1.8021, grad_fn=<MeanBackward0>) tensor(0.0391, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0159, 0.0332, 0.2587, 0.0214, 0.0000, 0.2629, 0.2496, 0.0148, 0.0467,\n",
      "         0.0219, 0.0748]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.7920], grad_fn=<NegBackward0>) tensor(1.7920, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8439, grad_fn=<DivBackward0>) tensor(1.7920, grad_fn=<MeanBackward0>) tensor(0.0386, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0158, 0.0289, 0.2656, 0.0205, 0.0000, 0.2630, 0.2479, 0.0148, 0.0464,\n",
      "         0.0224, 0.0748]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.7805], grad_fn=<NegBackward0>) tensor(1.7805, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8438, grad_fn=<DivBackward0>) tensor(1.7805, grad_fn=<MeanBackward0>) tensor(0.0381, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0157, 0.0244, 0.2724, 0.0196, 0.0000, 0.2632, 0.2464, 0.0147, 0.0463,\n",
      "         0.0227, 0.0747]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.7675], grad_fn=<NegBackward0>) tensor(1.7675, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8437, grad_fn=<DivBackward0>) tensor(1.7675, grad_fn=<MeanBackward0>) tensor(0.0377, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0158, 0.0217, 0.2786, 0.0183, 0.0000, 0.2631, 0.2445, 0.0146, 0.0462,\n",
      "         0.0228, 0.0743]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.7569], grad_fn=<NegBackward0>) tensor(1.7569, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8437, grad_fn=<DivBackward0>) tensor(1.7569, grad_fn=<MeanBackward0>) tensor(0.0371, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0161, 0.0203, 0.2844, 0.0170, 0.0000, 0.2630, 0.2423, 0.0145, 0.0461,\n",
      "         0.0227, 0.0738]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.7483], grad_fn=<NegBackward0>) tensor(1.7483, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8437, grad_fn=<DivBackward0>) tensor(1.7483, grad_fn=<MeanBackward0>) tensor(0.0365, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0162, 0.0188, 0.2902, 0.0156, 0.0000, 0.2631, 0.2398, 0.0143, 0.0461,\n",
      "         0.0224, 0.0734]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.7389], grad_fn=<NegBackward0>) tensor(1.7389, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8438, grad_fn=<DivBackward0>) tensor(1.7389, grad_fn=<MeanBackward0>) tensor(0.0359, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0162, 0.0174, 0.2961, 0.0142, 0.0000, 0.2635, 0.2373, 0.0140, 0.0460,\n",
      "         0.0221, 0.0732]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.7278], grad_fn=<NegBackward0>) tensor(1.7278, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8439, grad_fn=<DivBackward0>) tensor(1.7278, grad_fn=<MeanBackward0>) tensor(0.0354, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0160, 0.0159, 0.3022, 0.0128, 0.0000, 0.2643, 0.2343, 0.0138, 0.0459,\n",
      "         0.0216, 0.0732]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.7159], grad_fn=<NegBackward0>) tensor(1.7159, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8441, grad_fn=<DivBackward0>) tensor(1.7159, grad_fn=<MeanBackward0>) tensor(0.0349, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0158, 0.0144, 0.3085, 0.0113, 0.0000, 0.2652, 0.2311, 0.0135, 0.0458,\n",
      "         0.0212, 0.0733]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.7030], grad_fn=<NegBackward0>) tensor(1.7030, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8443, grad_fn=<DivBackward0>) tensor(1.7030, grad_fn=<MeanBackward0>) tensor(0.0343, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0156, 0.0128, 0.3152, 0.0097, 0.0000, 0.2662, 0.2278, 0.0133, 0.0456,\n",
      "         0.0207, 0.0732]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.6887], grad_fn=<NegBackward0>) tensor(1.6887, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8445, grad_fn=<DivBackward0>) tensor(1.6887, grad_fn=<MeanBackward0>) tensor(0.0337, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0153, 0.0112, 0.3223, 0.0081, 0.0000, 0.2672, 0.2242, 0.0130, 0.0453,\n",
      "         0.0203, 0.0729]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.6731], grad_fn=<NegBackward0>) tensor(1.6731, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8448, grad_fn=<DivBackward0>) tensor(1.6731, grad_fn=<MeanBackward0>) tensor(0.0331, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0151, 0.0097, 0.3300, 0.0064, 0.0000, 0.2682, 0.2205, 0.0127, 0.0449,\n",
      "         0.0200, 0.0724]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.6559], grad_fn=<NegBackward0>) tensor(1.6559, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8452, grad_fn=<DivBackward0>) tensor(1.6559, grad_fn=<MeanBackward0>) tensor(0.0324, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0147, 0.0080, 0.3383, 0.0046, 0.0000, 0.2692, 0.2166, 0.0125, 0.0445,\n",
      "         0.0199, 0.0718]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.6369], grad_fn=<NegBackward0>) tensor(1.6369, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8455, grad_fn=<DivBackward0>) tensor(1.6369, grad_fn=<MeanBackward0>) tensor(0.0317, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0143, 0.0063, 0.3469, 0.0026, 0.0000, 0.2699, 0.2125, 0.0122, 0.0441,\n",
      "         0.0198, 0.0714]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.6156], grad_fn=<NegBackward0>) tensor(1.6156, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8459, grad_fn=<DivBackward0>) tensor(1.6156, grad_fn=<MeanBackward0>) tensor(0.0310, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0139, 0.0046, 0.3559, 0.0004, 0.0000, 0.2705, 0.2083, 0.0120, 0.0436,\n",
      "         0.0199, 0.0712]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.5905], grad_fn=<NegBackward0>) tensor(1.5905, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8464, grad_fn=<DivBackward0>) tensor(1.5905, grad_fn=<MeanBackward0>) tensor(0.0302, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[1.3368e-02, 2.7288e-03, 3.6437e-01, 0.0000e+00, 2.5236e-05, 2.7046e-01,\n",
      "         2.0353e-01, 1.1719e-02, 4.3047e-02, 1.9933e-02, 7.0832e-02]],\n",
      "       grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.5727], grad_fn=<NegBackward0>) tensor(1.5727, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8468, grad_fn=<DivBackward0>) tensor(1.5727, grad_fn=<MeanBackward0>) tensor(0.0291, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0129, 0.0008, 0.3728, 0.0000, 0.0000, 0.2700, 0.1990, 0.0114, 0.0427,\n",
      "         0.0200, 0.0702]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.5553], grad_fn=<NegBackward0>) tensor(1.5553, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8472, grad_fn=<DivBackward0>) tensor(1.5553, grad_fn=<MeanBackward0>) tensor(0.0281, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[1.2596e-02, 2.1055e-05, 3.8064e-01, 0.0000e+00, 0.0000e+00, 2.6924e-01,\n",
      "         1.9441e-01, 1.1058e-02, 4.2338e-02, 2.0098e-02, 6.9601e-02]],\n",
      "       grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.5424], grad_fn=<NegBackward0>) tensor(1.5424, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8477, grad_fn=<DivBackward0>) tensor(1.5424, grad_fn=<MeanBackward0>) tensor(0.0271, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0123, 0.0000, 0.3872, 0.0000, 0.0000, 0.2684, 0.1903, 0.0106, 0.0420,\n",
      "         0.0201, 0.0689]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.5349], grad_fn=<NegBackward0>) tensor(1.5349, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8481, grad_fn=<DivBackward0>) tensor(1.5349, grad_fn=<MeanBackward0>) tensor(0.0262, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0122, 0.0000, 0.3931, 0.0000, 0.0000, 0.2679, 0.1862, 0.0102, 0.0419,\n",
      "         0.0201, 0.0684]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.5283], grad_fn=<NegBackward0>) tensor(1.5283, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8485, grad_fn=<DivBackward0>) tensor(1.5283, grad_fn=<MeanBackward0>) tensor(0.0252, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0119, 0.0000, 0.3979, 0.0000, 0.0000, 0.2682, 0.1822, 0.0098, 0.0419,\n",
      "         0.0201, 0.0680]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.5222], grad_fn=<NegBackward0>) tensor(1.5222, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8489, grad_fn=<DivBackward0>) tensor(1.5222, grad_fn=<MeanBackward0>) tensor(0.0243, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0117, 0.0000, 0.4022, 0.0000, 0.0000, 0.2685, 0.1785, 0.0093, 0.0421,\n",
      "         0.0200, 0.0678]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.5165], grad_fn=<NegBackward0>) tensor(1.5165, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8493, grad_fn=<DivBackward0>) tensor(1.5165, grad_fn=<MeanBackward0>) tensor(0.0234, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x tensor([[1.1406e-02, 2.4459e-05, 4.0627e-01, 0.0000e+00, 0.0000e+00, 2.6800e-01,\n",
      "         1.7530e-01, 8.8925e-03, 4.2415e-02, 1.9923e-02, 6.7767e-02]],\n",
      "       grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.5118], grad_fn=<NegBackward0>) tensor(1.5118, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8496, grad_fn=<DivBackward0>) tensor(1.5118, grad_fn=<MeanBackward0>) tensor(0.0227, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0112, 0.0000, 0.4097, 0.0000, 0.0000, 0.2675, 0.1729, 0.0085, 0.0427,\n",
      "         0.0198, 0.0677]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.5072], grad_fn=<NegBackward0>) tensor(1.5072, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8499, grad_fn=<DivBackward0>) tensor(1.5072, grad_fn=<MeanBackward0>) tensor(0.0222, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0108, 0.0000, 0.4125, 0.0000, 0.0000, 0.2678, 0.1704, 0.0081, 0.0430,\n",
      "         0.0198, 0.0677]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.5026], grad_fn=<NegBackward0>) tensor(1.5026, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8501, grad_fn=<DivBackward0>) tensor(1.5026, grad_fn=<MeanBackward0>) tensor(0.0217, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0105, 0.0000, 0.4144, 0.0000, 0.0000, 0.2692, 0.1679, 0.0077, 0.0432,\n",
      "         0.0196, 0.0675]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4979], grad_fn=<NegBackward0>) tensor(1.4979, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8503, grad_fn=<DivBackward0>) tensor(1.4979, grad_fn=<MeanBackward0>) tensor(0.0212, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0101, 0.0000, 0.4158, 0.0000, 0.0000, 0.2713, 0.1652, 0.0073, 0.0434,\n",
      "         0.0195, 0.0673]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4931], grad_fn=<NegBackward0>) tensor(1.4931, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8505, grad_fn=<DivBackward0>) tensor(1.4931, grad_fn=<MeanBackward0>) tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0096, 0.0000, 0.4171, 0.0000, 0.0000, 0.2735, 0.1627, 0.0069, 0.0436,\n",
      "         0.0194, 0.0670]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4883], grad_fn=<NegBackward0>) tensor(1.4883, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8508, grad_fn=<DivBackward0>) tensor(1.4883, grad_fn=<MeanBackward0>) tensor(0.0203, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0092, 0.0000, 0.4184, 0.0000, 0.0000, 0.2753, 0.1604, 0.0066, 0.0439,\n",
      "         0.0194, 0.0668]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4837], grad_fn=<NegBackward0>) tensor(1.4837, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8510, grad_fn=<DivBackward0>) tensor(1.4837, grad_fn=<MeanBackward0>) tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0088, 0.0000, 0.4199, 0.0000, 0.0000, 0.2767, 0.1584, 0.0063, 0.0442,\n",
      "         0.0193, 0.0665]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4793], grad_fn=<NegBackward0>) tensor(1.4793, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8512, grad_fn=<DivBackward0>) tensor(1.4793, grad_fn=<MeanBackward0>) tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0084, 0.0000, 0.4214, 0.0000, 0.0000, 0.2778, 0.1565, 0.0059, 0.0445,\n",
      "         0.0192, 0.0662]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4751], grad_fn=<NegBackward0>) tensor(1.4751, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8515, grad_fn=<DivBackward0>) tensor(1.4751, grad_fn=<MeanBackward0>) tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0081, 0.0000, 0.4228, 0.0000, 0.0000, 0.2789, 0.1549, 0.0056, 0.0446,\n",
      "         0.0192, 0.0659]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4709], grad_fn=<NegBackward0>) tensor(1.4709, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8516, grad_fn=<DivBackward0>) tensor(1.4709, grad_fn=<MeanBackward0>) tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0079, 0.0000, 0.4240, 0.0000, 0.0000, 0.2800, 0.1535, 0.0052, 0.0447,\n",
      "         0.0191, 0.0656]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4670], grad_fn=<NegBackward0>) tensor(1.4670, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8518, grad_fn=<DivBackward0>) tensor(1.4670, grad_fn=<MeanBackward0>) tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0077, 0.0000, 0.4250, 0.0000, 0.0000, 0.2810, 0.1522, 0.0049, 0.0448,\n",
      "         0.0191, 0.0653]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4634], grad_fn=<NegBackward0>) tensor(1.4634, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8520, grad_fn=<DivBackward0>) tensor(1.4634, grad_fn=<MeanBackward0>) tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0077, 0.0000, 0.4260, 0.0000, 0.0000, 0.2817, 0.1512, 0.0045, 0.0448,\n",
      "         0.0190, 0.0651]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4601], grad_fn=<NegBackward0>) tensor(1.4601, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8521, grad_fn=<DivBackward0>) tensor(1.4601, grad_fn=<MeanBackward0>) tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0076, 0.0000, 0.4272, 0.0000, 0.0000, 0.2821, 0.1502, 0.0042, 0.0448,\n",
      "         0.0190, 0.0649]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4571], grad_fn=<NegBackward0>) tensor(1.4571, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8522, grad_fn=<DivBackward0>) tensor(1.4571, grad_fn=<MeanBackward0>) tensor(0.0185, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0076, 0.0000, 0.4284, 0.0000, 0.0000, 0.2821, 0.1495, 0.0039, 0.0449,\n",
      "         0.0189, 0.0647]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4546], grad_fn=<NegBackward0>) tensor(1.4546, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8523, grad_fn=<DivBackward0>) tensor(1.4546, grad_fn=<MeanBackward0>) tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0077, 0.0000, 0.4294, 0.0000, 0.0000, 0.2820, 0.1489, 0.0035, 0.0450,\n",
      "         0.0189, 0.0647]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4524], grad_fn=<NegBackward0>) tensor(1.4524, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8524, grad_fn=<DivBackward0>) tensor(1.4524, grad_fn=<MeanBackward0>) tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0077, 0.0000, 0.4302, 0.0000, 0.0000, 0.2819, 0.1484, 0.0032, 0.0450,\n",
      "         0.0189, 0.0646]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4504], grad_fn=<NegBackward0>) tensor(1.4504, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8525, grad_fn=<DivBackward0>) tensor(1.4504, grad_fn=<MeanBackward0>) tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0077, 0.0000, 0.4307, 0.0000, 0.0000, 0.2821, 0.1480, 0.0029, 0.0451,\n",
      "         0.0189, 0.0646]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4485], grad_fn=<NegBackward0>) tensor(1.4485, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8525, grad_fn=<DivBackward0>) tensor(1.4485, grad_fn=<MeanBackward0>) tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0078, 0.0000, 0.4310, 0.0000, 0.0000, 0.2824, 0.1478, 0.0025, 0.0451,\n",
      "         0.0188, 0.0646]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4468], grad_fn=<NegBackward0>) tensor(1.4468, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8526, grad_fn=<DivBackward0>) tensor(1.4468, grad_fn=<MeanBackward0>) tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0078, 0.0000, 0.4312, 0.0000, 0.0000, 0.2826, 0.1476, 0.0022, 0.0453,\n",
      "         0.0188, 0.0646]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4452], grad_fn=<NegBackward0>) tensor(1.4452, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8526, grad_fn=<DivBackward0>) tensor(1.4452, grad_fn=<MeanBackward0>) tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0078, 0.0000, 0.4313, 0.0000, 0.0000, 0.2825, 0.1477, 0.0018, 0.0455,\n",
      "         0.0188, 0.0646]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4436], grad_fn=<NegBackward0>) tensor(1.4436, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8526, grad_fn=<DivBackward0>) tensor(1.4436, grad_fn=<MeanBackward0>) tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0077, 0.0000, 0.4315, 0.0000, 0.0000, 0.2821, 0.1480, 0.0014, 0.0458,\n",
      "         0.0188, 0.0646]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4420], grad_fn=<NegBackward0>) tensor(1.4420, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8525, grad_fn=<DivBackward0>) tensor(1.4420, grad_fn=<MeanBackward0>) tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0076, 0.0000, 0.4317, 0.0000, 0.0000, 0.2816, 0.1484, 0.0009, 0.0462,\n",
      "         0.0188, 0.0646]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4402], grad_fn=<NegBackward0>) tensor(1.4402, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8525, grad_fn=<DivBackward0>) tensor(1.4402, grad_fn=<MeanBackward0>) tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[7.5679e-03, 0.0000e+00, 4.3184e-01, 0.0000e+00, 0.0000e+00, 2.8115e-01,\n",
      "         1.4881e-01, 3.2297e-04, 4.6740e-02, 1.8858e-02, 6.4717e-02]],\n",
      "       grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4376], grad_fn=<NegBackward0>) tensor(1.4376, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8525, grad_fn=<DivBackward0>) tensor(1.4376, grad_fn=<MeanBackward0>) tensor(0.0190, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0075, 0.0000, 0.4317, 0.0000, 0.0000, 0.2809, 0.1490, 0.0000, 0.0473,\n",
      "         0.0189, 0.0648]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4361], grad_fn=<NegBackward0>) tensor(1.4361, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8525, grad_fn=<DivBackward0>) tensor(1.4361, grad_fn=<MeanBackward0>) tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0074, 0.0000, 0.4313, 0.0000, 0.0000, 0.2808, 0.1491, 0.0000, 0.0478,\n",
      "         0.0189, 0.0647]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4371], grad_fn=<NegBackward0>) tensor(1.4371, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8524, grad_fn=<DivBackward0>) tensor(1.4371, grad_fn=<MeanBackward0>) tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0074, 0.0000, 0.4307, 0.0000, 0.0000, 0.2809, 0.1491, 0.0000, 0.0482,\n",
      "         0.0190, 0.0647]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4380], grad_fn=<NegBackward0>) tensor(1.4380, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8524, grad_fn=<DivBackward0>) tensor(1.4380, grad_fn=<MeanBackward0>) tensor(0.0190, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0074, 0.0000, 0.4302, 0.0000, 0.0000, 0.2809, 0.1493, 0.0000, 0.0485,\n",
      "         0.0190, 0.0646]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4388], grad_fn=<NegBackward0>) tensor(1.4388, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8524, grad_fn=<DivBackward0>) tensor(1.4388, grad_fn=<MeanBackward0>) tensor(0.0190, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0074, 0.0000, 0.4298, 0.0000, 0.0000, 0.2808, 0.1497, 0.0000, 0.0486,\n",
      "         0.0191, 0.0646]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4396], grad_fn=<NegBackward0>) tensor(1.4396, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss tensor(0.8523, grad_fn=<DivBackward0>) tensor(1.4396, grad_fn=<MeanBackward0>) tensor(0.0190, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0075, 0.0000, 0.4296, 0.0000, 0.0000, 0.2805, 0.1501, 0.0000, 0.0487,\n",
      "         0.0191, 0.0646]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4405], grad_fn=<NegBackward0>) tensor(1.4405, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8523, grad_fn=<DivBackward0>) tensor(1.4405, grad_fn=<MeanBackward0>) tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0075, 0.0000, 0.4293, 0.0000, 0.0000, 0.2800, 0.1507, 0.0000, 0.0486,\n",
      "         0.0191, 0.0647]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4414], grad_fn=<NegBackward0>) tensor(1.4414, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8522, grad_fn=<DivBackward0>) tensor(1.4414, grad_fn=<MeanBackward0>) tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0076, 0.0000, 0.4290, 0.0000, 0.0000, 0.2795, 0.1512, 0.0000, 0.0486,\n",
      "         0.0192, 0.0649]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4423], grad_fn=<NegBackward0>) tensor(1.4423, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8521, grad_fn=<DivBackward0>) tensor(1.4423, grad_fn=<MeanBackward0>) tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0077, 0.0000, 0.4287, 0.0000, 0.0000, 0.2792, 0.1516, 0.0000, 0.0485,\n",
      "         0.0192, 0.0651]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4432], grad_fn=<NegBackward0>) tensor(1.4432, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8520, grad_fn=<DivBackward0>) tensor(1.4432, grad_fn=<MeanBackward0>) tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0077, 0.0000, 0.4284, 0.0000, 0.0000, 0.2790, 0.1520, 0.0000, 0.0485,\n",
      "         0.0192, 0.0652]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4440], grad_fn=<NegBackward0>) tensor(1.4440, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8520, grad_fn=<DivBackward0>) tensor(1.4440, grad_fn=<MeanBackward0>) tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0078, 0.0000, 0.4281, 0.0000, 0.0000, 0.2790, 0.1522, 0.0000, 0.0484,\n",
      "         0.0193, 0.0653]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4445], grad_fn=<NegBackward0>) tensor(1.4445, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8519, grad_fn=<DivBackward0>) tensor(1.4445, grad_fn=<MeanBackward0>) tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0078, 0.0000, 0.4280, 0.0000, 0.0000, 0.2790, 0.1524, 0.0000, 0.0483,\n",
      "         0.0193, 0.0652]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4446], grad_fn=<NegBackward0>) tensor(1.4446, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8519, grad_fn=<DivBackward0>) tensor(1.4446, grad_fn=<MeanBackward0>) tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0079, 0.0000, 0.4280, 0.0000, 0.0000, 0.2790, 0.1525, 0.0000, 0.0482,\n",
      "         0.0193, 0.0652]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4446], grad_fn=<NegBackward0>) tensor(1.4446, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8519, grad_fn=<DivBackward0>) tensor(1.4446, grad_fn=<MeanBackward0>) tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0079, 0.0000, 0.4282, 0.0000, 0.0000, 0.2789, 0.1525, 0.0000, 0.0480,\n",
      "         0.0194, 0.0651]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4443], grad_fn=<NegBackward0>) tensor(1.4443, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8519, grad_fn=<DivBackward0>) tensor(1.4443, grad_fn=<MeanBackward0>) tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0079, 0.0000, 0.4285, 0.0000, 0.0000, 0.2788, 0.1525, 0.0000, 0.0478,\n",
      "         0.0194, 0.0651]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4438], grad_fn=<NegBackward0>) tensor(1.4438, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8519, grad_fn=<DivBackward0>) tensor(1.4438, grad_fn=<MeanBackward0>) tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0079, 0.0000, 0.4288, 0.0000, 0.0000, 0.2788, 0.1524, 0.0000, 0.0477,\n",
      "         0.0194, 0.0651]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4433], grad_fn=<NegBackward0>) tensor(1.4433, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8519, grad_fn=<DivBackward0>) tensor(1.4433, grad_fn=<MeanBackward0>) tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0079, 0.0000, 0.4290, 0.0000, 0.0000, 0.2790, 0.1522, 0.0000, 0.0476,\n",
      "         0.0194, 0.0651]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4429], grad_fn=<NegBackward0>) tensor(1.4429, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8519, grad_fn=<DivBackward0>) tensor(1.4429, grad_fn=<MeanBackward0>) tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0079, 0.0000, 0.4290, 0.0000, 0.0000, 0.2792, 0.1522, 0.0000, 0.0475,\n",
      "         0.0193, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4425], grad_fn=<NegBackward0>) tensor(1.4425, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8519, grad_fn=<DivBackward0>) tensor(1.4425, grad_fn=<MeanBackward0>) tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0079, 0.0000, 0.4290, 0.0000, 0.0000, 0.2794, 0.1521, 0.0000, 0.0475,\n",
      "         0.0193, 0.0649]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4424], grad_fn=<NegBackward0>) tensor(1.4424, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8519, grad_fn=<DivBackward0>) tensor(1.4424, grad_fn=<MeanBackward0>) tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0079, 0.0000, 0.4289, 0.0000, 0.0000, 0.2795, 0.1520, 0.0000, 0.0476,\n",
      "         0.0192, 0.0649]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4424], grad_fn=<NegBackward0>) tensor(1.4424, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8519, grad_fn=<DivBackward0>) tensor(1.4424, grad_fn=<MeanBackward0>) tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0079, 0.0000, 0.4288, 0.0000, 0.0000, 0.2795, 0.1519, 0.0000, 0.0477,\n",
      "         0.0192, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4427], grad_fn=<NegBackward0>) tensor(1.4427, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8520, grad_fn=<DivBackward0>) tensor(1.4427, grad_fn=<MeanBackward0>) tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0079, 0.0000, 0.4287, 0.0000, 0.0000, 0.2794, 0.1518, 0.0000, 0.0478,\n",
      "         0.0192, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4430], grad_fn=<NegBackward0>) tensor(1.4430, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8520, grad_fn=<DivBackward0>) tensor(1.4430, grad_fn=<MeanBackward0>) tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0079, 0.0000, 0.4287, 0.0000, 0.0000, 0.2794, 0.1518, 0.0000, 0.0479,\n",
      "         0.0192, 0.0651]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4432], grad_fn=<NegBackward0>) tensor(1.4432, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8520, grad_fn=<DivBackward0>) tensor(1.4432, grad_fn=<MeanBackward0>) tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0079, 0.0000, 0.4286, 0.0000, 0.0000, 0.2795, 0.1517, 0.0000, 0.0480,\n",
      "         0.0192, 0.0651]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4433], grad_fn=<NegBackward0>) tensor(1.4433, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8519, grad_fn=<DivBackward0>) tensor(1.4433, grad_fn=<MeanBackward0>) tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0079, 0.0000, 0.4285, 0.0000, 0.0000, 0.2796, 0.1517, 0.0000, 0.0479,\n",
      "         0.0193, 0.0651]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4433], grad_fn=<NegBackward0>) tensor(1.4433, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8519, grad_fn=<DivBackward0>) tensor(1.4433, grad_fn=<MeanBackward0>) tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0078, 0.0000, 0.4285, 0.0000, 0.0000, 0.2798, 0.1517, 0.0000, 0.0479,\n",
      "         0.0193, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4431], grad_fn=<NegBackward0>) tensor(1.4431, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8519, grad_fn=<DivBackward0>) tensor(1.4431, grad_fn=<MeanBackward0>) tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[7.8067e-03, 0.0000e+00, 4.2847e-01, 0.0000e+00, 0.0000e+00, 2.7993e-01,\n",
      "         1.5158e-01, 3.0566e-07, 4.7890e-02, 1.9341e-02, 6.4984e-02]],\n",
      "       grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4429], grad_fn=<NegBackward0>) tensor(1.4429, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8520, grad_fn=<DivBackward0>) tensor(1.4429, grad_fn=<MeanBackward0>) tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0078, 0.0000, 0.4285, 0.0000, 0.0000, 0.2800, 0.1515, 0.0000, 0.0479,\n",
      "         0.0194, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4428], grad_fn=<NegBackward0>) tensor(1.4428, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8520, grad_fn=<DivBackward0>) tensor(1.4428, grad_fn=<MeanBackward0>) tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0078, 0.0000, 0.4286, 0.0000, 0.0000, 0.2800, 0.1514, 0.0000, 0.0479,\n",
      "         0.0194, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4427], grad_fn=<NegBackward0>) tensor(1.4427, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8520, grad_fn=<DivBackward0>) tensor(1.4427, grad_fn=<MeanBackward0>) tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0078, 0.0000, 0.4288, 0.0000, 0.0000, 0.2799, 0.1512, 0.0000, 0.0479,\n",
      "         0.0194, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4426], grad_fn=<NegBackward0>) tensor(1.4426, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8520, grad_fn=<DivBackward0>) tensor(1.4426, grad_fn=<MeanBackward0>) tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0078, 0.0000, 0.4290, 0.0000, 0.0000, 0.2799, 0.1510, 0.0000, 0.0479,\n",
      "         0.0193, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4424], grad_fn=<NegBackward0>) tensor(1.4424, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8520, grad_fn=<DivBackward0>) tensor(1.4424, grad_fn=<MeanBackward0>) tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0078, 0.0000, 0.4292, 0.0000, 0.0000, 0.2800, 0.1508, 0.0000, 0.0479,\n",
      "         0.0193, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4420], grad_fn=<NegBackward0>) tensor(1.4420, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8520, grad_fn=<DivBackward0>) tensor(1.4420, grad_fn=<MeanBackward0>) tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0078, 0.0000, 0.4294, 0.0000, 0.0000, 0.2801, 0.1507, 0.0000, 0.0478,\n",
      "         0.0193, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4415], grad_fn=<NegBackward0>) tensor(1.4415, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8521, grad_fn=<DivBackward0>) tensor(1.4415, grad_fn=<MeanBackward0>) tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0078, 0.0000, 0.4296, 0.0000, 0.0000, 0.2802, 0.1505, 0.0000, 0.0477,\n",
      "         0.0193, 0.0649]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4410], grad_fn=<NegBackward0>) tensor(1.4410, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8521, grad_fn=<DivBackward0>) tensor(1.4410, grad_fn=<MeanBackward0>) tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0077, 0.0000, 0.4298, 0.0000, 0.0000, 0.2803, 0.1504, 0.0000, 0.0476,\n",
      "         0.0193, 0.0648]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4406], grad_fn=<NegBackward0>) tensor(1.4406, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8521, grad_fn=<DivBackward0>) tensor(1.4406, grad_fn=<MeanBackward0>) tensor(0.0192, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x tensor([[0.0077, 0.0000, 0.4299, 0.0000, 0.0000, 0.2803, 0.1503, 0.0000, 0.0476,\n",
      "         0.0193, 0.0648]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4403], grad_fn=<NegBackward0>) tensor(1.4403, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8521, grad_fn=<DivBackward0>) tensor(1.4403, grad_fn=<MeanBackward0>) tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0077, 0.0000, 0.4300, 0.0000, 0.0000, 0.2803, 0.1503, 0.0000, 0.0476,\n",
      "         0.0193, 0.0648]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4403], grad_fn=<NegBackward0>) tensor(1.4403, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8521, grad_fn=<DivBackward0>) tensor(1.4403, grad_fn=<MeanBackward0>) tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0077, 0.0000, 0.4300, 0.0000, 0.0000, 0.2803, 0.1502, 0.0000, 0.0476,\n",
      "         0.0193, 0.0648]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4404], grad_fn=<NegBackward0>) tensor(1.4404, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8521, grad_fn=<DivBackward0>) tensor(1.4404, grad_fn=<MeanBackward0>) tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0077, 0.0000, 0.4299, 0.0000, 0.0000, 0.2803, 0.1501, 0.0000, 0.0477,\n",
      "         0.0193, 0.0649]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4405], grad_fn=<NegBackward0>) tensor(1.4405, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8521, grad_fn=<DivBackward0>) tensor(1.4405, grad_fn=<MeanBackward0>) tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0077, 0.0000, 0.4299, 0.0000, 0.0000, 0.2803, 0.1501, 0.0000, 0.0477,\n",
      "         0.0193, 0.0649]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4406], grad_fn=<NegBackward0>) tensor(1.4406, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8521, grad_fn=<DivBackward0>) tensor(1.4406, grad_fn=<MeanBackward0>) tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0077, 0.0000, 0.4298, 0.0000, 0.0000, 0.2803, 0.1502, 0.0000, 0.0477,\n",
      "         0.0194, 0.0649]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4407], grad_fn=<NegBackward0>) tensor(1.4407, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8521, grad_fn=<DivBackward0>) tensor(1.4407, grad_fn=<MeanBackward0>) tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0077, 0.0000, 0.4298, 0.0000, 0.0000, 0.2803, 0.1503, 0.0000, 0.0477,\n",
      "         0.0194, 0.0648]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4407], grad_fn=<NegBackward0>) tensor(1.4407, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8521, grad_fn=<DivBackward0>) tensor(1.4407, grad_fn=<MeanBackward0>) tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0077, 0.0000, 0.4298, 0.0000, 0.0000, 0.2802, 0.1503, 0.0000, 0.0477,\n",
      "         0.0194, 0.0648]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4408], grad_fn=<NegBackward0>) tensor(1.4408, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8521, grad_fn=<DivBackward0>) tensor(1.4408, grad_fn=<MeanBackward0>) tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0077, 0.0000, 0.4298, 0.0000, 0.0000, 0.2802, 0.1504, 0.0000, 0.0477,\n",
      "         0.0194, 0.0648]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4408], grad_fn=<NegBackward0>) tensor(1.4408, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8521, grad_fn=<DivBackward0>) tensor(1.4408, grad_fn=<MeanBackward0>) tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0077, 0.0000, 0.4298, 0.0000, 0.0000, 0.2802, 0.1504, 0.0000, 0.0477,\n",
      "         0.0194, 0.0649]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4409], grad_fn=<NegBackward0>) tensor(1.4409, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8521, grad_fn=<DivBackward0>) tensor(1.4409, grad_fn=<MeanBackward0>) tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0077, 0.0000, 0.4297, 0.0000, 0.0000, 0.2801, 0.1504, 0.0000, 0.0477,\n",
      "         0.0194, 0.0649]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4409], grad_fn=<NegBackward0>) tensor(1.4409, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8521, grad_fn=<DivBackward0>) tensor(1.4409, grad_fn=<MeanBackward0>) tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0077, 0.0000, 0.4297, 0.0000, 0.0000, 0.2801, 0.1504, 0.0000, 0.0477,\n",
      "         0.0194, 0.0649]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4410], grad_fn=<NegBackward0>) tensor(1.4410, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8520, grad_fn=<DivBackward0>) tensor(1.4410, grad_fn=<MeanBackward0>) tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0077, 0.0000, 0.4297, 0.0000, 0.0000, 0.2801, 0.1505, 0.0000, 0.0478,\n",
      "         0.0194, 0.0649]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4411], grad_fn=<NegBackward0>) tensor(1.4411, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8520, grad_fn=<DivBackward0>) tensor(1.4411, grad_fn=<MeanBackward0>) tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0077, 0.0000, 0.4297, 0.0000, 0.0000, 0.2801, 0.1505, 0.0000, 0.0478,\n",
      "         0.0194, 0.0649]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4412], grad_fn=<NegBackward0>) tensor(1.4412, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8520, grad_fn=<DivBackward0>) tensor(1.4412, grad_fn=<MeanBackward0>) tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0077, 0.0000, 0.4296, 0.0000, 0.0000, 0.2801, 0.1506, 0.0000, 0.0477,\n",
      "         0.0194, 0.0649]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4412], grad_fn=<NegBackward0>) tensor(1.4412, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8520, grad_fn=<DivBackward0>) tensor(1.4412, grad_fn=<MeanBackward0>) tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0077, 0.0000, 0.4296, 0.0000, 0.0000, 0.2800, 0.1506, 0.0000, 0.0477,\n",
      "         0.0194, 0.0649]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4413], grad_fn=<NegBackward0>) tensor(1.4413, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8520, grad_fn=<DivBackward0>) tensor(1.4413, grad_fn=<MeanBackward0>) tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0078, 0.0000, 0.4295, 0.0000, 0.0000, 0.2800, 0.1507, 0.0000, 0.0476,\n",
      "         0.0194, 0.0649]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4414], grad_fn=<NegBackward0>) tensor(1.4414, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8520, grad_fn=<DivBackward0>) tensor(1.4414, grad_fn=<MeanBackward0>) tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0078, 0.0000, 0.4295, 0.0000, 0.0000, 0.2800, 0.1508, 0.0000, 0.0476,\n",
      "         0.0195, 0.0649]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4415], grad_fn=<NegBackward0>) tensor(1.4415, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8520, grad_fn=<DivBackward0>) tensor(1.4415, grad_fn=<MeanBackward0>) tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0078, 0.0000, 0.4294, 0.0000, 0.0000, 0.2800, 0.1509, 0.0000, 0.0476,\n",
      "         0.0195, 0.0649]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4416], grad_fn=<NegBackward0>) tensor(1.4416, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8520, grad_fn=<DivBackward0>) tensor(1.4416, grad_fn=<MeanBackward0>) tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0078, 0.0000, 0.4293, 0.0000, 0.0000, 0.2800, 0.1509, 0.0000, 0.0476,\n",
      "         0.0195, 0.0649]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4417], grad_fn=<NegBackward0>) tensor(1.4417, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8520, grad_fn=<DivBackward0>) tensor(1.4417, grad_fn=<MeanBackward0>) tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0078, 0.0000, 0.4293, 0.0000, 0.0000, 0.2801, 0.1509, 0.0000, 0.0476,\n",
      "         0.0195, 0.0649]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4417], grad_fn=<NegBackward0>) tensor(1.4417, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8520, grad_fn=<DivBackward0>) tensor(1.4417, grad_fn=<MeanBackward0>) tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0078, 0.0000, 0.4292, 0.0000, 0.0000, 0.2801, 0.1509, 0.0000, 0.0477,\n",
      "         0.0194, 0.0649]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4418], grad_fn=<NegBackward0>) tensor(1.4418, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8520, grad_fn=<DivBackward0>) tensor(1.4418, grad_fn=<MeanBackward0>) tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0078, 0.0000, 0.4292, 0.0000, 0.0000, 0.2801, 0.1510, 0.0000, 0.0477,\n",
      "         0.0194, 0.0649]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4418], grad_fn=<NegBackward0>) tensor(1.4418, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8520, grad_fn=<DivBackward0>) tensor(1.4418, grad_fn=<MeanBackward0>) tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0078, 0.0000, 0.4291, 0.0000, 0.0000, 0.2801, 0.1510, 0.0000, 0.0477,\n",
      "         0.0194, 0.0649]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4418], grad_fn=<NegBackward0>) tensor(1.4418, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8519, grad_fn=<DivBackward0>) tensor(1.4418, grad_fn=<MeanBackward0>) tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0078, 0.0000, 0.4291, 0.0000, 0.0000, 0.2801, 0.1510, 0.0000, 0.0477,\n",
      "         0.0194, 0.0649]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4419], grad_fn=<NegBackward0>) tensor(1.4419, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8519, grad_fn=<DivBackward0>) tensor(1.4419, grad_fn=<MeanBackward0>) tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0078, 0.0000, 0.4291, 0.0000, 0.0000, 0.2801, 0.1510, 0.0000, 0.0477,\n",
      "         0.0194, 0.0649]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4419], grad_fn=<NegBackward0>) tensor(1.4419, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8519, grad_fn=<DivBackward0>) tensor(1.4419, grad_fn=<MeanBackward0>) tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0078, 0.0000, 0.4291, 0.0000, 0.0000, 0.2802, 0.1510, 0.0000, 0.0476,\n",
      "         0.0195, 0.0649]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4419], grad_fn=<NegBackward0>) tensor(1.4419, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8519, grad_fn=<DivBackward0>) tensor(1.4419, grad_fn=<MeanBackward0>) tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0077, 0.0000, 0.4285, 0.0000, 0.0000, 0.2799, 0.1504, 0.0000, 0.0477,\n",
      "         0.0212, 0.0648]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4459], grad_fn=<NegBackward0>) tensor(1.4459, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8514, grad_fn=<DivBackward0>) tensor(1.4459, grad_fn=<MeanBackward0>) tensor(0.0187, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0076, 0.0000, 0.4278, 0.0000, 0.0000, 0.2794, 0.1495, 0.0000, 0.0477,\n",
      "         0.0234, 0.0646]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4506], grad_fn=<NegBackward0>) tensor(1.4506, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8506, grad_fn=<DivBackward0>) tensor(1.4506, grad_fn=<MeanBackward0>) tensor(0.0180, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[7.4604e-03, 0.0000e+00, 4.2726e-01, 1.5079e-04, 0.0000e+00, 2.7876e-01,\n",
      "         1.4888e-01, 0.0000e+00, 4.7395e-02, 2.5617e-02, 6.4472e-02]],\n",
      "       grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4560], grad_fn=<NegBackward0>) tensor(1.4560, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8499, grad_fn=<DivBackward0>) tensor(1.4560, grad_fn=<MeanBackward0>) tensor(0.0173, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[7.2450e-03, 0.0000e+00, 4.2695e-01, 0.0000e+00, 3.5295e-06, 2.7835e-01,\n",
      "         1.4846e-01, 0.0000e+00, 4.6938e-02, 2.7676e-02, 6.4376e-02]],\n",
      "       grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4577], grad_fn=<NegBackward0>) tensor(1.4577, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8492, grad_fn=<DivBackward0>) tensor(1.4577, grad_fn=<MeanBackward0>) tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0070, 0.0000, 0.4264, 0.0000, 0.0000, 0.2777, 0.1486, 0.0000, 0.0462,\n",
      "         0.0297, 0.0645]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4605], grad_fn=<NegBackward0>) tensor(1.4605, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8485, grad_fn=<DivBackward0>) tensor(1.4605, grad_fn=<MeanBackward0>) tensor(0.0166, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x tensor([[0.0068, 0.0000, 0.4252, 0.0000, 0.0000, 0.2765, 0.1487, 0.0000, 0.0456,\n",
      "         0.0327, 0.0645]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4659], grad_fn=<NegBackward0>) tensor(1.4659, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8481, grad_fn=<DivBackward0>) tensor(1.4659, grad_fn=<MeanBackward0>) tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0066, 0.0000, 0.4238, 0.0000, 0.0000, 0.2754, 0.1489, 0.0000, 0.0453,\n",
      "         0.0355, 0.0644]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4713], grad_fn=<NegBackward0>) tensor(1.4713, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8480, grad_fn=<DivBackward0>) tensor(1.4713, grad_fn=<MeanBackward0>) tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0066, 0.0000, 0.4222, 0.0000, 0.0000, 0.2744, 0.1493, 0.0000, 0.0453,\n",
      "         0.0380, 0.0643]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4766], grad_fn=<NegBackward0>) tensor(1.4766, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8480, grad_fn=<DivBackward0>) tensor(1.4766, grad_fn=<MeanBackward0>) tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0066, 0.0000, 0.4205, 0.0000, 0.0000, 0.2735, 0.1501, 0.0000, 0.0454,\n",
      "         0.0398, 0.0642]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4815], grad_fn=<NegBackward0>) tensor(1.4815, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8481, grad_fn=<DivBackward0>) tensor(1.4815, grad_fn=<MeanBackward0>) tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0067, 0.0000, 0.4187, 0.0000, 0.0000, 0.2726, 0.1513, 0.0000, 0.0454,\n",
      "         0.0410, 0.0643]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4858], grad_fn=<NegBackward0>) tensor(1.4858, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8481, grad_fn=<DivBackward0>) tensor(1.4858, grad_fn=<MeanBackward0>) tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0068, 0.0000, 0.4171, 0.0000, 0.0000, 0.2716, 0.1530, 0.0000, 0.0452,\n",
      "         0.0416, 0.0646]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4893], grad_fn=<NegBackward0>) tensor(1.4893, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8480, grad_fn=<DivBackward0>) tensor(1.4893, grad_fn=<MeanBackward0>) tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0070, 0.0000, 0.4158, 0.0000, 0.0000, 0.2704, 0.1551, 0.0000, 0.0450,\n",
      "         0.0416, 0.0649]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4920], grad_fn=<NegBackward0>) tensor(1.4920, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8478, grad_fn=<DivBackward0>) tensor(1.4920, grad_fn=<MeanBackward0>) tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4150, 0.0000, 0.0000, 0.2694, 0.1573, 0.0000, 0.0448,\n",
      "         0.0413, 0.0652]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4934], grad_fn=<NegBackward0>) tensor(1.4934, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8475, grad_fn=<DivBackward0>) tensor(1.4934, grad_fn=<MeanBackward0>) tensor(0.0163, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0074, 0.0000, 0.4145, 0.0000, 0.0000, 0.2683, 0.1593, 0.0000, 0.0446,\n",
      "         0.0406, 0.0653]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4942], grad_fn=<NegBackward0>) tensor(1.4942, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8472, grad_fn=<DivBackward0>) tensor(1.4942, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0076, 0.0000, 0.4144, 0.0000, 0.0000, 0.2671, 0.1609, 0.0000, 0.0447,\n",
      "         0.0399, 0.0655]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4946], grad_fn=<NegBackward0>) tensor(1.4946, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4946, grad_fn=<MeanBackward0>) tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0078, 0.0000, 0.4145, 0.0000, 0.0000, 0.2659, 0.1621, 0.0000, 0.0450,\n",
      "         0.0391, 0.0657]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4951], grad_fn=<NegBackward0>) tensor(1.4951, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8466, grad_fn=<DivBackward0>) tensor(1.4951, grad_fn=<MeanBackward0>) tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0080, 0.0000, 0.4147, 0.0000, 0.0000, 0.2649, 0.1627, 0.0000, 0.0455,\n",
      "         0.0383, 0.0660]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4955], grad_fn=<NegBackward0>) tensor(1.4955, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8464, grad_fn=<DivBackward0>) tensor(1.4955, grad_fn=<MeanBackward0>) tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0081, 0.0000, 0.4149, 0.0000, 0.0000, 0.2642, 0.1631, 0.0000, 0.0460,\n",
      "         0.0375, 0.0663]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4959], grad_fn=<NegBackward0>) tensor(1.4959, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8463, grad_fn=<DivBackward0>) tensor(1.4959, grad_fn=<MeanBackward0>) tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0081, 0.0000, 0.4152, 0.0000, 0.0000, 0.2638, 0.1631, 0.0000, 0.0465,\n",
      "         0.0369, 0.0665]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4958], grad_fn=<NegBackward0>) tensor(1.4958, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8463, grad_fn=<DivBackward0>) tensor(1.4958, grad_fn=<MeanBackward0>) tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0082, 0.0000, 0.4154, 0.0000, 0.0000, 0.2637, 0.1631, 0.0000, 0.0468,\n",
      "         0.0363, 0.0665]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4954], grad_fn=<NegBackward0>) tensor(1.4954, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8463, grad_fn=<DivBackward0>) tensor(1.4954, grad_fn=<MeanBackward0>) tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0082, 0.0000, 0.4156, 0.0000, 0.0000, 0.2639, 0.1630, 0.0000, 0.0471,\n",
      "         0.0358, 0.0664]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4946], grad_fn=<NegBackward0>) tensor(1.4946, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8463, grad_fn=<DivBackward0>) tensor(1.4946, grad_fn=<MeanBackward0>) tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0082, 0.0000, 0.4158, 0.0000, 0.0000, 0.2644, 0.1628, 0.0000, 0.0471,\n",
      "         0.0354, 0.0663]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4936], grad_fn=<NegBackward0>) tensor(1.4936, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8463, grad_fn=<DivBackward0>) tensor(1.4936, grad_fn=<MeanBackward0>) tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0081, 0.0000, 0.4161, 0.0000, 0.0000, 0.2649, 0.1625, 0.0000, 0.0471,\n",
      "         0.0351, 0.0662]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4923], grad_fn=<NegBackward0>) tensor(1.4923, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8463, grad_fn=<DivBackward0>) tensor(1.4923, grad_fn=<MeanBackward0>) tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0081, 0.0000, 0.4159, 0.0000, 0.0000, 0.2664, 0.1620, 0.0000, 0.0468,\n",
      "         0.0348, 0.0660]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4906], grad_fn=<NegBackward0>) tensor(1.4906, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8464, grad_fn=<DivBackward0>) tensor(1.4906, grad_fn=<MeanBackward0>) tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0080, 0.0000, 0.4164, 0.0000, 0.0000, 0.2669, 0.1615, 0.0000, 0.0466,\n",
      "         0.0346, 0.0660]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4891], grad_fn=<NegBackward0>) tensor(1.4891, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8464, grad_fn=<DivBackward0>) tensor(1.4891, grad_fn=<MeanBackward0>) tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0079, 0.0000, 0.4175, 0.0000, 0.0000, 0.2665, 0.1611, 0.0000, 0.0463,\n",
      "         0.0345, 0.0661]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4877], grad_fn=<NegBackward0>) tensor(1.4877, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8465, grad_fn=<DivBackward0>) tensor(1.4877, grad_fn=<MeanBackward0>) tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0079, 0.0000, 0.4182, 0.0000, 0.0000, 0.2670, 0.1603, 0.0000, 0.0460,\n",
      "         0.0345, 0.0660]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4861], grad_fn=<NegBackward0>) tensor(1.4861, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8465, grad_fn=<DivBackward0>) tensor(1.4861, grad_fn=<MeanBackward0>) tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0078, 0.0000, 0.4182, 0.0000, 0.0000, 0.2689, 0.1591, 0.0000, 0.0456,\n",
      "         0.0346, 0.0658]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4842], grad_fn=<NegBackward0>) tensor(1.4842, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8466, grad_fn=<DivBackward0>) tensor(1.4842, grad_fn=<MeanBackward0>) tensor(0.0180, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0077, 0.0000, 0.4182, 0.0000, 0.0000, 0.2708, 0.1578, 0.0000, 0.0453,\n",
      "         0.0346, 0.0656]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4823], grad_fn=<NegBackward0>) tensor(1.4823, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8468, grad_fn=<DivBackward0>) tensor(1.4823, grad_fn=<MeanBackward0>) tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0076, 0.0000, 0.4189, 0.0000, 0.0000, 0.2717, 0.1566, 0.0000, 0.0450,\n",
      "         0.0348, 0.0654]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4808], grad_fn=<NegBackward0>) tensor(1.4808, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4808, grad_fn=<MeanBackward0>) tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0075, 0.0000, 0.4198, 0.0000, 0.0000, 0.2719, 0.1557, 0.0000, 0.0448,\n",
      "         0.0351, 0.0652]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4795], grad_fn=<NegBackward0>) tensor(1.4795, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4795, grad_fn=<MeanBackward0>) tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0074, 0.0000, 0.4206, 0.0000, 0.0000, 0.2720, 0.1548, 0.0000, 0.0447,\n",
      "         0.0354, 0.0652]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4785], grad_fn=<NegBackward0>) tensor(1.4785, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8471, grad_fn=<DivBackward0>) tensor(1.4785, grad_fn=<MeanBackward0>) tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0073, 0.0000, 0.4210, 0.0000, 0.0000, 0.2724, 0.1541, 0.0000, 0.0445,\n",
      "         0.0356, 0.0651]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4777], grad_fn=<NegBackward0>) tensor(1.4777, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8472, grad_fn=<DivBackward0>) tensor(1.4777, grad_fn=<MeanBackward0>) tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4209, 0.0000, 0.0000, 0.2731, 0.1535, 0.0000, 0.0444,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4771], grad_fn=<NegBackward0>) tensor(1.4771, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8472, grad_fn=<DivBackward0>) tensor(1.4771, grad_fn=<MeanBackward0>) tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0071, 0.0000, 0.4207, 0.0000, 0.0000, 0.2738, 0.1532, 0.0000, 0.0443,\n",
      "         0.0360, 0.0649]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4766], grad_fn=<NegBackward0>) tensor(1.4766, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8473, grad_fn=<DivBackward0>) tensor(1.4766, grad_fn=<MeanBackward0>) tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0071, 0.0000, 0.4206, 0.0000, 0.0000, 0.2741, 0.1531, 0.0000, 0.0442,\n",
      "         0.0361, 0.0647]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4764], grad_fn=<NegBackward0>) tensor(1.4764, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8473, grad_fn=<DivBackward0>) tensor(1.4764, grad_fn=<MeanBackward0>) tensor(0.0166, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x tensor([[0.0070, 0.0000, 0.4208, 0.0000, 0.0000, 0.2739, 0.1532, 0.0000, 0.0443,\n",
      "         0.0362, 0.0646]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4763], grad_fn=<NegBackward0>) tensor(1.4763, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8473, grad_fn=<DivBackward0>) tensor(1.4763, grad_fn=<MeanBackward0>) tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0070, 0.0000, 0.4210, 0.0000, 0.0000, 0.2734, 0.1534, 0.0000, 0.0444,\n",
      "         0.0362, 0.0646]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4766], grad_fn=<NegBackward0>) tensor(1.4766, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8473, grad_fn=<DivBackward0>) tensor(1.4766, grad_fn=<MeanBackward0>) tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0070, 0.0000, 0.4211, 0.0000, 0.0000, 0.2728, 0.1535, 0.0000, 0.0445,\n",
      "         0.0363, 0.0648]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4770], grad_fn=<NegBackward0>) tensor(1.4770, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8472, grad_fn=<DivBackward0>) tensor(1.4770, grad_fn=<MeanBackward0>) tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0070, 0.0000, 0.4211, 0.0000, 0.0000, 0.2725, 0.1536, 0.0000, 0.0447,\n",
      "         0.0362, 0.0649]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4775], grad_fn=<NegBackward0>) tensor(1.4775, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8472, grad_fn=<DivBackward0>) tensor(1.4775, grad_fn=<MeanBackward0>) tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0070, 0.0000, 0.4208, 0.0000, 0.0000, 0.2726, 0.1536, 0.0000, 0.0449,\n",
      "         0.0362, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4779], grad_fn=<NegBackward0>) tensor(1.4779, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8472, grad_fn=<DivBackward0>) tensor(1.4779, grad_fn=<MeanBackward0>) tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0070, 0.0000, 0.4205, 0.0000, 0.0000, 0.2729, 0.1535, 0.0000, 0.0450,\n",
      "         0.0361, 0.0649]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4781], grad_fn=<NegBackward0>) tensor(1.4781, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8472, grad_fn=<DivBackward0>) tensor(1.4781, grad_fn=<MeanBackward0>) tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0070, 0.0000, 0.4204, 0.0000, 0.0000, 0.2730, 0.1536, 0.0000, 0.0451,\n",
      "         0.0360, 0.0648]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4782], grad_fn=<NegBackward0>) tensor(1.4782, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8472, grad_fn=<DivBackward0>) tensor(1.4782, grad_fn=<MeanBackward0>) tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0071, 0.0000, 0.4205, 0.0000, 0.0000, 0.2728, 0.1538, 0.0000, 0.0453,\n",
      "         0.0359, 0.0648]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4783], grad_fn=<NegBackward0>) tensor(1.4783, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8472, grad_fn=<DivBackward0>) tensor(1.4783, grad_fn=<MeanBackward0>) tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0071, 0.0000, 0.4207, 0.0000, 0.0000, 0.2722, 0.1540, 0.0000, 0.0454,\n",
      "         0.0358, 0.0649]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4785], grad_fn=<NegBackward0>) tensor(1.4785, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8471, grad_fn=<DivBackward0>) tensor(1.4785, grad_fn=<MeanBackward0>) tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0071, 0.0000, 0.4210, 0.0000, 0.0000, 0.2715, 0.1543, 0.0000, 0.0454,\n",
      "         0.0357, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4789], grad_fn=<NegBackward0>) tensor(1.4789, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8471, grad_fn=<DivBackward0>) tensor(1.4789, grad_fn=<MeanBackward0>) tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4211, 0.0000, 0.0000, 0.2709, 0.1545, 0.0000, 0.0454,\n",
      "         0.0356, 0.0652]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4792], grad_fn=<NegBackward0>) tensor(1.4792, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8471, grad_fn=<DivBackward0>) tensor(1.4792, grad_fn=<MeanBackward0>) tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4211, 0.0000, 0.0000, 0.2708, 0.1547, 0.0000, 0.0454,\n",
      "         0.0356, 0.0653]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4794], grad_fn=<NegBackward0>) tensor(1.4794, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4794, grad_fn=<MeanBackward0>) tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4208, 0.0000, 0.0000, 0.2710, 0.1549, 0.0000, 0.0454,\n",
      "         0.0355, 0.0652]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4795], grad_fn=<NegBackward0>) tensor(1.4795, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4795, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4205, 0.0000, 0.0000, 0.2714, 0.1550, 0.0000, 0.0453,\n",
      "         0.0355, 0.0651]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4794], grad_fn=<NegBackward0>) tensor(1.4794, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4794, grad_fn=<MeanBackward0>) tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4202, 0.0000, 0.0000, 0.2718, 0.1551, 0.0000, 0.0452,\n",
      "         0.0355, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4792], grad_fn=<NegBackward0>) tensor(1.4792, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4792, grad_fn=<MeanBackward0>) tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0073, 0.0000, 0.4201, 0.0000, 0.0000, 0.2719, 0.1551, 0.0000, 0.0452,\n",
      "         0.0354, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4792], grad_fn=<NegBackward0>) tensor(1.4792, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4792, grad_fn=<MeanBackward0>) tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4201, 0.0000, 0.0000, 0.2719, 0.1551, 0.0000, 0.0452,\n",
      "         0.0355, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4793], grad_fn=<NegBackward0>) tensor(1.4793, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4793, grad_fn=<MeanBackward0>) tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4202, 0.0000, 0.0000, 0.2717, 0.1550, 0.0000, 0.0452,\n",
      "         0.0355, 0.0652]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4794], grad_fn=<NegBackward0>) tensor(1.4794, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4794, grad_fn=<MeanBackward0>) tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4203, 0.0000, 0.0000, 0.2715, 0.1550, 0.0000, 0.0452,\n",
      "         0.0355, 0.0652]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4794], grad_fn=<NegBackward0>) tensor(1.4794, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4794, grad_fn=<MeanBackward0>) tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4203, 0.0000, 0.0000, 0.2716, 0.1549, 0.0000, 0.0452,\n",
      "         0.0356, 0.0652]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4794], grad_fn=<NegBackward0>) tensor(1.4794, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4794, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4203, 0.0000, 0.0000, 0.2718, 0.1548, 0.0000, 0.0452,\n",
      "         0.0356, 0.0651]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4793], grad_fn=<NegBackward0>) tensor(1.4793, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4793, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4201, 0.0000, 0.0000, 0.2721, 0.1548, 0.0000, 0.0452,\n",
      "         0.0357, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4792], grad_fn=<NegBackward0>) tensor(1.4792, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4792, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4199, 0.0000, 0.0000, 0.2724, 0.1548, 0.0000, 0.0451,\n",
      "         0.0357, 0.0649]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4792], grad_fn=<NegBackward0>) tensor(1.4792, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4792, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4198, 0.0000, 0.0000, 0.2724, 0.1547, 0.0000, 0.0451,\n",
      "         0.0358, 0.0649]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4794], grad_fn=<NegBackward0>) tensor(1.4794, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4794, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4198, 0.0000, 0.0000, 0.2723, 0.1547, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4796], grad_fn=<NegBackward0>) tensor(1.4796, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4796, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4199, 0.0000, 0.0000, 0.2721, 0.1548, 0.0000, 0.0451,\n",
      "         0.0359, 0.0651]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4199, 0.0000, 0.0000, 0.2720, 0.1548, 0.0000, 0.0451,\n",
      "         0.0359, 0.0651]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4799], grad_fn=<NegBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>) tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4199, 0.0000, 0.0000, 0.2720, 0.1548, 0.0000, 0.0450,\n",
      "         0.0359, 0.0651]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4199, 0.0000, 0.0000, 0.2721, 0.1548, 0.0000, 0.0450,\n",
      "         0.0359, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4199, 0.0000, 0.0000, 0.2722, 0.1548, 0.0000, 0.0450,\n",
      "         0.0359, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4797], grad_fn=<NegBackward0>) tensor(1.4797, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4797, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4199, 0.0000, 0.0000, 0.2722, 0.1548, 0.0000, 0.0450,\n",
      "         0.0359, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4796], grad_fn=<NegBackward0>) tensor(1.4796, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4796, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4200, 0.0000, 0.0000, 0.2721, 0.1548, 0.0000, 0.0450,\n",
      "         0.0359, 0.0651]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4795], grad_fn=<NegBackward0>) tensor(1.4795, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4795, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x tensor([[0.0072, 0.0000, 0.4202, 0.0000, 0.0000, 0.2719, 0.1548, 0.0000, 0.0451,\n",
      "         0.0359, 0.0651]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4794], grad_fn=<NegBackward0>) tensor(1.4794, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4794, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4203, 0.0000, 0.0000, 0.2718, 0.1548, 0.0000, 0.0451,\n",
      "         0.0358, 0.0651]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4794], grad_fn=<NegBackward0>) tensor(1.4794, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4794, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4204, 0.0000, 0.0000, 0.2717, 0.1548, 0.0000, 0.0451,\n",
      "         0.0358, 0.0651]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4793], grad_fn=<NegBackward0>) tensor(1.4793, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4793, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4204, 0.0000, 0.0000, 0.2717, 0.1548, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4793], grad_fn=<NegBackward0>) tensor(1.4793, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4793, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4203, 0.0000, 0.0000, 0.2718, 0.1548, 0.0000, 0.0451,\n",
      "         0.0357, 0.0651]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4793], grad_fn=<NegBackward0>) tensor(1.4793, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4793, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4203, 0.0000, 0.0000, 0.2718, 0.1548, 0.0000, 0.0451,\n",
      "         0.0357, 0.0651]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4794], grad_fn=<NegBackward0>) tensor(1.4794, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4794, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4203, 0.0000, 0.0000, 0.2718, 0.1548, 0.0000, 0.0452,\n",
      "         0.0357, 0.0651]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4793], grad_fn=<NegBackward0>) tensor(1.4793, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4793, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4203, 0.0000, 0.0000, 0.2718, 0.1548, 0.0000, 0.0452,\n",
      "         0.0357, 0.0651]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4793], grad_fn=<NegBackward0>) tensor(1.4793, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4793, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4204, 0.0000, 0.0000, 0.2718, 0.1548, 0.0000, 0.0452,\n",
      "         0.0357, 0.0651]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4792], grad_fn=<NegBackward0>) tensor(1.4792, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4792, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4204, 0.0000, 0.0000, 0.2718, 0.1547, 0.0000, 0.0451,\n",
      "         0.0357, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4792], grad_fn=<NegBackward0>) tensor(1.4792, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4792, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4204, 0.0000, 0.0000, 0.2719, 0.1547, 0.0000, 0.0451,\n",
      "         0.0357, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4791], grad_fn=<NegBackward0>) tensor(1.4791, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4791, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4204, 0.0000, 0.0000, 0.2720, 0.1546, 0.0000, 0.0451,\n",
      "         0.0357, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4790], grad_fn=<NegBackward0>) tensor(1.4790, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4790, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4203, 0.0000, 0.0000, 0.2721, 0.1546, 0.0000, 0.0451,\n",
      "         0.0357, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4789], grad_fn=<NegBackward0>) tensor(1.4789, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4789, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4203, 0.0000, 0.0000, 0.2721, 0.1546, 0.0000, 0.0450,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4789], grad_fn=<NegBackward0>) tensor(1.4789, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4789, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4204, 0.0000, 0.0000, 0.2721, 0.1545, 0.0000, 0.0450,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4789], grad_fn=<NegBackward0>) tensor(1.4789, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4789, grad_fn=<MeanBackward0>) tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4204, 0.0000, 0.0000, 0.2721, 0.1546, 0.0000, 0.0450,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4789], grad_fn=<NegBackward0>) tensor(1.4789, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4789, grad_fn=<MeanBackward0>) tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4204, 0.0000, 0.0000, 0.2720, 0.1546, 0.0000, 0.0450,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4790], grad_fn=<NegBackward0>) tensor(1.4790, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4790, grad_fn=<MeanBackward0>) tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4203, 0.0000, 0.0000, 0.2720, 0.1546, 0.0000, 0.0450,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4791], grad_fn=<NegBackward0>) tensor(1.4791, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4791, grad_fn=<MeanBackward0>) tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4202, 0.0000, 0.0000, 0.2721, 0.1546, 0.0000, 0.0450,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4792], grad_fn=<NegBackward0>) tensor(1.4792, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4792, grad_fn=<MeanBackward0>) tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4202, 0.0000, 0.0000, 0.2721, 0.1547, 0.0000, 0.0450,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4793], grad_fn=<NegBackward0>) tensor(1.4793, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4793, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4201, 0.0000, 0.0000, 0.2721, 0.1547, 0.0000, 0.0450,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4793], grad_fn=<NegBackward0>) tensor(1.4793, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4793, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4201, 0.0000, 0.0000, 0.2720, 0.1548, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4794], grad_fn=<NegBackward0>) tensor(1.4794, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4794, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4201, 0.0000, 0.0000, 0.2719, 0.1548, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4795], grad_fn=<NegBackward0>) tensor(1.4795, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4795, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4201, 0.0000, 0.0000, 0.2719, 0.1548, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4795], grad_fn=<NegBackward0>) tensor(1.4795, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4795, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4201, 0.0000, 0.0000, 0.2719, 0.1548, 0.0000, 0.0451,\n",
      "         0.0358, 0.0651]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4796], grad_fn=<NegBackward0>) tensor(1.4796, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4796, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4201, 0.0000, 0.0000, 0.2719, 0.1549, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4796], grad_fn=<NegBackward0>) tensor(1.4796, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4796, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4200, 0.0000, 0.0000, 0.2719, 0.1549, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4796], grad_fn=<NegBackward0>) tensor(1.4796, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4796, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4200, 0.0000, 0.0000, 0.2720, 0.1549, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4796], grad_fn=<NegBackward0>) tensor(1.4796, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4796, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4200, 0.0000, 0.0000, 0.2720, 0.1549, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4796], grad_fn=<NegBackward0>) tensor(1.4796, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4796, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4200, 0.0000, 0.0000, 0.2719, 0.1549, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4796], grad_fn=<NegBackward0>) tensor(1.4796, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4796, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4200, 0.0000, 0.0000, 0.2719, 0.1549, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4796], grad_fn=<NegBackward0>) tensor(1.4796, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4796, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4201, 0.0000, 0.0000, 0.2719, 0.1549, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4796], grad_fn=<NegBackward0>) tensor(1.4796, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4796, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x tensor([[0.0072, 0.0000, 0.4201, 0.0000, 0.0000, 0.2720, 0.1548, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4795], grad_fn=<NegBackward0>) tensor(1.4795, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4795, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4201, 0.0000, 0.0000, 0.2720, 0.1548, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4795], grad_fn=<NegBackward0>) tensor(1.4795, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4795, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4200, 0.0000, 0.0000, 0.2721, 0.1548, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4794], grad_fn=<NegBackward0>) tensor(1.4794, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4794, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4200, 0.0000, 0.0000, 0.2721, 0.1548, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4794], grad_fn=<NegBackward0>) tensor(1.4794, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4794, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4201, 0.0000, 0.0000, 0.2721, 0.1548, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4794], grad_fn=<NegBackward0>) tensor(1.4794, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4794, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4201, 0.0000, 0.0000, 0.2721, 0.1547, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4794], grad_fn=<NegBackward0>) tensor(1.4794, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4794, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4201, 0.0000, 0.0000, 0.2721, 0.1548, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4794], grad_fn=<NegBackward0>) tensor(1.4794, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4794, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4200, 0.0000, 0.0000, 0.2721, 0.1548, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4794], grad_fn=<NegBackward0>) tensor(1.4794, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4794, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4200, 0.0000, 0.0000, 0.2721, 0.1548, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4794], grad_fn=<NegBackward0>) tensor(1.4794, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4794, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4200, 0.0000, 0.0000, 0.2721, 0.1548, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4794], grad_fn=<NegBackward0>) tensor(1.4794, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4794, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4200, 0.0000, 0.0000, 0.2721, 0.1548, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4795], grad_fn=<NegBackward0>) tensor(1.4795, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4795, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4200, 0.0000, 0.0000, 0.2721, 0.1548, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4795], grad_fn=<NegBackward0>) tensor(1.4795, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4795, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4200, 0.0000, 0.0000, 0.2721, 0.1548, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4795], grad_fn=<NegBackward0>) tensor(1.4795, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4795, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4200, 0.0000, 0.0000, 0.2720, 0.1548, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4796], grad_fn=<NegBackward0>) tensor(1.4796, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4796, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4199, 0.0000, 0.0000, 0.2720, 0.1548, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4797], grad_fn=<NegBackward0>) tensor(1.4797, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4797, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4199, 0.0000, 0.0000, 0.2720, 0.1548, 0.0000, 0.0453,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4199, 0.0000, 0.0000, 0.2720, 0.1549, 0.0000, 0.0453,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4799], grad_fn=<NegBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4199, 0.0000, 0.0000, 0.2719, 0.1549, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4199, 0.0000, 0.0000, 0.2719, 0.1550, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4199, 0.0000, 0.0000, 0.2719, 0.1550, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4199, 0.0000, 0.0000, 0.2719, 0.1550, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4199, 0.0000, 0.0000, 0.2719, 0.1549, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4799], grad_fn=<NegBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4199, 0.0000, 0.0000, 0.2720, 0.1549, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4799], grad_fn=<NegBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4198, 0.0000, 0.0000, 0.2720, 0.1549, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4799], grad_fn=<NegBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4198, 0.0000, 0.0000, 0.2720, 0.1549, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4799], grad_fn=<NegBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4198, 0.0000, 0.0000, 0.2720, 0.1549, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4198, 0.0000, 0.0000, 0.2720, 0.1549, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4198, 0.0000, 0.0000, 0.2721, 0.1549, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1549, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4196, 0.0000, 0.0000, 0.2723, 0.1549, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4196, 0.0000, 0.0000, 0.2723, 0.1549, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4196, 0.0000, 0.0000, 0.2724, 0.1549, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x tensor([[0.0072, 0.0000, 0.4196, 0.0000, 0.0000, 0.2724, 0.1549, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4196, 0.0000, 0.0000, 0.2724, 0.1550, 0.0000, 0.0451,\n",
      "         0.0357, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4799], grad_fn=<NegBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4196, 0.0000, 0.0000, 0.2723, 0.1550, 0.0000, 0.0451,\n",
      "         0.0357, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4799], grad_fn=<NegBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4196, 0.0000, 0.0000, 0.2723, 0.1550, 0.0000, 0.0451,\n",
      "         0.0357, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4799], grad_fn=<NegBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4196, 0.0000, 0.0000, 0.2723, 0.1550, 0.0000, 0.0452,\n",
      "         0.0357, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4800], grad_fn=<NegBackward0>) tensor(1.4800, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4800, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4195, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0452,\n",
      "         0.0357, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4800], grad_fn=<NegBackward0>) tensor(1.4800, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4800, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4195, 0.0000, 0.0000, 0.2722, 0.1551, 0.0000, 0.0452,\n",
      "         0.0357, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4801], grad_fn=<NegBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4196, 0.0000, 0.0000, 0.2721, 0.1551, 0.0000, 0.0452,\n",
      "         0.0357, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4801], grad_fn=<NegBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4196, 0.0000, 0.0000, 0.2721, 0.1551, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4801], grad_fn=<NegBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4196, 0.0000, 0.0000, 0.2721, 0.1551, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4801], grad_fn=<NegBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4196, 0.0000, 0.0000, 0.2720, 0.1551, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4802], grad_fn=<NegBackward0>) tensor(1.4802, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4802, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4196, 0.0000, 0.0000, 0.2720, 0.1551, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4802], grad_fn=<NegBackward0>) tensor(1.4802, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4802, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4196, 0.0000, 0.0000, 0.2720, 0.1551, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4802], grad_fn=<NegBackward0>) tensor(1.4802, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4802, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4196, 0.0000, 0.0000, 0.2720, 0.1551, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4802], grad_fn=<NegBackward0>) tensor(1.4802, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4802, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2720, 0.1551, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4802], grad_fn=<NegBackward0>) tensor(1.4802, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4802, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2720, 0.1551, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4801], grad_fn=<NegBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2720, 0.1551, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4801], grad_fn=<NegBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2720, 0.1550, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4800], grad_fn=<NegBackward0>) tensor(1.4800, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4800, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2720, 0.1550, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4800], grad_fn=<NegBackward0>) tensor(1.4800, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4800, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2720, 0.1550, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4800], grad_fn=<NegBackward0>) tensor(1.4800, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4800, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2721, 0.1550, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4800], grad_fn=<NegBackward0>) tensor(1.4800, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4800, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2721, 0.1550, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4800], grad_fn=<NegBackward0>) tensor(1.4800, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4800, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2721, 0.1550, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4800], grad_fn=<NegBackward0>) tensor(1.4800, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4800, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2721, 0.1550, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4800], grad_fn=<NegBackward0>) tensor(1.4800, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4800, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2721, 0.1550, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4800], grad_fn=<NegBackward0>) tensor(1.4800, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4800, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2721, 0.1550, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4800], grad_fn=<NegBackward0>) tensor(1.4800, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4800, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4196, 0.0000, 0.0000, 0.2721, 0.1550, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4800], grad_fn=<NegBackward0>) tensor(1.4800, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4800, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4196, 0.0000, 0.0000, 0.2721, 0.1550, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4800], grad_fn=<NegBackward0>) tensor(1.4800, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4800, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4196, 0.0000, 0.0000, 0.2721, 0.1550, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4801], grad_fn=<NegBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4196, 0.0000, 0.0000, 0.2721, 0.1550, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4801], grad_fn=<NegBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4196, 0.0000, 0.0000, 0.2721, 0.1550, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4801], grad_fn=<NegBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4196, 0.0000, 0.0000, 0.2721, 0.1551, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4801], grad_fn=<NegBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x tensor([[0.0072, 0.0000, 0.4196, 0.0000, 0.0000, 0.2721, 0.1551, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4801], grad_fn=<NegBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4196, 0.0000, 0.0000, 0.2721, 0.1551, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4801], grad_fn=<NegBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4196, 0.0000, 0.0000, 0.2721, 0.1551, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4801], grad_fn=<NegBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4196, 0.0000, 0.0000, 0.2721, 0.1550, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4801], grad_fn=<NegBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4196, 0.0000, 0.0000, 0.2721, 0.1550, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4801], grad_fn=<NegBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4196, 0.0000, 0.0000, 0.2721, 0.1550, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4801], grad_fn=<NegBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4196, 0.0000, 0.0000, 0.2721, 0.1550, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4801], grad_fn=<NegBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4196, 0.0000, 0.0000, 0.2721, 0.1550, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4801], grad_fn=<NegBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4196, 0.0000, 0.0000, 0.2721, 0.1550, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4801], grad_fn=<NegBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4196, 0.0000, 0.0000, 0.2721, 0.1550, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4801], grad_fn=<NegBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4196, 0.0000, 0.0000, 0.2721, 0.1550, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4801], grad_fn=<NegBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4196, 0.0000, 0.0000, 0.2721, 0.1551, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4801], grad_fn=<NegBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4196, 0.0000, 0.0000, 0.2721, 0.1551, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4801], grad_fn=<NegBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4196, 0.0000, 0.0000, 0.2721, 0.1551, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4801], grad_fn=<NegBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4196, 0.0000, 0.0000, 0.2721, 0.1551, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4801], grad_fn=<NegBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4196, 0.0000, 0.0000, 0.2721, 0.1551, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4801], grad_fn=<NegBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4196, 0.0000, 0.0000, 0.2721, 0.1551, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4801], grad_fn=<NegBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4196, 0.0000, 0.0000, 0.2721, 0.1551, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4801], grad_fn=<NegBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4196, 0.0000, 0.0000, 0.2721, 0.1551, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4801], grad_fn=<NegBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4196, 0.0000, 0.0000, 0.2721, 0.1551, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4801], grad_fn=<NegBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4196, 0.0000, 0.0000, 0.2721, 0.1551, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4801], grad_fn=<NegBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4196, 0.0000, 0.0000, 0.2721, 0.1551, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4801], grad_fn=<NegBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4196, 0.0000, 0.0000, 0.2721, 0.1551, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4801], grad_fn=<NegBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4196, 0.0000, 0.0000, 0.2721, 0.1551, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4801], grad_fn=<NegBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4196, 0.0000, 0.0000, 0.2721, 0.1551, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4801], grad_fn=<NegBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4196, 0.0000, 0.0000, 0.2721, 0.1551, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4801], grad_fn=<NegBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4196, 0.0000, 0.0000, 0.2721, 0.1551, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4801], grad_fn=<NegBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4196, 0.0000, 0.0000, 0.2721, 0.1550, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4801], grad_fn=<NegBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4196, 0.0000, 0.0000, 0.2721, 0.1550, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4801], grad_fn=<NegBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4196, 0.0000, 0.0000, 0.2721, 0.1550, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4801], grad_fn=<NegBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x tensor([[0.0072, 0.0000, 0.4196, 0.0000, 0.0000, 0.2721, 0.1550, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4801], grad_fn=<NegBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4196, 0.0000, 0.0000, 0.2721, 0.1550, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4801], grad_fn=<NegBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4196, 0.0000, 0.0000, 0.2721, 0.1550, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4801], grad_fn=<NegBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4196, 0.0000, 0.0000, 0.2721, 0.1550, 0.0000, 0.0452,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4801], grad_fn=<NegBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[7.2344e-03, 0.0000e+00, 4.1961e-01, 0.0000e+00, 0.0000e+00, 2.7211e-01,\n",
      "         1.5505e-01, 3.8275e-07, 4.5196e-02, 3.5781e-02, 6.5024e-02]],\n",
      "       grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4801], grad_fn=<NegBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0073, 0.0000, 0.4194, 0.0000, 0.0000, 0.2718, 0.1556, 0.0000, 0.0453,\n",
      "         0.0357, 0.0648]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4806], grad_fn=<NegBackward0>) tensor(1.4806, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4806, grad_fn=<MeanBackward0>) tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0074, 0.0000, 0.4193, 0.0000, 0.0000, 0.2714, 0.1560, 0.0000, 0.0454,\n",
      "         0.0357, 0.0649]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4812], grad_fn=<NegBackward0>) tensor(1.4812, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8468, grad_fn=<DivBackward0>) tensor(1.4812, grad_fn=<MeanBackward0>) tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0074, 0.0000, 0.4192, 0.0000, 0.0000, 0.2710, 0.1560, 0.0000, 0.0456,\n",
      "         0.0356, 0.0651]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4820], grad_fn=<NegBackward0>) tensor(1.4820, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8468, grad_fn=<DivBackward0>) tensor(1.4820, grad_fn=<MeanBackward0>) tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0074, 0.0000, 0.4193, 0.0000, 0.0000, 0.2708, 0.1559, 0.0000, 0.0458,\n",
      "         0.0356, 0.0653]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4823], grad_fn=<NegBackward0>) tensor(1.4823, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8468, grad_fn=<DivBackward0>) tensor(1.4823, grad_fn=<MeanBackward0>) tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0073, 0.0000, 0.4193, 0.0000, 0.0000, 0.2709, 0.1558, 0.0000, 0.0457,\n",
      "         0.0356, 0.0653]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4819], grad_fn=<NegBackward0>) tensor(1.4819, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8468, grad_fn=<DivBackward0>) tensor(1.4819, grad_fn=<MeanBackward0>) tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0073, 0.0000, 0.4194, 0.0000, 0.0000, 0.2713, 0.1557, 0.0000, 0.0455,\n",
      "         0.0356, 0.0652]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4811], grad_fn=<NegBackward0>) tensor(1.4811, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4811, grad_fn=<MeanBackward0>) tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4195, 0.0000, 0.0000, 0.2718, 0.1555, 0.0000, 0.0453,\n",
      "         0.0356, 0.0651]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4802], grad_fn=<NegBackward0>) tensor(1.4802, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4802, grad_fn=<MeanBackward0>) tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4195, 0.0000, 0.0000, 0.2721, 0.1554, 0.0000, 0.0452,\n",
      "         0.0357, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4799], grad_fn=<NegBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>) tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4196, 0.0000, 0.0000, 0.2721, 0.1553, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2719, 0.1553, 0.0000, 0.0450,\n",
      "         0.0359, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4198, 0.0000, 0.0000, 0.2719, 0.1552, 0.0000, 0.0450,\n",
      "         0.0359, 0.0649]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0073, 0.0000, 0.4198, 0.0000, 0.0000, 0.2720, 0.1551, 0.0000, 0.0450,\n",
      "         0.0360, 0.0649]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4800], grad_fn=<NegBackward0>) tensor(1.4800, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4800, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0073, 0.0000, 0.4196, 0.0000, 0.0000, 0.2722, 0.1549, 0.0000, 0.0450,\n",
      "         0.0360, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4802], grad_fn=<NegBackward0>) tensor(1.4802, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4802, grad_fn=<MeanBackward0>) tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0073, 0.0000, 0.4195, 0.0000, 0.0000, 0.2724, 0.1547, 0.0000, 0.0450,\n",
      "         0.0360, 0.0651]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4804], grad_fn=<NegBackward0>) tensor(1.4804, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4804, grad_fn=<MeanBackward0>) tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0073, 0.0000, 0.4195, 0.0000, 0.0000, 0.2724, 0.1547, 0.0000, 0.0450,\n",
      "         0.0360, 0.0651]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4803], grad_fn=<NegBackward0>) tensor(1.4803, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4803, grad_fn=<MeanBackward0>) tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4195, 0.0000, 0.0000, 0.2724, 0.1548, 0.0000, 0.0451,\n",
      "         0.0359, 0.0651]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4801], grad_fn=<NegBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>) tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4196, 0.0000, 0.0000, 0.2723, 0.1549, 0.0000, 0.0451,\n",
      "         0.0359, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4799], grad_fn=<NegBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4196, 0.0000, 0.0000, 0.2723, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4797], grad_fn=<NegBackward0>) tensor(1.4797, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4797, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4196, 0.0000, 0.0000, 0.2723, 0.1551, 0.0000, 0.0451,\n",
      "         0.0357, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4796], grad_fn=<NegBackward0>) tensor(1.4796, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4796, grad_fn=<MeanBackward0>) tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4196, 0.0000, 0.0000, 0.2723, 0.1552, 0.0000, 0.0451,\n",
      "         0.0357, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4797], grad_fn=<NegBackward0>) tensor(1.4797, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4797, grad_fn=<MeanBackward0>) tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0073, 0.0000, 0.4196, 0.0000, 0.0000, 0.2722, 0.1552, 0.0000, 0.0451,\n",
      "         0.0357, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4799], grad_fn=<NegBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>) tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0073, 0.0000, 0.4196, 0.0000, 0.0000, 0.2721, 0.1552, 0.0000, 0.0451,\n",
      "         0.0357, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4800], grad_fn=<NegBackward0>) tensor(1.4800, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4800, grad_fn=<MeanBackward0>) tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0073, 0.0000, 0.4196, 0.0000, 0.0000, 0.2720, 0.1552, 0.0000, 0.0451,\n",
      "         0.0357, 0.0651]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4802], grad_fn=<NegBackward0>) tensor(1.4802, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4802, grad_fn=<MeanBackward0>) tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0073, 0.0000, 0.4196, 0.0000, 0.0000, 0.2720, 0.1551, 0.0000, 0.0451,\n",
      "         0.0357, 0.0651]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4803], grad_fn=<NegBackward0>) tensor(1.4803, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4803, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0073, 0.0000, 0.4196, 0.0000, 0.0000, 0.2721, 0.1551, 0.0000, 0.0451,\n",
      "         0.0357, 0.0651]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4803], grad_fn=<NegBackward0>) tensor(1.4803, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4803, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0073, 0.0000, 0.4196, 0.0000, 0.0000, 0.2721, 0.1551, 0.0000, 0.0451,\n",
      "         0.0358, 0.0651]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4801], grad_fn=<NegBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4801, grad_fn=<MeanBackward0>) tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2721, 0.1551, 0.0000, 0.0451,\n",
      "         0.0358, 0.0651]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4799], grad_fn=<NegBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>) tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4198, 0.0000, 0.0000, 0.2721, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4797], grad_fn=<NegBackward0>) tensor(1.4797, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4797, grad_fn=<MeanBackward0>) tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4198, 0.0000, 0.0000, 0.2721, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4796], grad_fn=<NegBackward0>) tensor(1.4796, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4796, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4198, 0.0000, 0.0000, 0.2722, 0.1549, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4796], grad_fn=<NegBackward0>) tensor(1.4796, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4796, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4198, 0.0000, 0.0000, 0.2723, 0.1548, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4796], grad_fn=<NegBackward0>) tensor(1.4796, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4796, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4198, 0.0000, 0.0000, 0.2724, 0.1548, 0.0000, 0.0451,\n",
      "         0.0358, 0.0649]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4796], grad_fn=<NegBackward0>) tensor(1.4796, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4796, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4198, 0.0000, 0.0000, 0.2723, 0.1548, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4796], grad_fn=<NegBackward0>) tensor(1.4796, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4796, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4198, 0.0000, 0.0000, 0.2723, 0.1548, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4797], grad_fn=<NegBackward0>) tensor(1.4797, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4797, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4199, 0.0000, 0.0000, 0.2721, 0.1549, 0.0000, 0.0450,\n",
      "         0.0358, 0.0651]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4797], grad_fn=<NegBackward0>) tensor(1.4797, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8470, grad_fn=<DivBackward0>) tensor(1.4797, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4199, 0.0000, 0.0000, 0.2721, 0.1549, 0.0000, 0.0450,\n",
      "         0.0358, 0.0651]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4796], grad_fn=<NegBackward0>) tensor(1.4796, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4796, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4199, 0.0000, 0.0000, 0.2721, 0.1549, 0.0000, 0.0450,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4796], grad_fn=<NegBackward0>) tensor(1.4796, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4796, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4199, 0.0000, 0.0000, 0.2722, 0.1549, 0.0000, 0.0450,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4795], grad_fn=<NegBackward0>) tensor(1.4795, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4795, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4198, 0.0000, 0.0000, 0.2722, 0.1549, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4796], grad_fn=<NegBackward0>) tensor(1.4796, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4796, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4198, 0.0000, 0.0000, 0.2722, 0.1549, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4796], grad_fn=<NegBackward0>) tensor(1.4796, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4796, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4198, 0.0000, 0.0000, 0.2722, 0.1549, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4797], grad_fn=<NegBackward0>) tensor(1.4797, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4797, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4198, 0.0000, 0.0000, 0.2721, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2721, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2721, 0.1551, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4799], grad_fn=<NegBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2721, 0.1551, 0.0000, 0.0451,\n",
      "         0.0358, 0.0651]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4799], grad_fn=<NegBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>) tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2721, 0.1551, 0.0000, 0.0451,\n",
      "         0.0358, 0.0651]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4799], grad_fn=<NegBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>) tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2721, 0.1551, 0.0000, 0.0451,\n",
      "         0.0358, 0.0651]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4799], grad_fn=<NegBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2721, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4799], grad_fn=<NegBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4799], grad_fn=<NegBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4799], grad_fn=<NegBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4799], grad_fn=<NegBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2721, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4799], grad_fn=<NegBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2721, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4799], grad_fn=<NegBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2721, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4799], grad_fn=<NegBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2721, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4799], grad_fn=<NegBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2721, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2721, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4799], grad_fn=<NegBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2721, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4799], grad_fn=<NegBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2721, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4799], grad_fn=<NegBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2721, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4799], grad_fn=<NegBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4799], grad_fn=<NegBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4799], grad_fn=<NegBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4799], grad_fn=<NegBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4799], grad_fn=<NegBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4799], grad_fn=<NegBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4799], grad_fn=<NegBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4799], grad_fn=<NegBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4799], grad_fn=<NegBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4799], grad_fn=<NegBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4798], grad_fn=<NegBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4798, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4799], grad_fn=<NegBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4799], grad_fn=<NegBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4799], grad_fn=<NegBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4799], grad_fn=<NegBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4799], grad_fn=<NegBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4799], grad_fn=<NegBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4799], grad_fn=<NegBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4799], grad_fn=<NegBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4799], grad_fn=<NegBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4799], grad_fn=<NegBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4799], grad_fn=<NegBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4799], grad_fn=<NegBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "x tensor([[0.0072, 0.0000, 0.4197, 0.0000, 0.0000, 0.2722, 0.1550, 0.0000, 0.0451,\n",
      "         0.0358, 0.0650]], grad_fn=<SumBackward1>)\n",
      "entropy tensor([1.4799], grad_fn=<NegBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>)\n",
      "loss tensor(0.8469, grad_fn=<DivBackward0>) tensor(1.4799, grad_fn=<MeanBackward0>) tensor(0.0169, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "sample = sample.optimize(num_epoch=500, print_prog=True, loss_weight=loss_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 899,
   "id": "26e4861c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: # 72\n",
      "                  Name     Entry_id  fraction     shift  width\n",
      "0                Bi2O3  00-059-0331  0.328163  0.021654   0.03\n",
      "1              Bi(VO4)  04-010-5713  0.077703  0.005906   0.03\n",
      "2           BiV1.025O4  00-044-0081  0.072590  0.005906   0.03\n",
      "3              Bi(VO4)  04-010-5710  0.135492  0.011811   0.03\n",
      "4         Bi3V4.2O15.5  00-058-0430  0.134774  0.007874   0.03\n",
      "5             Cu2VBiO6  04-012-3857  0.013421 -0.001969   0.03\n",
      "6           Cu1.3V9O22  00-046-0362  0.045345  0.001969   0.03\n",
      "7             Bi11VO19  00-045-0363  0.031087  0.049214   0.03\n",
      "8            Bi17V3O33  00-052-1476  0.019813  0.049214   0.03\n",
      "9   Bi7.38Cu0.62O11.69  00-049-1765  0.012962  0.025591   0.03\n",
      "10                Cu2O  01-078-2076  0.021523 -0.047245   0.03\n",
      "11            V3Bi6O16  04-014-9744  0.010891 -0.015748   0.03\n",
      "12            VBi2O5.5  04-007-5482  0.007926 -0.009843   0.03\n",
      "13               Bi2O3  04-015-6853  0.010174  0.021654   0.03\n",
      "14            Bi2VO5.5  01-088-0870  0.008619 -0.011811   0.03\n",
      "15        Bi4(V2O11.2)  01-074-7536  0.009830  0.007874   0.03\n",
      "16            V2Bi4O11  04-011-3627  0.003561 -0.009843   0.03\n",
      "17            Cu3(VO4)  04-016-3668  0.010737 -0.043308   0.03\n",
      "18               Bi4O7  00-047-1058  0.003056  0.047245   0.03\n",
      "19                Cu2O  04-020-7578  0.010218  0.021654   0.03\n",
      "20                 CuO  00-041-0254  0.003326 -0.029528   0.03\n",
      "21            Bi2VO5.5  00-051-0032  0.004567  0.007874   0.03\n",
      "22           Cu2(V2O7)  01-078-2581  0.002710  0.033466   0.03\n",
      "23                 VO2  04-003-2035  0.005066  0.049214   0.03\n",
      "24            Bi8V2O17  00-044-0171  0.004146  0.039371   0.03\n",
      "25               V0.9O  04-010-5832  0.007314 -0.011811   0.03\n",
      "26                 VO2  01-076-0675  0.004986  0.041340   0.03\n",
      "Current R^2 = 467113.43671012786\n"
     ]
    }
   ],
   "source": [
    "sample.print_solution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 896,
   "id": "27c96ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sample = deepcopy(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 897,
   "id": "86547252",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sample.prune_candidates_based_on_composition(cutoff=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 894,
   "id": "a20b0f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sample.update_solution(0.03, 0.2999, new_sample.max_q_shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56185022",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 898,
   "id": "d3b3fcc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: # 72\n",
      "                  Name     Entry_id  fraction     shift  width\n",
      "0                Bi2O3  00-059-0331  0.340089  0.021654   0.03\n",
      "1              Bi(VO4)  04-010-5713  0.080527  0.005906   0.03\n",
      "2           BiV1.025O4  00-044-0081  0.075228  0.005906   0.03\n",
      "3              Bi(VO4)  04-010-5710  0.140417  0.011811   0.03\n",
      "4         Bi3V4.2O15.5  00-058-0430  0.139672  0.007874   0.03\n",
      "5             Cu2VBiO6  04-012-3857  0.013909 -0.001969   0.03\n",
      "6           Cu1.3V9O22  00-046-0362  0.046993  0.001969   0.03\n",
      "7             Bi11VO19  00-045-0363  0.032217  0.049214   0.03\n",
      "8            Bi17V3O33  00-052-1476  0.020533  0.049214   0.03\n",
      "9   Bi7.38Cu0.62O11.69  00-049-1765  0.013433  0.025591   0.03\n",
      "10            V3Bi6O16  04-014-9744  0.011287 -0.015748   0.03\n",
      "11            VBi2O5.5  04-007-5482  0.008214 -0.009843   0.03\n",
      "12               Bi2O3  04-015-6853  0.010543  0.021654   0.03\n",
      "13            Bi2VO5.5  01-088-0870  0.008932 -0.011811   0.03\n",
      "14        Bi4(V2O11.2)  01-074-7536  0.010187  0.007874   0.03\n",
      "15            V2Bi4O11  04-011-3627  0.003691 -0.009843   0.03\n",
      "16            Cu3(VO4)  04-016-3668  0.011127 -0.043308   0.03\n",
      "17               Bi4O7  00-047-1058  0.003167  0.047245   0.03\n",
      "18            Bi2VO5.5  00-051-0032  0.004733  0.007874   0.03\n",
      "19           Cu2(V2O7)  01-078-2581  0.002809  0.033466   0.03\n",
      "20                 VO2  04-003-2035  0.005250  0.049214   0.03\n",
      "21            Bi8V2O17  00-044-0171  0.004296  0.039371   0.03\n",
      "22               V0.9O  04-010-5832  0.007580 -0.011811   0.03\n",
      "23                 VO2  01-076-0675  0.005167  0.041340   0.03\n",
      "Current R^2 = 459737.5655152487\n"
     ]
    }
   ],
   "source": [
    "new_sample.print_solution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c08f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 908,
   "id": "31e2abcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 908,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 892,
   "id": "01bd2bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special._ufuncs import wofz\n",
    "def Voigt(x, c, alphagamma, amps,wavelength=0.9):\n",
    "    #alphagamma = alphagamma * 1 / np.cos(np.arcsin(np.array(c) / np.pi / 2 / 10 * wavelength / 2))\n",
    "    x = x[:, None]\n",
    "    c = c[None, :]\n",
    "    amps = amps[None, :]\n",
    "    #alphagamma = alphagamma[None, :]\n",
    "    \"\"\" Return the c-centered Voigt line shape at x, scaled to match HWHM of Gaussian and Lorentzian profiles.\"\"\"\n",
    "    alpha = 0.61065 * alphagamma\n",
    "    gamma = 0.61065 * alphagamma\n",
    "    sigma = alpha / np.sqrt(2 * np.log(2))\n",
    "    profile = np.real(wofz(((x - c) + 1j * gamma) / (sigma * np.sqrt(2)))) / (sigma * np.sqrt(2 * np.pi))\n",
    "    profile*=amps\n",
    "    profile=np.sum(profile,axis=1)\n",
    "    profile=profile/np.max(profile)*1.5\n",
    "    return profile\n",
    "\n",
    "def plot_xrd(ax,data):\n",
    "    q_vectors = np.linspace(5,50,1000)\n",
    "#     amps,_,_,ds = list(zip(*(data['xrd.Ag']['pattern'])))\n",
    "    amps,qs = np.array(data.amp),np.array(data.q)\n",
    "#     qs = 4 * np.pi / (2 * qs) * 10\n",
    "    ax.plot(q_vectors,Voigt(q_vectors,qs,0.3,amps),c='C0')\n",
    "    plt.title(f'{data.name} entry_id:{data.entry_id}')\n",
    "    \n",
    "    for q,amp in zip(qs,amps):\n",
    "        ax.plot([q,q],[0,amp],c='C1')\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 883,
   "id": "49e88eb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax=plt.gca()\n",
    "plot_xrd(ax,entries[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 889,
   "id": "6cff879d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax=plt.gca()\n",
    "plot_xrd(ax,entries[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 893,
   "id": "b5254308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA4kElEQVR4nO3deXxcdbn48c8zM9mbJm2TNt0X2lJadiqbLGW1RQUUvYIC4lXRq6j3qteL140L6kW9v+tyxQUVcWMTUSqLKMi+CIXSjbZ0b9M2zdJmXyYz8/z+OGeSk8lMZpqZnKTJ8+4rr85Zcs43Z2ae+c7zXY6oKsYYY458geEugDHGmNywgG6MMaOEBXRjjBklLKAbY8woYQHdGGNGCQvoxhgzSlhAH2Yi8hMR+cpwl8MMHRE5W0Q2D7D9ThH5up9lMqOTBfQhJiI7RaRDRFpF5JCIPCwiM+PbVfXjqnqLiEwXkYiIHJXkGH8Ukf9xH98iIuvcfW9Kc24RkW+JSIP78y0REXfbQhF5UETqROSgiDwmIkd7fvc6EYm65Y7/LEs49r+LyBb379stIv8tIgVJypEvIhtFpHoQl9AXIjJHRFREQrk+tqo+q6pHp98zORG5QEQ2iUi7iDwpIrM92wpE5A4RaRaRGhH5bJpjTXRfT20isktE3p9ivzvc6zE/ybYFItIpIr9Nc645bnnb3fJfmLD939wyN7vnK/BsO1FEnhWRJhGp9lZ63NfT/e57S72vy7HOAro/3qmq44CpwAHg/xJ3UNW9wBPANd71IjIRuAT4lbtqK/AF4OEMzns9cDlwAnA88E7gY+62cmAlcDQwBXgZeDDh919U1XGen6c8237gHv9aoBRYAVwA3JekHP8O1A1UUBF5aqS/MYci2GdwzgrgAeArwERgFXCvZ5ebgAXAbOA84AsisnyAQ94GhHGe8w8APxaRJQnnPAvoV7FIOMYrGRT/bmA1MAn4EnC/iFS653gbcCPOa2Y2MA/4L8/v3gU8g/M3nwt8QkQu9Wx/DrgaqMmgHGOHqtrPEP4AO4ELPcuXAG96lu8Evu4+fj+wLeH3PwGsTnLc3wI3pTn3C8D1nuUPAy+l2HcioMAkd/k64LkU+y4AosCpCetnAl3A+Z51c4GNOAG/eoCyPgUsS7L+fcAOYLy7vALnTVyZ4jinu393I7DGe0z3HLcAzwMtwF+BCnfbbvfvb3V/znCvwfPAd4EG4JvAQeA4zzEnA+2pyuPus8z7twMnAa+5ZbgXuCf+Gkjyu9cDL3iWS4AOYJG7vA+42LP9FuCeFMcqwQnmCz3rfgPc6lkO4QTh493rMT/hGFfifGjfBPx2gL95oftaKPWsexb4uPv4LuCbnm0XADWe5XZgsWf598AXk5ynOtnrZqz+WA3dRyJSjBOgXkqxyx+BCreGFHcNvbXzw7UEJ6jFrXHXJXMOzhuqwbPuJBGpF5E3ReQrnhrqBTgB6mXvAVR1D87fdpFn9f8B/4kThA6bqt6LE6B/ICKTgF8AH1HVfjV+EZmO883l6zgfUJ8H/hCvFbreD3wIJxDnu/uA8/cDlKvzbeRFd/k0YDtOjfYWnOB7ted4VwFPJCtPMiKSD/wJJ5BOxAlUVyTs0+h5DfR5DlW1DdgGLBGRCTjf+jJ9jhcCEVV9c4D9/w14RlXXJin7eOBmYMC0jqfc21W1JcW5kr02p7jPMcD3gGtFJM9NBZ4BPJ7Becc0C+j++JOINAJNOMHuO8l2UtUOnDf4teDkKoFTcGozgzHOPWdcEzAunkePE5EZOF+jvW/UZ4BjcQLfFTiB69/dbRXA/hTn3O9uR0TeBQRV9Y+DLH/cJ4HzcWrYf1bVh1LsdzXwiKo+oqoxVf0bToriEs8+v1TVN91rfR9wYppz71PV/1PViPs7vwKu8lzDa3CCc6ZOB/KA76lqt6reT0L6QlXLVfU5dzHxOcRdLnW3Qf/nuDTFuccBzSmOhThtOx8Dvpri928BfqGqmbSFDFTuZNvjj+PbHwLeg1MR2OSeN5M0z5hmAd0fl6tqOVAI3AA8LSJVKfb9FfBeESnECRaPqWrtIM/bCoz3LI8HWtX9rgrg1l7/CvxIVe+Or1fV7aq6ww2M63BqZu9xN9fj1AyTmQrUi0gJ8G3g06kK59ZEG90Pu7OAhzzrbvSUpRHng+5Y4P8N8PfOxrl2icf1ltWbc22nNyimsse7oKr/cH9vmYgsAubjtEVkahqw1/scALsG2D/xOcRdbnG3Qf/nuAVARB71NGh/IM2xwKkV36yqiYEYETkRuBAn/dSPiGzwnOvsDM6V7LUJ0OK2G/0F5zVXiJPKe5uIfCLZuU0vC+g+UtWoqj6Ak38+K8Vuz+HkaS/DqXEONt0CsAGnQTTuBHcdAO5X9r8CK1X1G2mOpUC8Vvp3YKaInOrdwa3hnY7TuLsAmAM8KyI1OA17U91eDXOgpyZa7n7YPQe8w7PuVs9xTwT+GaeR7QcDlHEP8BvvcVW1xHusNH9fput/hfPcXAPcr6qdGRw/bj8wPeFb0qwB9u/zHLoflEcBG1T1kHu8pM+xqq7Q3gbt3wFvAiH3m1+//XFSad9xn6P4B9+Lbk+YZTjP52532+eBK0TkNfdcSzznetY95jwRKU1xrmSvzQNuym8eEFXVX7vfjKpxUl3eb1ommeFO4o/2HzyNojgB8TIgAixx191JQoMY8DX39w4CBQnb8nBqLXfh5IoLcdIayc79cZwGyek4NcMN9DZKjcfp2fLDFL+7ApjiPl4ErAe+5tn+I2ALTgAP4uREXwYedreHgCrPz7txGvCqkpWX1I2ihe65/wUoANYBn0hR5pk4NfC3uWUqxAlEMzzn+Ihn/+twG36BYpwP2oXJtic5z0GcmvU5GbwGluE2iuLk7XcDn3Gfy3cD3YmvAc/vVuKkI65w/55v4WnYBm4FngYmuM/TfmD5AGW5B+eDsQR4q3vs+GtxcsJzpu7zW+ReH++2/wHuZ+DG4Jfc/QqBd+E0VFe625a7z9VinB5Xf8dtnMV5bTbitHcE3PO9SN9G1AL3uNXAxe5jGe73+3D/DHsBRvsPTmDuwPmK2eIGpw94tt+Z+GbG6RkSA36c5Hh3um8078917razcVIq8X0FJ+1x0P35dvxFD3zQ/d02ent2tAKz3O3/g9PFsg2nUfBmIM9z7ADwHzjdKDtwasffBgpTXIdlDK6Xy3eBRz3LJ7h/y4IUxzkNJ8AdxOkq+bDnb3qKFAHdXb7Z/Z1GnEDWZ3vCeR53n9u0QSTxbweW4vQkifdyudf7GnCfh7M9yxfi5JE73L9hjmdbAXAHTm78APDZNGWZiNMo24bzwfL+Afbt18vFs+0mBujl4u4zxy1vB7AZT28vd/tn3TI3A7/EU3nBaTN5BecDpwb4GVCc8L5KfB/MGag8Y+En/uY2xhwGEbkDp8H0y8NdFmPifB8oYcyRzm0DeDdOf3JjRgxrFDXmMIjILThps++o6g7P+v+UvtMkxH8eHb7SmrHGUi7GGDNKWA3dGGNGiWHLoVdUVOicOXOG6/TGGHNEevXVV+tVtTLZtmEL6HPmzGHVqlXDdXpjjDkiiUjKkcWWcjHGmFHCAroxxowSFtCNMWaUsIBujDGjhAV0Y4wZJSygG2PMKGEB3RhjRgkL6CanXt/TyOrdh4a7GMaMSTbbosmpy297HoCdt759mEtizNhjNXQzJFo6u4e7CMaMORbQzZBo64oOdxGMGXMsoJsh0R6ODHcRjBlzLKCbnIlEYz2P28NWQzfGbxbQTc60eYJ4R7cFdGP8ZgHd5Ew4YjV0Y4aTBXSTM10RTw3dcujG+M4CuskZbw3dUi7G+M8CusmZLk9A747YzceN8VvagC4id4hIrYisT7PfW0QkIiLvyV3xzJHEG9DDnh4vxhh/ZFJDvxNYPtAOIhIEvgX8NQdlMkcob8olYgHdGN+lDeiq+gxwMM1unwL+ANTmolDmyORtFO2OWsrFGL9lnUMXkenAu4AfZ7Dv9SKySkRW1dXVZXtqM8J4a+jdMauhG+O3XDSKfg/4D1VN+w5W1dtVdamqLq2srMzBqc1IYo2ixgyvXEyfuxS4R0QAKoBLRCSiqn/KwbHNEaRPDt1q6Mb4LuuArqpz449F5E7gIQvmY1N31Hq5GDOc0gZ0EbkbWAZUiEg18DUgD0BVfzKkpTNHlEisN80SsUZRY3yXNqCr6lWZHkxVr8uqNOaI1jegWw3dGL/ZSFGTM/EgnhcUwlZDN8Z3FtBNzkTdGnphXtBq6MYMAwvoJmfig4mK8oJ9GkiNMf6wgG5yJup2VSzKD9Ids5SLMX6zgG5yJl5DLwwF6Y5YDd0Yv1lANzkTjSnBgJAfCvTp8WKM8YcFdJMz3bEYwYAQCorl0I0ZBhbQTc5Eo0peQMgLBiygGzMMLKCbnIm4KZe8oNj0ucYMAwvoJmcisRh5wQChQMD6oRszDCygm5yJROM19ICNFDVmGFhANzkTiSl5wQB5QbEaujHDwAK6yZlINNZTQ7dGUWP8ZwHd5EwkpoSC8W6LlnIxxm8W0E3ORKJKKCDkWw3dmGFhAd3kTCSmhAIBQkGxkaLGDAML6CZnIrEYoaCbQ7e5XIzxnQV0kzPRmJNyyQsG6LabRBvju7QBXUTuEJFaEVmfYvsHRGStiKwTkRdE5ITcF9McCbqjMSflEhC7p6gxwyCTGvqdwPIBtu8AzlXV44BbgNtzUC5zBIpE471cnNkWVS2oG+OntAFdVZ8BDg6w/QVVPeQuvgTMyFHZzBEmPpdLKCBA7y3pjDH+yHUO/cPAo6k2isj1IrJKRFbV1dXl+NRmuPXM5RIUd9kCujF+yllAF5HzcAL6f6TaR1VvV9Wlqrq0srIyV6c2I0R8Lpd4Dd0CujH+CuXiICJyPPBzYIWqNuTimObI48zlIoQCTj0hag2jxvgq6xq6iMwCHgCuUdU3sy+SOVI5t6DrTblY10Vj/JW2hi4idwPLgAoRqQa+BuQBqOpPgK8Ck4AfiQhARFWXDlWBzcjVHY2RF/DU0C3lYoyv0gZ0Vb0qzfaPAB/JWYnMESua0MvF5nMxxl82UtTkTHdUCXl6uVgN3Rh/WUA3ORONxQgFhGBPDd0CujF+soBuciY+UjQvaDl0Y4aDBXSTMxF3cq6g5dCNGRYW0E3OONPnOvcUBauhG+M3C+gmZ3pr6AF32WroxvjJArrJiWhMUYVQIEBefOi/NYoa4ysL6CYn4rXxULA3h25zuRjjLwvoJifitfFQwJkPHSygG+M3C+gmJ+LBOxQM9M62aL1cjPGVBXSTE/Hg7dTQLeVizHCwgG5yItpTQ++dnMsaRY3xlwV0kxPdMW8OPV5Dt5SLMX6ygG5yItrTKOrNoVsN3Rg/WUA3OdHt6bYYsrlcjBkWFtBNTvTk0D01dLtjkTH+soBuciI+EZf3BhdWQzfGX2kDuojcISK1IrI+xXYRkR+IyFYRWSsiJ+e+mGakiwdv702ibT50Y/yVSQ39TmD5ANtXAAvcn+uBH2dfLHOkiQfvoKeXS9RSLsb4KpN7ij4jInMG2OUy4NeqqsBLIlIuIlNVdX+uCmlGvngNfeHqb1CwtQA412roxvgsFzn06cAez3K1u64fEbleRFaJyKq6urocnNqMFPGRouMObSRY62TnLIdujL98bRRV1dtVdamqLq2srPTz1GaIxYf5i3jW2VwuxvgqFwF9LzDTszzDXWfGkPioUHH/5QXF5nIxxme5COgrgWvd3i6nA02WPx974qNC4zX0YMACujF+S9soKiJ3A8uAChGpBr4G5AGo6k+AR4BLgK1AO/ChoSqsGbl6Ui7ucl4gYEP/jfFZJr1crkqzXYFP5qxE5ojUm0N3QnowKDY5lzE+s5GiJifiDaDxGnooELCUizE+s4BuciKxl0soINbLxRifWUA3OdHbKOpE9JD1cjHGdxbQTU5EY4kpF7FGUWN8ZgHd5ER3QrfFUDBgI0WN8ZkFdJMT0YReLqGA9Eypa4zxhwV0kxPdiSmXoFgN3RifWUA3ORHtN1I00HPjaGOMPyygm5zoE7wPbuejbT+1+dCN8VnakaLGZCIaixEKOBNzEW5lrm63+dCN8ZnV0E1ORKJKMNA7d24Ay6Eb4zcL6CYnIjElL+h5OYnNh26M3yygm5yIRGN9a+iCjRQ1xmcW0E1OdMeUvKDndkXYSFFj/GYB3eRENCGHLoJNn2uMzyygm5zojsUIBXpfToKlXIzxmwV0kxPRmBIKemvolnIxxm8ZBXQRWS4im0Vkq4jcmGT7LBF5UkRWi8haEbkk90U1I1kkqoS8KRcs5WKM39IGdBEJArcBK4DFwFUisjhhty8D96nqScCVwI9yXVAzskUSUy6C9UM3xmeZ1NBPBbaq6nZVDQP3AJcl7KPAePdxGbAvd0U0R4JItH/KxUaKGuOvTAL6dGCPZ7naXed1E3C1iFQDjwCfSnYgEbleRFaJyKq6urpBFNeMVJFY/5SL1dCN8VeuGkWvAu5U1RnAJcBvRKTfsVX1dlVdqqpLKysrc3RqMxJEYjFCwb4pF5sP3Rh/ZRLQ9wIzPcsz3HVeHwbuA1DVF4FCoCIXBTRHhsS5XMTmcjHGd5kE9FeABSIyV0TycRo9Vybssxu4AEBEjsEJ6JZTGUMiCSNFxR36r2pB3Ri/pA3oqhoBbgAeAzbi9GbZICI3i8il7m6fAz4qImuAu4Hr1N7JY0okpgQTermA5dGN8VNG86Gr6iM4jZ3edV/1PH4DeGtui2aOJJFojLyAOP2dcFIu4DaWBoexYMaMITZS1ORE/5Gizv82/N8Y/1hANznRHe0/lwvYnOjG+MkCusmJZHO5gNXQjfGTBXSTE91Jps8FbIIuY3xkAd3kRCQWIy9ZysUm6DLGNxbQTU4km8slvt4Y4w8L6CYnwtFYn5tE99bQLaAb4xcL6CYnItH+I0XBUi7G+MkCusmJSCyhhm4pF2N8ZwHdZE1V6Y5q39kW3f8t5WKMfyygm6zFg3Zekm6LUUu5GOMbC+gma/F5z/NC3hq6uNushm6MXyygm6zFg3YoaQ3dAroxfrGAbrIWn68lP9R/+ly7a5Ex/rGAbrLWW0Pvn3KxGrox/rGAbrIWr4Xb9LnGDC8L6CZr8YCen6zbojWKGuMbC+gma/FaePLpcy2HboxfMgroIrJcRDaLyFYRuTHFPv8kIm+IyAYRuSu3xTQjWU+3xWD/RlGroRvjn7T3FBWRIHAbcBFQDbwiIivd+4jG91kAfBF4q6oeEpHJQ1VgM/LEG0X7zOXi/m+Nosb4J5Ma+qnAVlXdrqph4B7gsoR9PgrcpqqHAFS1NrfFNCNZvNtin14ubhW921Iuxvgmk4A+HdjjWa5213ktBBaKyPMi8pKILE92IBG5XkRWiciqurq6wZXYjDjhZCkX93+roRvjn1w1ioaABcAy4CrgZyJSnriTqt6uqktVdWllZWWOTm2GWyRZyqVnYJEFdGP8kklA3wvM9CzPcNd5VQMrVbVbVXcAb+IEeDMGxHuyJJs+1ybnMsY/mQT0V4AFIjJXRPKBK4GVCfv8Cad2johU4KRgtueumGYkC0eSdFt0/7caujH+SRvQVTUC3AA8BmwE7lPVDSJys4hc6u72GNAgIm8ATwL/rqoNQ1VoM7Ikr6G72yygG+ObtN0WAVT1EeCRhHVf9TxW4LPujxljkvZDRwiITc5ljJ9spKjJWrLpc8GZfTFsAd0Y31hAN1mLp1W80+eCM7dLOGIB3Ri/WEA3WeuZbbFfDT1IVyQ6HEUyZkyygG6y1jt9bt+XU0EoQJfV0I3xjQV0k7V4Dj0/SUC3lIsx/rGAbrIWSXKDC3AbRS2gG+MbC+gma+FoDBHr5WLMcLOAbrIWjsQoCAV6hvvHWS8XY/xlAd1krSsS65c/ByjIs0ZRY/xkAd1krSsSoyAv2G+91dCN8ZcFdJO1rkg0aQ3dGkWN8ZcFdJM1p4aeLKAHrVHUGB9ZQDdZcxpFLeVizHCzgG6y1hWJ9ZvHBZyUiw39N8Y/FtBN1sKRKAVJAroN/TfGXxbQTda63H7oiWzovzH+soBushZOEdDjI0Wd+58YY4ZaRgFdRJaLyGYR2SoiNw6w3xUioiKyNHdFNCNd1wCNoqoQiVlAN8YPaQO6iASB24AVwGLgKhFZnGS/UuAzwD9yXUgzsnVFoikbRZ3tlnYxxg+Z1NBPBbaq6nZVDQP3AJcl2e8W4FtAZw7LZ44AqVIu8XWWRzfGH5kE9OnAHs9ytbuuh4icDMxU1YcHOpCIXC8iq0RkVV1d3WEX1oxMKRtF3ekArOuiMf7IulFURALA/wKfS7evqt6uqktVdWllZWW2pzYjRDhFP/QiN6B3hC2gG+OHTAL6XmCmZ3mGuy6uFDgWeEpEdgKnAyutYXTsSNUoWpzvrGu3gG6MLzIJ6K8AC0RkrojkA1cCK+MbVbVJVStUdY6qzgFeAi5V1VVDUmIzokSiMaIxTVpDLykIARbQjfFL2oCuqhHgBuAxYCNwn6puEJGbReTSoS6gGdnik28ly6EXuTX0tnDE1zIZM1aFMtlJVR8BHklY99UU+y7LvljmSNHVnTqgl+S7NfQuq6Eb4wcbKWqyEu9jnuwGF705dKuhG+MHC+gmK/FgHQ/eXtYoaoy/LKCbrMSDdXF+/+ydNYoa4y8L6CYrvQG9fw29IBRAxFIuxvjFArrJStsAKRcRoSQ/RNsR2Cj68o6D3HDXazS0dg13UYzJmAV0k5V4D5ZkKRdnfZCO7iOvhv6NRzby0Nr9/PrFXcNdFGMyZgHdZGWgRtH4+iOtht4RjrJhbxPg1NRN7qgqtS02f99QsYBusjJQDt1ZHzricug7G9qIxJSyojze2N88LGU42BamqaN7WM49lG5/ZjunfuMJHl23f7iLMipZQDdZiQf0eI+WRKWFIZo7jqyAvquhHYBzF1bS1NFNU7u/gXXDvibOvPUJzvn2k2ytbfX13EPt7pd3A/D7V6uHuSSjkwV0k5X2cASR5CNFASaNy6ehzdOw+OiNzs8ItvtgGwBnza8AYM+hdl/P/+OnthFTZxbL7zy2yddzD6X2cIRdB51r+fqexuEtzChlAd1kpT0cpSQ/hIgk3T6xJJ+DbWEAGlq72PT68zTtfM3PIh62XQ3tlBfnsXjaeACqfQzo4UiMpzbXccXJM7j69Fk8sbGW5s7RkXp580ArqvCWORM42BbmkPu6MLljAd1kpT0c6ZmEK5mJJQU0dnQTjSn3rtpDY0c3uxrafCzh4as+1MHMCcXMnFgMwJ6DHb6d+5WdB2ntinD+osmct2gykZjy2q5Dvp1/KL1Z0wLAimOnArC9fnSlk0YCC+gmK04NPXVAn1SSjyocag/z+u5GADq6o0RH8I2j61q6mDK+gLKiPEoLQ+xt9C+gP77xAPmhAG+dP4klU8sA2OwGwiPdppoWCvMCnLdoMsCoax8YCSygm6y0dUUpStEHHWBCST7g9NpYW+10BVSFA80jt+tabUsXlaUFAFSNL6SmyZ+yRqIxHlq7n2ULKynOD1FWnMfUskI2jZKAvvlAMwunlDJrYjHBgPj6zWessIBustLS2c34wtQBfZIb0Dfub6amuZPyojwA9hz0t6ExU9GYcrCti8rSQgCmjC+kxqcPn7tf3k1dSxfvPrn3lr1HV5WycZi6Tuba5ppWjp5SSjAgTCktYF+TBfRcs4BustLU0U15cV7K7RXjnJru4xtrAZjkLu85NDLfzA2tXcSUnhr6lPGF1PoQ0P+8Zh9feXADZy+o4KLFVT3r50wqYe8IvVaZ6AhHUVXqW7uob+3i6KpSAKrK/PvmM5ZkdIMLY1JpbO/m+BmpA/ost2Hxz2v2EQwIE9zgn/OeI/GukCtuzeowtS1OF8vJ8ZRLWQG1LV3EYkogkLwnT7Y6u6P81583cOLMcn527VKCnvNcUft/zIoeoqnjfMqKUl/nkWjDvibe9aMXWL6kistPmgbA8TPKAZhaVjRqvnmMJBnV0EVkuYhsFpGtItKvE7GIfFZE3hCRtSLyhIjMzn1RzUjU2BGmvDg/5fai/CAzJxYBcMzUUkKBAPnBQM5qnV2RKB/99So2vf48sZq1WR+vzg3o3hp6JKbUtw3dJF3PbqmnvjXMv120kMK8YJ+++tM6t7I4sIt9PjbM5sr9r1YTjsRYuWYfv35xFwGBY6c7XUGnlhWyr6kD1ZHbOH4kShvQRSQI3AasABYDV4nI4oTdVgNLVfV44H7g27kuqBl5OrujdHbH0tYcz5g3CYALj5kCQF4okHVeuvvhL/DMDz7MJd9/lr+9cYDGjm4aczCiMz7PyGRPQAeobR66gP74GwcoLQz1XCdq1jk/0HPz7aEO6Bv3N7O1NreNry9ua+DEmeWUFoZ4anMdR1eN75nEraqskM7u2Kic3mA4ZVJDPxXYqqrbVTUM3ANc5t1BVZ9U1fh36JeAGbktphmJ4m/GgXLoADeuOIavvGMx158zD4D8YCDrXi71W1aRX7+BvGCAr75jMQERmnMQHOI19Hjuv8oN6EOZ7123t4mTZk3oCd5eBSGnS+hQdp081BZmxfef5e0/eI6Ie9PvbDV3drOppoULFk3mY+7zfs3pvV/cp5Y539r2NVoePZcyyaFPB/Z4lquB0wbY/8PAo9kUyhwZ4jXi8qLUKRdwRot++Ky5Pcv5oUDWAfJQezfF+UH+8q/nALDuqSAdObgzUm1LF+MLQ07qg94a+lD1dIlEY2yta+WsBRVJt+cFBQH2D+EHyovbGwDn/rCbalo4dnpZ1sfcWe8MHlswpZS3LZnCe5fO7LmWAFPL49e1o2dErsleTnu5iMjVwFLgOym2Xy8iq0RkVV1dXS5PbYZBY7szdPtwG+vygwGaOyNZBeD2cIRxngnBivKDdHTnIKA3d/UJPBXj8gnI0PWb39nQTjgS4+gppUm3C0J+KMD+Iayhv7Gvt3Fyw76mnBxzhxvQ51WWICJ9rik4OXSwGnquZRLQ9wIzPcsz3HV9iMiFwJeAS1U1acJRVW9X1aWqurSysnIw5TUjyKH2hJTLozfCwe1pfy+eWhhsrbexPUwkphTl9Y5QLcwLEI7Gsq6l17Z0Mnl8Qc9yKBigsrRgyAJ6fBRovDtfMvnBwJDW0LfWtjJ7UjGhgPTMNJmtHfVtiPT2cko0ubSQYECs62KOZRLQXwEWiMhcEckHrgRWencQkZOAn+IE89rcF9OMRIkNiNSsg3D64dz5QTegD/LNHA86BZ6AHg/u8ZrhYNW2dDG5tG9t0hlcNDSNoptrmgkIzJ88LuU++TloRB5IdWM7cytKmDGhKGcBfWd9G9PKinpSV4lscNHQSBvQVTUC3AA8BmwE7lPVDSJys4hc6u72HWAc8HsReV1EVqY4nBlFapo6CQWkZ7BQpuI19MHWene6k3sV5vW+fOONh7uzGIGqqtQ2dzk1dE/XwSnjCzkwRDXJzQdamFNRkjLwgXO99jd1DlkXv+pDHcyYUMTsSSU91zZbOxramVORvHYeN7W8iP2WcsmpjAYWqeojwCMJ677qeXxhjstljgA1zZ1MLi3oMxAmE9mmXHbWtzMFKAz1TblAdgOWmjq6CUdjTg19y7qe9VXjC3ll59Dcim5zTQvHTB24UTA/FCAciXGwLXzYH57ptHQ63T1nTCgmKMKruw6hqimnQ86EqrKjrpVLT5w24H5VZYU9t/ozuWFD/82gHWjuZEpZYfodEwRFKMkPDrqGvquhjfxggIAn6AQDQlCE6iwGLCWOEo2bMr6AxvZuOgdodP3mIxt5z49foLUr87szxW/4MFD+HKAg6HxwZZJHf3jtft7/s5cynisn3h1yxoQiZk4sprUrknXf8EPt3TR3RpgzqWTA/aaVFQ7pN4+xyAK6GbSaps6eftqHa0pZYVYpl8QUhSAUhAJZTfoVL0+fHhmP3sjFe77XZ3uy37v9me2s2nWIR9Zmfq/MLe4NHxalCejxbzTpAnospvzXnzfwwrYGfvDElozKUO3OeDi9vIgZE3Iz/3u8HePi3d8b8O5UU8uK6HK/eZjcsIBuBiUWU/Y1dvYMEDlc2UxLu6uhvU/+PK4gL5hdDb05SQ29Zh2T294E4ECKhtFXPTegeMnt052JzQecHi4LU3RZjOtJUaVpQHx196GebxlPv1mXUc03nqKaObG4Z4qGbOfZifdBr2x7s2fEazLT3L7oQ9mDZ6yxgG4Gpaa5k47uKPMqB/5anUrV+MKUAXIgzZ3dNLSFkzYiFoQC7DnUPuiv8D0pl/F9Uy7pcv4b9jURCghnL6hg7WHkhDe7N3yYnSY1kRcUQgFJG/he3NaACHz57cdQ29LFmwfS9ziqPtRBYV6ASSX5vTX0LAP6jvo2ggGhIMmHrrexuXe0qPV0yRUL6GZQttU5wWKg7nYDiadcYod556Ldbre6wqTD5AO0h6OD/gq/v6mD8YWhnvlG4uLdLFP1dNmwr5nvjLubz0Z/yba61ozz6JtrWlgwuTRto7LgDMxJF9DX7W1ibkVJz5w5r+1Of+s6p4dLMfKXL1L21FcYXxjK6lsOOAF95oQiAiT5uzzz1PSOFrUaeq5YQDeDss29fdhRlYML6FWDnMUw3q2uIFkN3V032IC0+2A7syb172oXDAhFecEBaujNHBfazZzubag6fcszsflAS2+6xVNzTWZaeSH706Rc1lU3cfz0Mma/cjNfL/wta6sb05ahurGdGROK4I0H4Y0HmTmxOOubj+yob2NORZJvHfGBZwe3w6M3UlFSQF5QbLRoDllAN4OycX8L5cV5VIwbeB6XVOKBc2f94QWP+MCXVCkXGHzKYPfB9qQjG50ackHSnH9tSyd1LV2U5Acpdu+tmskt4w62halr6eptEPXUXJOpKisasM2htqWTmuZOjp1ehtSs55SCatbsSZ/+ifdBJ9wK4VZmTCjK6uYjqsrOhjbmJgvo8YFn4VaoWUcgIEwvLxqxd686EllAN4Oyes8hTppZPuj+ygvcVM2Ww5yydUd9m9P3Pcl540F+ML00YjGl+mAHM1MMVZ9TUdKTZvKKz4NSUhAiPxSgtCDEpv3p/6ZNbi0+XZfFuGllhexr6kx5c+31bu7+7fu+Dwe3U1IQYvOBlgG7Wnr7oMcdVTmOnfVthCODm3WxtqWL9nC0N6C7tfFU5laUsD3L0b2mlwV0c9iaO7vZUtvKybMmDPoY08qKKMoLHvad37fUtqZsiA2Kc0ekwfTSqGnuJByNMXNCcdI5aRZOKWV7fVu/6WU3uAG9OD+IIBxdVdozP8tA4kE/04B+VOU4wpFYytrsmj1NBAQmt22BcCvjCkJEY9pTvmTiqanp5b09lRZNHU8kpkk/vDIR/3YyP56Kc2vj/biBfl7lOHbUtx52W4pJzgK6OWzPb6lHFU6dO3HQxwgEhAVTxmVUm42LxZQtB1pYVJV6ZOWMCcWDGv4fvx3a0VWlSeekmT/ZCaiJx35jXzOzJhYTCjhvpUVTS9lY05y2p836vU1Ulhb0m4UwlYVu4I93dUy0trqR+ZPH9Xxzic9EuWZPY8pjbqnt37AdTwFl8qGUTHy2xrRT4rqBfl5lCZ3dMfZbw2hOWEA3h+1vGw9QVpTHKbMHX0MHOHnWBF7f00h3hjdV2HOonfZwdMCBOEdXlbJxf/qAmmjDvmZESDkMP37OxBrva7sPcfyMMs9+42npjLAvgx4pxx/GvOMLpzhBN1mgVVXWVjf13K8TnJ45k0sLBmwY3VzTTCggfRq251aUUJwfZNWu5FMdvLGvmU/dvZqnNiefg2/DvmamlxcNeFtCrwWTneu6ye4vmhMW0M1hae2K8Nj6Gi5ePIVQMLuXz6lzJ9LRHWVdhn234/sNNPfJ8TPKqG8NH/ZglfV7m5gzqcSp2R7cDpG+v3/M1PGU5Af5x47egUN7GzvY39TJW+ZM7Om9EQ/8GwdIdTR1dLOtrpXjZpT19m6J9/5IoTg/xFGVJUm7Iu5t7KChLcwJM/p+QJwws5y11amv7eaaFuZVlvS5U1JeMMBZ8yt4YmNtvw/F7miMG+56jT+v2cen7lpNbUKtWlVZvavvB1w6x04fT0BgzQDlNJmzgG4Oy32v7KEtHOXKU2dlfazT500iFBAeW1+T0f7Pb21gXEGIJQN8nY/fbWegVEOi7miMl7Y39H7jCLdCrG9jYl4wwFvmTuT5rQ09ge75rfUALJ0zoaf3xpJpZeQFZcDJvF7c1kBM4cyjKnp7t8R7fwzgzKMqeHnHwX4Nli9sdT5kTpndNwV2wowytte3JZ2bRVV5fU8jS6b1D74rjqtif1Mn33h4Iw+v3d/TsHrfqj1sr2/jS5ccQ3t3lJ8/t6PP7+1saGdfUydvnZ/87kvJFOeHWDillNcP4/nKxJ6D7dz3yp6ecQtjhQV0k7GWzm5++ORWzjxqEifPKs/6eBNL8ll2dCV/eG3vgL0xwMmfP7uljtPmThzwm8Gx08ooLXBuSpypV3YcpLkzwoXHTB5wvxXHVrGjvq1nqP+f1+xj1sRiFnu+MRTlBzlp1gSe31af8jhPv1lLSX6Qkw7zGp69oIL2cLTfsf++qZaq8YUcM7VvKiqeglmXpPa7+UAL9a1hzjxqUr9t7zx+GhctnsLPn9vBJ+96jUt+8Cyrdh7ku3/bwg8n3stH2n7KJcdN5a5/7Ka5s/fD4omNBwA4a35Fxjc7ATht7kRe3tGQk1sIxmLKL57bwUXffZov/GEtF333aVYN0UyZI5EFdJMRVeVLf1xPY3uYL644JqvpVb0+cvY86lu7+NGTWwfc74VtDVQf6uDtx08dcL/8UIBzj67k8Y0H6IqkDxCqyu3PbmdCcR7nLBz4LlrvPGEa5cV53PLwRu5btYdnt9TznlNm9LsW5y6sZP3eZnYlmVu8rSvCn9fs521Lqsg7zJTVsqMnUzGugDue29HzLaG2uZO/b6pl+bFV/cpx4qxy8oMBHncDrddfN7jBN8m9TEPBAD+7dimrv3IRP792KU3t3bznJy/S3NHNeWUHkJr1fPTsubR2Rbj3Zed2w7GYcs8rezhxZrkzqCjDm50AXLS4is7uGM9sye62lN3RGDfc/Rq3PPQGZx5VwX0fO4Np5UV8+u7VhzUL5pHMArpJKxZTbn10EyvX7OPfLlzo5H5z5PR5k3j3SdP5wd+3cs/Lu5Pu09kd5b8f3UhlaQGXHDdwQAe48i2zaGgLc8/Le5JuP9QW5pfP7+B//7qZG+5azVOb6/iXZUf1G/IP9MltF+eH+O93Hce66ka+cP9aFkwex0fPntfvV644eQbBgPCLhJQEwE+e3kZrV4Srz5jd9xyR9Dn//FCAj587j2e31POjp5zj3PTnDURiMT545px++48vzOPiJVN44LXqnvu/gvOh8tuXdnHOwsq+k6tFOvv0GZ9Qks+Fu77L08c9xqcvWMDvPnoaJe41On5GOafNnchPnt5G9aF2fvz0NrbWtva5GXimTps3kSnjC7jz+Z2H/btetz66iUfW1fDFFYv4xQeXcurcifzPe09gf3Mn3/7LpoyOsbuhnQ/e8TIX/L+n+Pmz24+4qX0zusGFGbt2N7Tz5QfX88ybdVx9+iw+ed78nJ/jm+8+jrrWLm58YB0PrN7LPy2dybHTx5MXDLDlQAs/eXo7b+xv5qdXnzLgnX3i3jp/EmceNYlbH93E7EnFLDu6N5Xy5KZa/v3+tdS3OlMOlOQH+dg58/jIWf0DM9CvlrniuKk8+plzePNAC+cvmkxRfv/yVJUVctWpM/nNS7tYOKWU95wyg65IjF+/sJMfPrmVd588vW8f/iQ5+1Q+9Na5vLb7EN95bDPfeWwzAF9csSj5yEzgE8vm8+j6Gj573xq+dcXxqCr/+cf11LV28aPzE57LWLR/n/GadYwDPnv5wt51bh/yr1/+JS6/7XnO+taTAFxyXBXvSPMNKpm8YIDrzzmKWx56gz+uruZdJ8047GOsXLOPXzy3g+vOnMPHzj3KWfnojZwCXHfmNfzy+Z0sX1LFmQPk9x/bUMPnf78GgP8u/h21j3XxlYYvc/OlxxI4zJu4DBcL6Kaf7miMF7Y18KfVe1m5Zh95QeHrlx/LB06blbNUi1dhXpA7P3Qqv3lxJz99ZnvPmyquYlwBt73/ZC5eUpXR8USE773vRK6942Wu++UrLJ09gYVVpWytbeXlHQdZOGUcf1n0MBUlBbDi1sMu79FVpWkHBH1xxTHsrG/ny39az1ceXE+8ovf246fyzXcdl/oX47nnick/YIIB4YdXncwTJ9WycX8zb5kzkTOS5MHjFk8bz02XLuGrD67nLd94HAAR+No7FrN0ziDHEbh9yBdMKeWhT5/NA69VM3NCMe8+efqgXx8fPGM2j62v4fO/X0tDa5gPnjknaUpq/d4mDtz3r7SHoxw48ybeu3Qma/Y08vnfr+G2ifeyPDQV+JZzHd94ECbO40uTf8Wxpfv43O8L+cO/nMm08iJUlSc319Kx8gu0dUX4ft6H2dvYwffL7+X8RZWMO1TP7mA7N7+0m2gMvnH5kRHUMwroIrIc+D4QBH6uqrcmbC8Afg2cAjQA71PVnbktqsm1mDs51u6GdnY2tLO9rpXXdh9izZ4mOrqjlBaEuOb02Xxi2VFMHuSNLDIVDAjXvXUu154xh001LWyvbyUciTFjQjEnzSo/7Hzz5PGFPPCJM7nzhZ08uq6Gx9bXUFlawH8sX8Q/nzWHgt98GwY3diYjJQUhfv3Pp/L0ljpW726kIBTgzKMmcVK60bUZ5J4DAeGixVO4aPGUjMpyzemzOW3uRJ7aXIsgnLeokvmTMxuhms7cihI+d/HRWR8nFAxwx4fewqfvXs3XH97Ij5/axvmLJrNk2ngmjiugvSvC4xsP8PjGWn5fuInKUIBPPbyRrz+8EXAGR11cVkfwgNut1HMdQ7UbWF4R4aZ9ES6/7XkuO3Ear+9p5JWdh/hj8RZKC/NYOmsC106dzTu31RM41AAIsyYW88ljj+K2J7cRjcX45ruOy7qr7lBLG9BFJAjcBlwEVAOviMhKVX3Ds9uHgUOqOl9ErgS+BbxvKAo8nFQVVVD3McQfg6J4023eder9fXcb7vbefSESixGNac9PJP5/1F2nSjQW61mOJOzbFYnS2R2lIxylMxJz/u+O0uGua+mMcLA9zKG2MAfbwhxqD+MdcR0MCIunjud9b5nJGUdN4tyFlRmlOHIpEBAWTxuffqRhBorzQ3xi2Xw+sSz3aaJMBALCeUdP5ryjB+4944eFU0rT3khjuI0rCPGLDy7lmS313PvKbh7feIDfv1rds72ytIBPX7CAk3aXEwoEeOjis3h84wEmleRzxSkzyPtdwPl285OzoK3vjUZK8kPc+7EzuGnlBu58YSczJxTztXcu5oTN5QRE+P6VJzk7bu+thQvC52O/5IK5jbx71aX8Y8dB3rakigWTx1FVVsi4ghBF+UGK80IU5gcIBQIERQgEICBCMCCe/xmSb7eJMqmhnwpsVdXtACJyD3AZ4A3olwE3uY/vB34oIqJD0KLwtzcO8MUH1gL0Ca49gdKzTIpg6g2+vfv1XZd4zCNVYV6AorwgRXlBSgpCTCzJZ/7kcUwoyWeS+zO7ooQ5k0qYXl7UZ5CJMX4TEc5dWMm5CytRVepau2ju6KYgFGRaeZEzd/wvndfosdPLesYd9BigP//iaeO57+Nn9F35Zpq56GvWc3I+3H7NKdzx/A7ufH4n4QxHNicKiFNpEhE+ds68nHyzSZRJQJ8OeLsLVAOnpdpHVSMi0gRMAvp0mBWR64HrAWbNGtzAlKrxhVy8pKpn6nwR55PU+b/nPP22gbNd3E/Knqcx4fd79/Uc07N/8vP1P2fv4/7r4mXsez4IBgOEAs4neu//AYIBCAb6bwt69gkEoCAUpCg/2BPAC0IBf/N+VcdBV1Pv41T75Opc2Rx3oP0nzIbmfX3/nnQmzE6/T6pydDU55xs/rXc5Xr7B/F3e38+U929OPN5gjp/stZB4PdMcQ0SYXFrI5NKEdN9Ar63E5yuTcmaw/8VLqrh4SRVdkSgHmrqoae6kLRyhI+x8++3ojvZ8W45p7zfqWEyJxuh97H7LPznLaTNSkXSVaBF5D7BcVT/iLl8DnKaqN3j2We/uU+0ub3P3STm6YunSpbpq1aoc/AnGGDN2iMirqro02bZMvl/vBWZ6lme465LuIyIhoAyncdQYY4xPMgnorwALRGSuiOQDVwIrE/ZZCXzQffwe4O9DkT83xhiTWtocupsTvwF4DKfb4h2qukFEbgZWqepK4BfAb0RkK3AQJ+gbY4zxUUb90FX1EeCRhHVf9TzuBN6b26IZY4w5HNZHzRhjRgkL6MYYM0pYQDfGmFHCAroxxowSaQcWDdmJReqAXcNy8typIGE07Bhn16Mvux697Fr0lc31mK2qSe/GMmwBfTQQkVWpRmyNRXY9+rLr0cuuRV9DdT0s5WKMMaOEBXRjjBklLKBn5/bhLsAIY9ejL7sevexa9DUk18Ny6MYYM0pYDd0YY0YJC+jGGDNKWEDPkIjcISK17s084usmisjfRGSL+//Q3IZkhBGRmSLypIi8ISIbROQz7vqxej0KReRlEVnjXo//ctfPFZF/iMhWEbnXnX56TBCRoIisFpGH3OWxfC12isg6EXldRFa564bkvWIBPXN3AssT1t0IPKGqC4An3OWxIAJ8TlUXA6cDnxSRxYzd69EFnK+qJwAnAstF5HScm6V/V1XnA4dwbqY+VnwG2OhZHsvXAuA8VT3R0/d8SN4rFtAzpKrP4Mz17nUZ8Cv38a+Ay/0s03BR1f2q+pr7uAXnjTudsXs9VFXjdybOc38UOB/npukwhq6HiMwA3g783F0Wxui1GMCQvFcsoGdniqrudx/XAFOGszDDQUTmACcB/2AMXw83xfA6UAv8DdgGNKpqxN2lGudDbyz4HvAFIOYuT2LsXgtwPtz/KiKvisj17rohea9kdIMLk56qqoiMqT6gIjIO+APwr6ra7FTEHGPteqhqFDhRRMqBPwKLhrdEw0NE3gHUquqrIrJsmIszUpylqntFZDLwNxHZ5N2Yy/eK1dCzc0BEpgK4/9cOc3l8IyJ5OMH8d6r6gLt6zF6POFVtBJ4EzgDK3ZumQ/Kbq49GbwUuFZGdwD04qZbvMzavBQCqutf9vxbnw/5Uhui9YgE9O96bY38QeHAYy+IbNyf6C2Cjqv6vZ9NYvR6Vbs0cESkCLsJpV3gS56bpMEauh6p+UVVnqOocnHsL/11VP8AYvBYAIlIiIqXxx8DFwHqG6L1iI0UzJCJ3A8twpr08AHwN+BNwHzALZyrgf1LVxIbTUUdEzgKeBdbRmyf9T5w8+li8HsfjNGwFcSpJ96nqzSIyD6eWOhFYDVytql3DV1J/uSmXz6vqO8bqtXD/7j+6iyHgLlX9hohMYgjeKxbQjTFmlLCUizHGjBIW0I0xZpSwgG6MMaOEBXRjjBklLKAbY8woYQHdGGNGCQvoxhgzSvx/QKafXt43pIAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax=plt.gca()\n",
    "plot_xrd(ax,entries[38])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 891,
   "id": "f4d2bfc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax=plt.gca()\n",
    "plot_xrd(ax,entries[26])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "id": "5071dc09",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'samples' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18620\\323054159.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msamples\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[1;31m# if min([count_act[_.entry_id] for _ in sample.entries])<5.0:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[1;31m# if sample.R > 0.4:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'samples' is not defined"
     ]
    }
   ],
   "source": [
    "for sample in samples:\n",
    "    if True:\n",
    "        # if min([count_act[_.entry_id] for _ in sample.entries])<5.0:\n",
    "        # if sample.R > 0.4:\n",
    "        print(sample.sample_id, sample.loss(loss_weight))\n",
    "        # candidate_entries = []\n",
    "        # for i in nn_list[sample.sample_id]:\n",
    "        #     candidate_entries += samples[i].entries\n",
    "        # candidate_entries = list(set(candidate_entries))\n",
    "        # solution = []\n",
    "        # for e in candidate_entries:\n",
    "        #     phase = Phase.from_entry_and_instance_data(e, 1 / len(candidate_entries), instance_data)\n",
    "        #     solution.append(phase)\n",
    "\n",
    "        new_sample = deepcopy(sample)\n",
    "        # new_sample.solution = solution\n",
    "        # au = new_sample.to_auto\n",
    "        new_sample = new_sample.optimize(num_epoch=500, print_prog=True, loss_weight=loss_weight)\n",
    "        new_sample.update_solution(0.03, 0.2999, new_sample.max_q_shift)\n",
    "\n",
    "        new_sample = new_sample.optimize(num_epoch=3000, print_prog=True, loss_weight=loss_weight)\n",
    "        new_sample.update_solution(0.01, 0.2999, new_sample.max_q_shift)\n",
    "\n",
    "        new_sample.refine_one_by_one()\n",
    "        new_sample.refine_all_fractions()\n",
    "\n",
    "        new_sample.update_solution(0.01, 0.2999, new_sample.max_q_shift)\n",
    "        print(new_sample.loss(loss_weight))\n",
    "        if new_sample.loss(loss_weight) <= sample.loss(loss_weight):\n",
    "            sample.print_solution()\n",
    "            new_sample.print_solution()\n",
    "            samples[sample.sample_id] = new_sample\n",
    "            solution_file = f'solution/samples{sample.sample_id}.json'\n",
    "            with open(solution_file, 'w') as f:\n",
    "                json.dump(sample, f, cls=MontyEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "id": "e3c46990",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "id": "c8e9b532",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056d6f39",
   "metadata": {},
   "outputs": [],
   "source": [
    " i=83\n",
    "        solution = []\n",
    "        for e in entries:\n",
    "            phase = Phase.from_entry_and_instance_data(e, 1 / len(entries), instance_data)\n",
    "            solution.append(phase)\n",
    "            \n",
    "        solution = [Phase.from_entry_and_instance_data(entries[-1], 1, instance_data,width=0.1)]    \n",
    "\n",
    "        sample = Sample(i, instance_data.log_q, instance_data.sample_xrd[i], instance_data.chemsys,\n",
    "                        instance_data.sample_comp[i], oxide_system, instance_data.wavelength, max_q_shift, solution)\n",
    "        sample.prune_candidates_based_on_composition(cutoff=0.05)\n",
    "        sample.prune_candidate_based_on_xrd(plot=True, cutoff=0.08)\n",
    "        new_sample = deepcopy(sample)\n",
    "        \n",
    "        new_sample = new_sample.optimize(num_epoch=500, print_prog=True, loss_weight=loss_weight)\n",
    "        #new_sample.update_solution(0.03, 0.2999, new_sample.max_q_shift)\n",
    "        new_sample.print_solution()\n",
    "        new_sample.plot(perphase=True)\n",
    "        \n",
    "        new_sample.refine_all_fractions()\n",
    "        new_sample.refine_one_by_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e5239e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1688af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
